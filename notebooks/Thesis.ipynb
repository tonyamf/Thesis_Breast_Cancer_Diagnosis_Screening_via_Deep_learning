{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Thesis.ipynb","provenance":[],"collapsed_sections":["dExRVQI8aLbl","Bf0ES9ZmG0DP","5mfjVVbJXZ2B","rY5qvb78V2bh","lNXXuIMyez9W","7AjMzyqfzqP1","UpO3eF0C0Hie","SDDBEl_C1Kev","CV0-LhNMBBSA","q33D_g-RW0jV","cvxxutAvW6Rz","v7f1nC1JkfG7"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVsrGkj4Zn2L","executionInfo":{"status":"ok","timestamp":1629986338834,"user_tz":-60,"elapsed":188,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"9f8ffae8-8784-4794-b0ce-58dc0d6c7c1e"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Aug 26 13:58:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rEnfG94NobPR","executionInfo":{"status":"ok","timestamp":1627656633060,"user_tz":-60,"elapsed":3931,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"c7544849-6b6d-46e9-aaed-a2b574361f53"},"source":["!pip install image-quality"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: image-quality in /usr/local/lib/python3.7/dist-packages (1.2.7)\n","Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from image-quality) (1.4.1)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from image-quality) (7.1.2)\n","Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from image-quality) (0.16.2)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from image-quality) (1.19.5)\n","Requirement already satisfied: libsvm>=3.23.0 in /usr/local/lib/python3.7/dist-packages (from image-quality) (3.23.0.4)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->image-quality) (2.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->image-quality) (3.2.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->image-quality) (2.5.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->image-quality) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->image-quality) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->image-quality) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->image-quality) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->image-quality) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->image-quality) (1.15.0)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.15.0->image-quality) (4.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jEOxHu9xCjK","executionInfo":{"status":"ok","timestamp":1629986357418,"user_tz":-60,"elapsed":4454,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"2547d493-a026-441d-fca3-1e5d751dad3b"},"source":["!pip install tensorflow-addons"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.14.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dExRVQI8aLbl"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"K_X6Tj9TaBOF","executionInfo":{"status":"ok","timestamp":1629986359142,"user_tz":-60,"elapsed":1727,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"782ca65c-1b76-4a18-a2ff-7a727630b4f4"},"source":["#@title Libraries\n","%pylab inline\n","import imutils\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import pylab as pylab\n","import matplotlib.image as mpimg\n","from PIL import Image as im\n","# import segmentation_models_pytorch as smp\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from scipy import ndimage, misc\n","from skimage.filters import threshold_otsu\n","from skimage.segmentation import clear_border\n","from skimage.measure import label, regionprops\n","from skimage.morphology import closing, square\n","from skimage.color import label2rgb\n","import matplotlib.patches as mpatches\n","from scipy.misc import face\n","from scipy.signal.signaltools import wiener\n","import sys\n","import numpy as np\n","import skimage.color\n","import skimage.filters\n","import skimage.io\n","import skimage.viewer\n","from skimage import feature, io, color, filters\n","from skimage.transform import hough_line, hough_line_peaks\n","from skimage.feature import canny\n","from skimage.filters import sobel\n","from skimage.draw import polygon\n","from skimage import exposure\n","from skimage.transform import resize\n","from PIL import Image\n","import scipy.ndimage as snd\n","#from meta-pseudo-labels.\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Viewer requires Qt\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Bf0ES9ZmG0DP"},"source":["# Mount file syste,"]},{"cell_type":"code","metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"u2yW4Ik2Gy22","executionInfo":{"status":"ok","timestamp":1629986485331,"user_tz":-60,"elapsed":126191,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"0a692774-a0b6-4262-c58d-0238ac02f426"},"source":["#@title Driver mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w7kfgMnUadk0"},"source":["# Import data"]},{"cell_type":"code","metadata":{"id":"X30cgZKOacpN","executionInfo":{"status":"ok","timestamp":1629986485331,"user_tz":-60,"elapsed":4,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}}},"source":["\n","# import os\n","# input_dir = \"/content/drive/MyDrive/Thesis/MINI-DDSM-Complete-JPEG-8/Data.xlsx\"\n","root = '\\\\content\\\\drive\\\\MyDrive\\\\Thesis\\\\MINI-DDSM-Complete-JPEG-8\\\\'\n","# dfAll = pd.read_excel(input_dir)\n","# dfAll.head()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5mfjVVbJXZ2B"},"source":["# Selecting and Sampling"]},{"cell_type":"code","metadata":{"id":"igm2upJaCm5u"},"source":["# data = dfAll.loc[(dfAll.Status == 'Benign') & (dfAll.Tumour_Contour != '-')].copy()\n","# data.reset_index(inplace = True, drop = True)\n","# Cancer_data = dfAll.loc[(dfAll.Status == 'Cancer') & (dfAll.Tumour_Contour != '-')].copy()\n","# Cancer_data.reset_index(inplace = True, drop = True)\n","# Normal_data = dfAll.loc[(dfAll.Status == 'Normal')].copy()\n","# Normal_data.reset_index(inplace = True, drop = True)\n","# data = data.append(Cancer_data, ignore_index = True)\n","# data = data.append(Normal_data, ignore_index = True)\n","# data = data.sample(frac=1).reset_index(drop=True)\n","# data.head()to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mToRCE_3ACK8","executionInfo":{"status":"ok","timestamp":1629986487257,"user_tz":-60,"elapsed":1109,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}}},"source":["data = pd.read_csv('/content/drive/MyDrive/Thesis/pos/data.csv')\n","df_ = pd.read_csv('/content/drive/MyDrive/Thesis/pos/data_p.csv')\n","dfc_ = pd.read_csv('/content/drive/MyDrive/Thesis/pos/data_c.csv')\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"mWXlQOWTTNtZ","executionInfo":{"status":"ok","timestamp":1629986487441,"user_tz":-60,"elapsed":185,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"3f8b20be-3dc6-4cbe-bec0-67af431918be"},"source":["data.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fullPath</th>\n","      <th>fileName</th>\n","      <th>View</th>\n","      <th>Side</th>\n","      <th>Status</th>\n","      <th>Age</th>\n","      <th>Density</th>\n","      <th>Tumour_Contour</th>\n","      <th>Tumour_Contour2</th>\n","      <th>Tumour_Contour3</th>\n","      <th>Tumour_Contour4</th>\n","      <th>Tumour_Contour5</th>\n","      <th>Tumour_Contour6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Benign\\0275\\C_0275_1.RIGHT_MLO.png</td>\n","      <td>C_0275_1.RIGHT_MLO.png</td>\n","      <td>MLO</td>\n","      <td>RIGHT</td>\n","      <td>Benign</td>\n","      <td>52.0</td>\n","      <td>2</td>\n","      <td>Benign\\0275\\C_0275_1.RIGHT_MLO_Mask.png</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cancer\\3063\\B_3063_1.RIGHT_CC.png</td>\n","      <td>B_3063_1.RIGHT_CC.png</td>\n","      <td>CC</td>\n","      <td>RIGHT</td>\n","      <td>Cancer</td>\n","      <td>55.0</td>\n","      <td>3</td>\n","      <td>Cancer\\3063\\B_3063_1.RIGHT_CC_Mask.png</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Normal\\0572\\A_0572_1.RIGHT_MLO.png</td>\n","      <td>A_0572_1.RIGHT_MLO.png</td>\n","      <td>MLO</td>\n","      <td>RIGHT</td>\n","      <td>Normal</td>\n","      <td>72.0</td>\n","      <td>4</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Normal\\0603\\A_0603_1.RIGHT_CC.png</td>\n","      <td>A_0603_1.RIGHT_CC.png</td>\n","      <td>CC</td>\n","      <td>RIGHT</td>\n","      <td>Normal</td>\n","      <td>76.0</td>\n","      <td>1</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Normal\\1990\\A_1990_1.RIGHT_MLO.png</td>\n","      <td>A_1990_1.RIGHT_MLO.png</td>\n","      <td>MLO</td>\n","      <td>RIGHT</td>\n","      <td>Normal</td>\n","      <td>66.0</td>\n","      <td>1</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             fullPath  ... Tumour_Contour6\n","0  Benign\\0275\\C_0275_1.RIGHT_MLO.png  ...             NaN\n","1   Cancer\\3063\\B_3063_1.RIGHT_CC.png  ...             NaN\n","2  Normal\\0572\\A_0572_1.RIGHT_MLO.png  ...             NaN\n","3   Normal\\0603\\A_0603_1.RIGHT_CC.png  ...             NaN\n","4  Normal\\1990\\A_1990_1.RIGHT_MLO.png  ...             NaN\n","\n","[5 rows x 13 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"vMXZMKj6wmAU","executionInfo":{"status":"ok","timestamp":1629986488016,"user_tz":-60,"elapsed":5,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"b368f7eb-42fd-4e52-fe4d-cb4fbd0d3137"},"source":["df_.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>mask</th>\n","      <th>label</th>\n","      <th>refrence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/0.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/0.jpg</td>\n","      <td>Benign</td>\n","      <td>Benign\\0275\\C_0275_1.RIGHT_MLO.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/1.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/1.jpg</td>\n","      <td>Cancer</td>\n","      <td>Cancer\\3063\\B_3063_1.RIGHT_CC.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/2.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/2.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\0572\\A_0572_1.RIGHT_MLO.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/3.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/3.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\0603\\A_0603_1.RIGHT_CC.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/4.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/4.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\1990\\A_1990_1.RIGHT_MLO.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       image  ...                            refrence\n","0  /content/drive/MyDrive/Thesis/pos/x/0.jpg  ...  Benign\\0275\\C_0275_1.RIGHT_MLO.png\n","1  /content/drive/MyDrive/Thesis/pos/x/1.jpg  ...   Cancer\\3063\\B_3063_1.RIGHT_CC.png\n","2  /content/drive/MyDrive/Thesis/pos/x/2.jpg  ...  Normal\\0572\\A_0572_1.RIGHT_MLO.png\n","3  /content/drive/MyDrive/Thesis/pos/x/3.jpg  ...   Normal\\0603\\A_0603_1.RIGHT_CC.png\n","4  /content/drive/MyDrive/Thesis/pos/x/4.jpg  ...  Normal\\1990\\A_1990_1.RIGHT_MLO.png\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"B8LRHKNHwpMu","executionInfo":{"status":"ok","timestamp":1629986779266,"user_tz":-60,"elapsed":490,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"4dc0ba1f-c5f8-47c0-b069-23a43f737374"},"source":["dfp = pd.read_csv('/content/drive/MyDrive/Thesis/pos/SCM2data.csv')\n","dfp.head()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>mask</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sx/0.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sy/0.jpg</td>\n","      <td>Benign</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sx/1.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sy/1.jpg</td>\n","      <td>Cancer</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sx/2.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sy/2.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sx/3.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sy/3.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sx/4.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/Sy/4.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        image  ...   label\n","0  /content/drive/MyDrive/Thesis/pos/Sx/0.jpg  ...  Benign\n","1  /content/drive/MyDrive/Thesis/pos/Sx/1.jpg  ...  Cancer\n","2  /content/drive/MyDrive/Thesis/pos/Sx/2.jpg  ...  Normal\n","3  /content/drive/MyDrive/Thesis/pos/Sx/3.jpg  ...  Normal\n","4  /content/drive/MyDrive/Thesis/pos/Sx/4.jpg  ...  Normal\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"D_eouxC2Ttgd","colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"status":"ok","timestamp":1629986848480,"user_tz":-60,"elapsed":1384,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"a8084287-807f-4ce7-8a93-6dfb78d13e5c"},"source":["img = cv2.imread(dfp['image'][3565])\n","print(img.shape)\n","plt.imshow(img)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["(3323, 2183, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fc0f42b7590>"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"01EiAooV9qlK","executionInfo":{"status":"ok","timestamp":1629989855787,"user_tz":-60,"elapsed":757,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"70a594c3-b214-44bd-b9ee-05cef6195ffb"},"source":["plt.imshow(cv2.resize(img, (400,400)))"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fc0f3f42490>"]},"metadata":{},"execution_count":38},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"5_vvxOQo0k5E","executionInfo":{"status":"error","timestamp":1629989401102,"user_tz":-60,"elapsed":1853,"user":{"displayName":"Paula Mpembe","photoUrl":"","userId":"04981801455453252449"}},"outputId":"d786edba-e2d1-4a6e-d016-1e36375a9fc2"},"source":["def expand2square(pil_img, background_color):\n","    width, height = pil_img.shape[:2]\n","    if width == height:\n","        return pil_img\n","    elif width > height:\n","        result = Image.new('RGB', (width, width), background_color)\n","        plt.imshow(result)\n","        \n","        result[0:s_img.shape[0], 0:s_img.shape[1]] = s_img\n","        # result.paste(pil_img, (0, 0, width, height))\n","        return result\n","    else:\n","        result = Image.new(pil_img.mode, (height, height), background_color)\n","        result.paste(pil_img, ((height - width) // 2, 0))\n","        return result\n","\n","\n","im_new = expand2square(img, (0, 0, 0)).resize((150, 150))\n","plt.imshow(im_new)"],"execution_count":36,"outputs":[{"output_type":"error","ename":"SystemError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-3196019e2010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mim_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand2square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-3196019e2010>\u001b[0m in \u001b[0;36mexpand2square\u001b[0;34m(pil_img, background_color)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpaste\u001b[0;34m(self, im, box, mask)\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0malpha_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemError\u001b[0m: new style getargs format but argument is not a tuple"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"iEg4Ykf4Vyd6"},"source":["# Enchecement"]},{"cell_type":"markdown","metadata":{"id":"_tE313OREOmL"},"source":["## cONSTRACT"]},{"cell_type":"code","metadata":{"cellView":"form","id":"1FTwjLg3ESUy"},"source":["#@title contrast_streching\n","def contrast_streching(img):\n","  img1 = img\n","  minmax_img = np.zeros((img1.shape[0],img1.shape[1]),dtype = 'uint8')\n","  for i in range(img1.shape[0]):\n","      for j in range(img1.shape[1]):\n","          minmax_img[i,j] = 255*(img1[i,j]-np.min(img1))/(np.max(img1)-np.min(img1))\n","  \n","  return minmax_img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rY5qvb78V2bh"},"source":["##  Morphological enhancement"]},{"cell_type":"code","metadata":{"cellView":"form","id":"tZJv2OGmV1pu"},"source":["#@title morphological_enhancement\n","def morphological_enhancement(imag):\n","  # imag = cv2.imread(path, 0)\n","  rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","  tophat = cv2.morphologyEx(imag, cv2.MORPH_TOPHAT, rectKernel)\n","  blackhat = cv2.morphologyEx(imag, cv2.MORPH_BLACKHAT, rectKernel)\n","  imag = imag + tophat - blackhat\n","\n","\n","  return imag"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bakVN_gd_YXY"},"source":["## *Clahe*"]},{"cell_type":"code","metadata":{"cellView":"form","id":"fAE_0Wg24lgc"},"source":["#@title clahe\n","def clahe(img, i):\n","\n","  clahe = cv2.createCLAHE(clipLimit=i, tileGridSize=( grid_l,  grid_w))\n","  cl1 = clahe.apply(img)\n","  return cl1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACEvRQcgbbKN"},"source":["# Image pre processing"]},{"cell_type":"markdown","metadata":{"id":"z93nF0ccovcw"},"source":["## Mask label"]},{"cell_type":"code","metadata":{"id":"qaZRfCZGou7i","cellView":"form"},"source":["#@title Mask_label\n","def mask_label(image):\n","  #grid = int((image.shape[0]+image.shape[1])/1000)*3\n","  \n","  # img_clahe = clahe(image)\n","  # img_md_n = ndimage.median_filter(image, 3)\n","  # img_md = cv2.dilate(image, None, iterations=3)\n","  img_md = ndimage.median_filter(image, 5)\n","  # img_md = cv2.GaussianBlur(img,(5,5),0)\n","\n","  left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]/2)])\n","  right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]/2):])\n","  # flip_n = left_nonzero\n","  n =  np.mean(image[:, 0:int(image.shape[1]/2)][image[:, 0:int(image.shape[1]/2)] > 0] )\n","  n_l = len(image[:, 0:int(image.shape[1]/2)][image[:, 0:int(image.shape[1]/2)] > n] )\n","  \n","  if(left_nonzero < right_nonzero):\n","    # flip_n = right_nonzero\n","    n =  np.mean(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > 0] )\n","    n_l = len(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > n] )\n","  #     print('wtf')\n","  #     flip = True\n","  #     image = cv2.flip(image, 1)\n","  # img_md = cv2.dilate(img_md, None, iterations=7)\n","  # image_eq = cv2.equalizeHist(img_md)\n","  # ret,thresh1 = cv2.threshold(image_eq, 0,255, cv2.THRESH_OTSU)\n","  # np.mean(cv2.countNonZero(image[:, 0:int(image.shape[1]/2)]))\n","  # np.where(np.nonzero(image[:, 0:int(image.shape[1]/2)]\n","\n","  ret,thresh  = cv2.threshold(img_md,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","  thresh = cv2.dilate(thresh, None, iterations=5)\n","  # contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","  # contours2, hier2 = cv2.findContours(thresh2,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","  # cnts = cv2.findContours(thresh1.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  # cnts = imutils.grab_contours(cnts)\n","  # contours,hierarchy = cv2.findContours(thresh2, 1, 2)\n","\n","  # find contours in thresholded image, then grab the largest\n","  # one\n","  cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n","    cv2.CHAIN_APPROX_SIMPLE)\n","  cnts = imutils.grab_contours(cnts)\n","  c = max(cnts, key=cv2.contourArea)\n","  # # x_m = image.shape[0] - image.shape[0]/5\n","  # # x_n = image.shape[0]/5\n","  # # y_m =  image.shape[1] - image.shape[1]/4.2\n","  # d_image = np.sqrt( (image.shape[0]**2) + (image.shape[1]**2) )\n","  # max1 = 0\n","  # # max2 = 0\n","  # for cnt in contours:\n","  #   if cv2.contourArea(cnt) > max1:\n","  #     max1 = cv2.contourArea(cnt)\n","  left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]/2)])\n","  right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]/2):])\n","  # flip_n = left_nonzero\n","  n =  np.mean(image[:, 0:int(image.shape[1]/2)][image[:, 0:int(image.shape[1]/2)] > 0] )\n","  n_l = len(image[:, 0:int(image.shape[1]/2)][image[:, 0:int(image.shape[1]/2)] > n] )\n","  s =  np.mean(thresh[:, 0:int(thresh.shape[1]/2)][thresh[:, 0:int(thresh.shape[1]/2)] > 0] )\n","  s_l = len(thresh[:, 0:int(thresh.shape[1]/2)][thresh[:, 0:int(thresh.shape[1]/2)] > s] )\n","  o =  np.mean(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > 0] )\n","  o_l = len(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > o] )\n","  if(left_nonzero < right_nonzero):\n","    # flip_n = right_nonzero\n","    n =  np.mean(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > 0] )\n","    n_l = len(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > n] )\n","    o =  np.mean(thresh[:, 0:int(thresh.shape[1]/2)][thresh[:, 0:int(thresh.shape[1]/2)] > 0] )\n","    o_l = len(thresh[:, 0:int(thresh.shape[1]/2)][thresh[:, 0:int(thresh.shape[1]/2)] > o] )\n","    s =  np.mean(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > 0] )\n","    s_l = len(image[:, int(image.shape[1]/2):][image[:, int(image.shape[1]/2):] > s] )\n","\n","  if s_l < o_l:\n","    for cnt in cnts: \n","      if cv2.contourArea(cnt) < cv2.contourArea(c):\n","        (x,y,w,h) = cv2.boundingRect(cnt)\n","        cv2.drawContours(img_md, [cnt], 0, 0,-1)\n","  elif cv2.countNonZero(thresh) < n_l*0.95:\n","    for cnt in cnts: \n","      if cv2.contourArea(cnt) < cv2.contourArea(c):\n","      #   hausdorff_sd = cv2.createHausdorffDistanceExtractor()\n","        (x,y,w,h) = cv2.boundingRect(cnt)\n","        cv2.drawContours(img_md, [cnt], 0, 0,-1)\n","\n","  else:\n","    for cnt in cnts: \n","      if cv2.contourArea(cnt) < cv2.contourArea(c):\n","      #   hausdorff_sd = cv2.createHausdorffDistanceExtractor()\n","        (x,y,w,h) = cv2.boundingRect(cnt)\n","        cv2.drawContours(thresh, [cnt], 0, 0,-1)\n","    img_md = image * thresh\n","      # cv2.(img_md,(x,y),(x+w,y+h),0,-1)\n","      # mask = np.zeros((img_md.shape), dtype=np.uint8)\n","      # cv2.fillPoly(img_md, (x,y),(x+w,y+h),0,-1)\n","      # img_md[np.where(mask\n","    # # 4. Calculate the distance between contours\n","    #   if hausdorff_sd.computeDistance(c, cnt) > d_image/5:\n","  # hausdorff_sd = cv2.createHausdorffDistanceExtractor()  \n","  # for x in range(img_md.shape[0]):\n","  #   for y in range(img_md.shape[1]):\n","  #           # for the given pixel at w,h, lets check its value against the threshold\n","            \n","  #     if hausdorff_sd.computeDistance((x,y,1,1) , cnt) > d_image/5:\n","  #       img_md[x, y] = 0\n","        # M = cv2.moments(cnt)\n","        # if M[\"m00\"] < 1:\n","        #   M[\"m00\"] =1\n","        # cX = int(M[\"m10\"] / M[\"m00\"])\n","        # cY = int(M[\"m01\"] / M[\"m00\"])\n","        # (x,y,w,h) = cv2.boundingRect(cnt)\n","        # if cX > x_m or cX < x_n or cY > y_m:\n","      # cv2.rectangle(img_md,(x,y),(x+w,y+h),0,-1)\n","\n","\n","  # for cnt in contours:\n","  #   if cv2.contourArea(cnt) > max2 and cv2.contourArea(cnt) < max1:\n","  #     max2 = cv2.contourArea(cnt)\n","  # x_m = image.shape[0] - image.shape[0]/5\n","  # x_n = image.shape[0]/5\n","  # y_m =  image.shape[1] - image.shape[1]/4.2\n","  # for cnt in contours: \n","  #   M = cv2.moments(cnt)\n","  #   if M[\"m00\"] < 1:\n","  #     M[\"m00\"] =1\n","  #   cX = int(M[\"m10\"] / M[\"m00\"])\n","  #   cY = int(M[\"m01\"] / M[\"m00\"])\n","  #   (x,y,w,h) = cv2.boundingRect(cnt)\n","  #   if cX > x_m or cX < x_n or cY > y_m:\n","  #     print(x_m, x_n, y_m)\n","  #     print()\n","  #     print(cX, cY)\n","  #     cv2.rectangle(thresh2,(x,y),(x+w,y+h),0,-1)\n","\n","  # max1 = 0\n","  # max2 = 0\n","  # for cnt in contours2:\n","  #   if cv2.contourArea(cnt) > max1:\n","  #     max1 = cv2.contourArea(cnt)\n","\n","  # for cnt in contours2:\n","  #   if cv2.contourArea(cnt) > max2 and cv2.contourArea(cnt) < max1:\n","  #     max2 = cv2.contourArea(cnt)\n","\n","  # for cnt in contours2:      \n","  #     if cv2.contourArea(cnt) < max2 * (max2/max1):\n","  #         (x,y,w,h) = cv2.boundingRect(cnt)\n","  #         cv2.rectangle(thresh2,(x,y),(x+w,y+h),0,-1)\n","\n","  \n","  # lab_val = 255\n","  # kernel_size = 15\n","  # _, mammo_binary = cv2.threshold(img_md, 0, maxval=255, type=cv2.THRESH_BINARY)\n","  # n_labels, img_labeled, lab_stats, _ = cv2.connectedComponentsWithStats(\n","  #     thresh1, connectivity=8, ltype=cv2.CV_32S)\n","  # largest_obj_lab = np.argmax(lab_stats[1:, 4]) + 1\n","  # largest_mask = np.zeros(thresh1.shape, dtype=np.uint8)\n","  # largest_mask[img_labeled == largest_obj_lab] = lab_val\n","  \n","    \n","\n","  # fig, axes = plt.subplots(1, 2, figsize=(15,10))\n","  # fig.tight_layout(pad=3.0)\n","  # axes[0].set_title('Image')\n","  # axes[0].imshow(img_md, cmap=pylab.cm.gray)\n","  # axes[0].axis('on')\n","  # axes[1].set_title('Mask')\n","  # axes[1].imshow(thresh, cmap=pylab.cm.gray)\n","  # axes[1].axis('on')\n","  # plt.show()\n","  # if flip == True:\n","  #   image = cv2.flip(image, 1)\n","\n","  # plt.imshow(img, 'gray')\n","\n","  return img_md"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lNXXuIMyez9W"},"source":["## Image flip"]},{"cell_type":"code","metadata":{"cellView":"form","id":"-f1kEIlmeiH0"},"source":["#@title right_orient_mammogram\n","\n","def right_orient_mammogram(image):\n","    flip = False\n","    left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]/2)])\n","    right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]/2):])\n","    \n","    if(left_nonzero < right_nonzero):\n","        # print('wtf')\n","        flip = True\n","        image = cv2.flip(image, 1)\n","    # print(flip)    \n","    return [image, flip]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AjMzyqfzqP1"},"source":["## Canny edge detection"]},{"cell_type":"code","metadata":{"cellView":"form","id":"vbh8_RuAzmMU"},"source":["#@title Apply_canny\n","def apply_canny(image):\n","    #img_eq = exposure.equalize_hist(image)\n","    canny_img = canny(image, 6)\n","    return sobel(canny_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UpO3eF0C0Hie"},"source":["## Hough transform"]},{"cell_type":"code","metadata":{"cellView":"form","id":"YC7QSQJf0MPQ"},"source":["#@title get_hough_lines\n","\n","def get_hough_lines(canny_img):\n","    h, theta, d = hough_line(canny_img)\n","    lines = list()\n","    # print('\\nAll hough lines')\n","    for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n","        # print(\"Angle: {:.2f}, Dist: {:.2f}\".format(np.degrees(angle), dist))\n","        x1 = 0\n","        y1 = (dist - x1 * np.cos(angle)) / np.sin(angle)\n","        x2 = canny_img.shape[1]\n","        y2 = (dist - x2 * np.cos(angle)) / np.sin(angle)\n","        lines.append({\n","            'dist': dist,\n","            'angle': np.degrees(angle),\n","            'point1': [x1, y1],\n","            'point2': [x2, y2]\n","        })\n","    \n","    return lines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-q1d1G90U73"},"source":["## Lines selection"]},{"cell_type":"code","metadata":{"cellView":"form","id":"GKmaOOag0Vhx"},"source":["#@title shortlist_lines\n","def shortlist_lines(lines, max_dist):\n","    MIN_ANGLE = 1\n","    MAX_ANGLE = 60\n","    MIN_DIST  = max_dist/100\n","    MAX_DIST  = max_dist*1.2\n","    \n","    shortlisted_lines = [x for x in lines if \n","                          (x['dist']>=abs(MIN_DIST)) &\n","                          (x['dist']<=abs(MAX_DIST)) &\n","                          (x['angle']>=abs(MIN_ANGLE)) &\n","                          (x['angle']<=abs(MAX_ANGLE))\n","                        ]\n","    # print('\\nShorlisted lines')\n","    # for i in shortlisted_lines:\n","    #     print(\"Angle: {:.2f}, Dist: {:.2f}\".format(i['angle'], i['dist']))\n","        \n","    return shortlisted_lines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SDDBEl_C1Kev"},"source":["## Pectoral region selection"]},{"cell_type":"code","metadata":{"cellView":"form","id":"ezTfIhIY1KyQ"},"source":["#@title remove_pectoral\n","def remove_pectoral(shortlisted_lines):\n","    shortlisted_lines.sort(key = lambda x: x['dist'])\n","    pectoral_line = shortlisted_lines[0].copy()\n","    # shortlisted_lines.pop(0)\n","    d = pectoral_line['dist']\n","    theta = np.radians(pectoral_line['angle'])\n","    \n","    x_intercept = d/np.cos(theta)\n","    y_intercept = d/np.sin(theta)\n","    \n","    return polygon([0, 0, y_intercept], [0, x_intercept, 0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c67yYV9S1eiZ"},"source":["## Image preprocessing process"]},{"cell_type":"code","metadata":{"id":"Sh6HC6skbk3_","cellView":"form"},"source":["#@title breast_snip\n","def breast_snip(image, plotting=False):\n","    # img = io.imread(filename)\n","    # img = color.rgb2gray(img)\n","    # plt.imshow(img, 'gray')\n","    image = mask_label(image)\n","    flip_array = right_orient_mammogram(image)\n","    image = flip_array[0]\n","    img = clahe(image.copy(), 2)\n","    canny_img = apply_canny(img)\n","    lines = get_hough_lines(canny_img)\n","    shortlisted_lines = shortlist_lines(lines, img.shape[0]/1.5)\n","\n","    # if plotting:\n","    #   fig, axes = plt.subplots(1, 4, figsize=(15,10))\n","    #   fig.tight_layout(pad=3.0)\n","    #   plt.xlim(0,img.shape[1])\n","    #   plt.ylim(img.shape[0])\n","      \n","      \n","    #   axes[0].set_title('Right-oriented mammogram')\n","    #   axes[0].imshow(img, cmap=pylab.cm.gray)\n","    #   axes[0].axis('on') \n","      \n","    #   axes[1].set_title('Hough Lines on Canny Edge img')\n","    #   axes[1].imshow(canny_img, cmap=pylab.cm.gray)\n","    #   axes[1].axis('on')\n","    #   axes[1].set_xlim(0,img.shape[1])\n","    #   axes[1].set_ylim(img.shape[0])\n","    #   for line in lines:\n","    #       axes[1].plot((line['point1'][0],line['point2'][0]), (line['point1'][1],line['point2'][1]), '-r')\n","          \n","    #   axes[2].set_title('Shortlisted Lines')\n","    #   axes[2].imshow(canny_img, cmap=pylab.cm.gray)\n","    #   axes[2].axis('on')\n","    #   axes[2].set_xlim(0,img.shape[1])\n","    #   axes[2].set_ylim(img.shape[0])\n","    #   for line in shortlisted_lines:\n","    #       axes[2].plot((line['point1'][0],line['point2'][0]), (line['point1'][1],line['point2'][1]), '-r')\n","    if size(shortlisted_lines) > 0:\n","      rr, cc = remove_pectoral(shortlisted_lines)\n","      try:\n","        image[rr, cc] = 0\n","      except:\n","        pass\n","    # if plotting:\n","    #   axes[3].set_title('Pectoral muscle removed')\n","    #   axes[3].imshow(img, cmap=pylab.cm.gray)\n","    #   axes[3].axis('on')\n","    #   plt.show()\n","    if flip_array[1]:\n","      # print('yes')\n","      image = cv2.flip(image, 1)\n","    image = clahe(image, 2)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CV0-LhNMBBSA"},"source":["# Train data"]},{"cell_type":"markdown","metadata":{"id":"q33D_g-RW0jV"},"source":["## path_checker"]},{"cell_type":"code","metadata":{"id":"5DEVOhArNWlY","cellView":"form"},"source":["#@title check_path\n","\n","def check_path(path):\n","  path = path.replace('\\\\', '/')\n","  try:\n","    # mask_ = imread(path,0)    \n","    im1 = Image.open(path)\n","    #rgb_im = mask_.convert('RGB')\n","    im1.save(path.replace('.png', '.jpg'))\n","\n","    return path.replace('.png', '.jpg')\n","  except :\n","  \n","    try:\n","      # mask_ = imread(path,0) \n","      path = path.replace('MASK', 'Mask')\n","      path = path.replace('.png', '.jpg')   \n","      im1 = Image.open(path)\n","\n","      return path\n","    except :\n","      try:\n","        # mask_ = imread(path,0) \n","        path = path.replace('Mask', 'MASK')\n","        path = path.replace('.png', '.jpg')   \n","        im1 = Image.open(path)\n","\n","        return path\n","      except :\n","        try:\n","          path = path.replace('.png', '.jpg')\n","          return path\n","        except:\n","          pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvxxutAvW6Rz"},"source":["## Adding image and mask to train data"]},{"cell_type":"code","metadata":{"id":"XzGOjcdABG9v"},"source":["#@title add_image_and_mask 1 channels contour mask\n","\n","def add_image_and_mask(img, data, index):\n","  n= index\n","  img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),mode='constant',  \n","                                  preserve_range=True)\n","  X_train[n] = img  #Fill empty X_train with values from img\n","  Main_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","  masks = []\n","\n","  if data['Tumour_Contour'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour'][i]))\n","  if data['Tumour_Contour2'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour2'][i]))\n","  if pd.isnull(data[\"Tumour_Contour3\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour3'][i]))\n","  if pd.isnull(data[\"Tumour_Contour4\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour4'][i]))\n","  if pd.isnull(data[\"Tumour_Contour5\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour5'][i]))\n","  if pd.isnull(data[\"Tumour_Contour6\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour6'][i]))\n","  for mask in masks:\n","    mask_ = imread(mask)\n","    mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n","                                  preserve_range=True), axis=-1)\n","    Main_mask = np.maximum(Main_mask, mask_) \n","\n","  # for mask in masks:\n","  #   mask.save(path)\n","  #   mask_ = imread(mask)\n","  #   mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n","  #                                 preserve_range=True), axis=-1)\n","  #   mask = np.maximum(Main_mask, mask_)  \n","            \n","  Y_train[n] = Main_mask "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0e2oIWwmyLY1"},"source":["## mask add"]},{"cell_type":"code","metadata":{"id":"PvYsHweocSA3"},"source":["last_mask = None\n","i_c=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9x0jd0jxvwX","colab":{"base_uri":"https://localhost:8080/","height":120},"cellView":"form","executionInfo":{"status":"ok","timestamp":1627634205526,"user_tz":-60,"elapsed":76,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"5e6f8e35-14fd-489a-d934-e361792d3c92"},"source":["#@title add_image_and_mask 3 channels mask\n","def mask_add(img, data, index):\n","  i = index\n","  global i_c\n","  global last_mask\n","  path = root + data[\"fullPath\"][i]#2499 2\n","  path = path.replace('\\\\', '/')\n","  path = path.replace('.png', '.jpg')\n","  img = cv2.imread(path, 0)\n","\n","  Main_mask = np.zeros((img.shape[0], img.shape[1], 1), dtype=np.uint8)\n","  masks = []\n","  if data['Tumour_Contour'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour'][i]))\n","  if data['Tumour_Contour2'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour2'][i]))\n","  if pd.isnull(data[\"Tumour_Contour3\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour3'][i]))\n","  if pd.isnull(data[\"Tumour_Contour4\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour4'][i]))\n","  if pd.isnull(data[\"Tumour_Contour5\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour5'][i]))\n","  if pd.isnull(data[\"Tumour_Contour6\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour6'][i]))\n","  for mask in masks:\n","    ini_img = img.copy()\n","    mask_ = imread(mask)\n","    last_mask = mask_.copy()\n","    img_mask = mask_.copy() \n","    ret,thresh = cv2.threshold(img_mask, 0,255, cv2.THRESH_OTSU)\n","    contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","    for cnt in contours:      \n","      (x,y,w,h) = cv2.boundingRect(cnt)\n","      # cv2.drawContours(mask_, [cnt], 0,(255, 0, 0),-1)\n","      cv2.drawContours(img_mask, [cnt], 0,(0, 0, 255),-1)\n","    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\n","    # ini_img = ini_img * mask_\n","    img_mask = cv2.resize(img_mask, (ini_img.shape[0], ini_img.shape[1]))\n","    ini_img[np.where(img_mask==0), -1] = 0\n","    save_c = \"/content/drive/MyDrive/Thesis/pos/x_/\" + str(i_c) + \".jpg\"\n","    cv2.imwrite(save_c, ini_img[y:y+h,x:x+w])\n","    List = [save_c, data['Status'][i]]\n","    dfc_.loc[i_c] = List\n","    i_c = i_c+1\n","    mask_ = np.expand_dims(resize(mask_, (img.shape[0], img.shape[1]), mode='constant',  \n","                                preserve_range=True), axis=-1)\n","    Main_mask = np.maximum(Main_mask, mask_)\n","\n","  if len(masks) <1:\n","    # if last_mask == None:\n","    #   path_ = root + data['Tumour_Contour'][0]\n","    #   path_ = path.replace('\\\\', '/')\n","    #   last_mask = Image.open(path_)\n","    # ini_img = img.copy()\n","    img_mask = last_mask.copy()\n","    ret,thresh = cv2.threshold(img_mask, 0,255, cv2.THRESH_OTSU)\n","    contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)   \n","    for cnt in contours:      \n","      (x,y,w,h) = cv2.boundingRect(cnt)\n","      cv2.drawContours(img_mask, [cnt], 0,(0, 0, 255),-1)\n","    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\n","    # ini_img = ini_img * mask_\n","    img_mask = cv2.resize(img_mask, (img.shape[0], img.shape[1]))\n","    plt,imshow(img_mask)\n","    img[np.where(img_mask==0), -1] = 0\n","    save_c = \"/content/drive/MyDrive/Thesis/pos/x_/\" + str(i_c) + \".jpg\"\n","    # if ini_img.em\n","    cv2.imwrite(save_c, img[y:y+h,x:x+w])\n","    List = [save_c, data['Status'][i]]\n","    dfc_.loc[i_c] = List\n","    i_c = i_c+1\n","\n","  save_m = \"/content/drive/MyDrive/Thesis/pos/y/\" + str(index) + \".jpg\"\n","  cv2.imwrite(save_m, np.squeeze(Main_mask))\n","'''\n","\n","    mask_ = imread(mask)\n","    mask_ = np.expand_dims(resize(mask_, (img.shape[0], img.shape[1]), mode='constant',  \n","                                  preserve_range=True), axis=-1)\n","    if data[\"Status\"][i] == 'Cancer':\n","      Main_mask[:,:,2] = np.maximum(Main_mask[:,:,2], mask_[:,:,0])\n","      Main_mask[:,:,2][np.nonzero(Main_mask[:,:,2])] = 255\n","    if data[\"Status\"][i] == 'Benign':\n","      Main_mask[:,:,0] = np.maximum(Main_mask[:,:,0], mask_[:,:,0])\n","      Main_mask[:,:,0][np.nonzero(Main_mask[:,:,0])] = 127\n","  # plt.imsave(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", np.squeeze(Main_mask))\n","  save_m = \"/content/drive/MyDrive/Thesis/pos/y/\" + str(i) + \".jpg\"\n","  cv2.imwrite(save_m, np.squeeze(Main_mask))\n","  # img_mask = i_mask.save(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", 'jpeg')\n","  img_mask = cv2.imread(save_m, cv2.IMREAD_COLOR)\n","  plt.imshow(img_mask,)\n","  i_mask = cv2.cvtColor(img_mask, cv2.COLOR_BGR2GRAY)\n","  ret,thresh = cv2.threshold(i_mask, 0,255, cv2.THRESH_OTSU)\n","\n","  # contours,_ = cv2.findContours(img, cv2.RETR_LIST, cv2.cv.CV_CHAIN_APPROX_NONE)\n","  contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","  # print(len(contours))\n","  if data[\"Status\"][i] == 'Cancer':\n","    for cnt in contours:      \n","      (x,y,w,h) = cv2.boundingRect(cnt)\n","      cv2.drawContours(img_mask, [cnt], 0,(255, 0, 0),-1)\n","    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\n","    img_mask[:,:,0][np.nonzero(Main_mask[:,:,2])] = 127\n","    img_mask[:,:,2][np.nonzero(Main_mask[:,:,2])] = 255\n","  if data[\"Status\"][i] == 'Benign':\n","    for cnt in contours:      \n","      (x,y,w,h) = cv2.boundingRect(cnt)\n","      cv2.drawContours(img_mask, [cnt], 0,(0, 0, 127),-1)\n","    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\n","    img_mask[:,:,2][np.nonzero(Main_mask[:,:,0])] = 255\n","    img_mask[:,:,0][np.nonzero(Main_mask[:,:,0])] = 127\n","  # plt.imshow(thresh, 'gray')\n","  # ar_img = np.expand_dims(resize(thresh, (img.shape[0], img.shape[1]), mode='constant',  \n","  #                                 preserve_range=True), axis=-1)\n","  # Main_mask[:,:,2] = Main_mask[:,:,2] + ar_img[:,:,0]\n","  # Main_mask[:,:,1] = Main_mask[:,:,1] + ar_img[:,:,0]\n","  cv2.imwrite(save_m, img_mask)\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n\\n    mask_ = imread(mask)\\n    mask_ = np.expand_dims(resize(mask_, (img.shape[0], img.shape[1]), mode=\\'constant\\',  \\n                                  preserve_range=True), axis=-1)\\n    if data[\"Status\"][i] == \\'Cancer\\':\\n      Main_mask[:,:,2] = np.maximum(Main_mask[:,:,2], mask_[:,:,0])\\n      Main_mask[:,:,2][np.nonzero(Main_mask[:,:,2])] = 255\\n    if data[\"Status\"][i] == \\'Benign\\':\\n      Main_mask[:,:,0] = np.maximum(Main_mask[:,:,0], mask_[:,:,0])\\n      Main_mask[:,:,0][np.nonzero(Main_mask[:,:,0])] = 127\\n  # plt.imsave(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", np.squeeze(Main_mask))\\n  save_m = \"/content/drive/MyDrive/Thesis/pos/y/\" + str(i) + \".jpg\"\\n  cv2.imwrite(save_m, np.squeeze(Main_mask))\\n  # img_mask = i_mask.save(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", \\'jpeg\\')\\n  img_mask = cv2.imread(save_m, cv2.IMREAD_COLOR)\\n  plt.imshow(img_mask,)\\n  i_mask = cv2.cvtColor(img_mask, cv2.COLOR_BGR2GRAY)\\n  ret,thresh = cv2.threshold(i_mask, 0,255, cv2.THRESH_OTSU)\\n\\n  # contours,_ = cv2.findContours(img, cv2.RETR_LIST, cv2.cv.CV_CHAIN_APPROX_NONE)\\n  contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\\n  # print(len(contours))\\n  if data[\"Status\"][i] == \\'Cancer\\':\\n    for cnt in contours:      \\n      (x,y,w,h) = cv2.boundingRect(cnt)\\n      cv2.drawContours(img_mask, [cnt], 0,(255, 0, 0),-1)\\n    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\\n    img_mask[:,:,0][np.nonzero(Main_mask[:,:,2])] = 127\\n    img_mask[:,:,2][np.nonzero(Main_mask[:,:,2])] = 255\\n  if data[\"Status\"][i] == \\'Benign\\':\\n    for cnt in contours:      \\n      (x,y,w,h) = cv2.boundingRect(cnt)\\n      cv2.drawContours(img_mask, [cnt], 0,(0, 0, 127),-1)\\n    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\\n    img_mask[:,:,2][np.nonzero(Main_mask[:,:,0])] = 255\\n    img_mask[:,:,0][np.nonzero(Main_mask[:,:,0])] = 127\\n  # plt.imshow(thresh, \\'gray\\')\\n  # ar_img = np.expand_dims(resize(thresh, (img.shape[0], img.shape[1]), mode=\\'constant\\',  \\n  #                                 preserve_range=True), axis=-1)\\n  # Main_mask[:,:,2] = Main_mask[:,:,2] + ar_img[:,:,0]\\n  # Main_mask[:,:,1] = Main_mask[:,:,1] + ar_img[:,:,0]\\n  cv2.imwrite(save_m, img_mask)\\n'"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"cellView":"form","id":"wIKC3auMi1NG"},"source":["#@title SSim\n","\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import mean_squared_error\n","\n","\n","\n","def ssim_mse(img, img_const):\n","\n","\n","  mse_const = mean_squared_error(img, img_const)\n","  ssim_const = ssim(img, img_const,\n","                    data_range=img_const.max() - img_const.min())\n","\n","  return mse_const, ssim_const"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7f1nC1JkfG7"},"source":["\n","# PRE P"]},{"cell_type":"code","metadata":{"id":"tLpvowbXkhuH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dxXue3jlNjT"},"source":["\n","def select_largest_obj(img_bin, lab_val=255, fill_holes=True, \n","                       smooth_boundary=True, kernel_size=15):\n","    '''Select the largest object from a binary image and optionally\n","    fill holes inside it and smooth its boundary.\n","    Args:\n","        img_bin(2D array): 2D numpy array of binary image.\n","        lab_val([int]): integer value used for the label of the largest \n","                        object. Default is 255.\n","        fill_holes([boolean]): whether fill the holes inside the largest \n","                               object or not. Default is false.\n","        smooth_boundary([boolean]): whether smooth the boundary of the \n","                                    largest object using morphological \n","                                    opening or not. Default is false.\n","        kernel_size([int]): the size of the kernel used for morphological \n","                            operation.\n","    '''\n","    \n","    n_labels, img_labeled, lab_stats, _ = cv2.connectedComponentsWithStats(\n","        img_bin, connectivity=8, ltype=cv2.CV_32S)\n","    largest_obj_lab = np.argmax(lab_stats[1:, 4]) + 1\n","    largest_mask = np.zeros(img_bin.shape, dtype=np.uint8)\n","    largest_mask[img_labeled == largest_obj_lab] = lab_val\n","    if fill_holes:\n","        bkg_locs = where(img_labeled == 0)\n","        bkg_seed = (bkg_locs[0][0], bkg_locs[1][0])\n","        img_floodfill = largest_mask.copy()\n","        h_, w_ = largest_mask.shape\n","        mask_ = np.zeros((h_ + 2, w_ + 2), dtype=np.uint8)\n","        cv2.floodFill(img_floodfill, mask_, seedPoint=bkg_seed, newVal=lab_val)\n","        holes_mask = cv2.bitwise_not(img_floodfill)  # mask of the holes.\n","        largest_mask = largest_mask + holes_mask\n","    if smooth_boundary:\n","        kernel_ = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n","        largest_mask = cv2.morphologyEx(largest_mask, cv2.MORPH_OPEN, kernel_)\n","    \n","        \n","    return largest_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pi3O9xYouLsu"},"source":["def pect_mask(img):\n","  pect_high_inten_thres = 200  # <<= para to tune!\n","  _, pect_binary_thres = cv2.threshold(img, pect_high_inten_thres, \n","                                      maxval=255, type=cv2.THRESH_BINARY)\n","\n","  # Markers image for watershed algo.\n","  pect_marker_img = np.zeros(pect_binary_thres.shape, dtype=np.int32)\n","  # Sure foreground.\n","  pect_mask_init = select_largest_obj(pect_binary_thres, lab_val=255, \n","                                      fill_holes=True, smooth_boundary=False)\n","\n","  # Markers image for watershed algo.\n","  pect_marker_img = np.zeros(pect_binary_thres.shape, dtype=np.int32)\n","  # Sure foreground.\n","  pect_mask_init = select_largest_obj(pect_binary_thres, lab_val=255, \n","                                      fill_holes=True, smooth_boundary=False)\n","  kernel_ = ones((3, 3), dtype=np.uint8)  # <<= para to tune!\n","  n_erosions = 7  # <<= para to tune!\n","  pect_mask_eroded = cv2.erode(pect_mask_init, kernel_, iterations=n_erosions)\n","  pect_marker_img[pect_mask_eroded > 0] = 255\n","  # Sure background - breast.\n","  n_dilations = 7  # <<= para to tune!\n","  pect_mask_dilated = cv2.dilate(pect_mask_init, kernel_, iterations=n_dilations)\n","  pect_marker_img[pect_mask_dilated == 0] = 128\n","  # Sure background - background.\n","  pect_marker_img[mammo_breast_mask == 0] = 64\n","\n","  return pect_marker_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tBX5vgKbyUTs"},"source":["def final_mam(mammo_breast_equ, pect_marker_img):\n","  mammo_breast_equ_3c = cv2.cvtColor(mammo_breast_equ, cv2.COLOR_GRAY2BGR)\n","  cv2.watershed(mammo_breast_equ_3c, pect_marker_img)\n","  pect_mask_watershed = pect_marker_img.copy()\n","  mammo_breast_equ_3c[pect_mask_watershed == -1] = (0, 0, 255)\n","  pect_mask_watershed[pect_mask_watershed == -1] = 0\n","  breast_only_mask = pect_mask_watershed.astype(np.uint8)\n","  breast_only_mask[breast_only_mask != 128] = 0\n","  breast_only_mask[breast_only_mask == 128] = 255\n","  kn_size = 25  # <<= para to tune!\n","  kernel_ = np.ones((kn_size, kn_size), dtype=np.uint8)\n","  breast_only_mask_smo = cv2.morphologyEx(breast_only_mask, cv2.MORPH_OPEN, kernel_)\n","  mammo_breast_only = cv2.bitwise_and(mammo_breast_equ, breast_only_mask_smo)\n","  return mammo_breast_only"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5wgH5SIbaVSK"},"source":["# New section"]},{"cell_type":"code","metadata":{"id":"aS4xEsOZaYkI"},"source":["# columns = ['image', 'mask', 'label', 'refrence']\n","# df_ = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"JODF2NR5bYz4","executionInfo":{"status":"ok","timestamp":1627634205537,"user_tz":-60,"elapsed":73,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"2b58d9bc-87c8-4f1e-9fde-c13e00125b60"},"source":["df_.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>mask</th>\n","      <th>label</th>\n","      <th>refrence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/0.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/0.jpg</td>\n","      <td>Benign</td>\n","      <td>Benign\\0275\\C_0275_1.RIGHT_MLO.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/1.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/1.jpg</td>\n","      <td>Cancer</td>\n","      <td>Cancer\\3063\\B_3063_1.RIGHT_CC.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/2.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/2.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\0572\\A_0572_1.RIGHT_MLO.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/3.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/3.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\0603\\A_0603_1.RIGHT_CC.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x/4.jpg</td>\n","      <td>/content/drive/MyDrive/Thesis/pos/y/4.jpg</td>\n","      <td>Normal</td>\n","      <td>Normal\\1990\\A_1990_1.RIGHT_MLO.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       image  ...                            refrence\n","0  /content/drive/MyDrive/Thesis/pos/x/0.jpg  ...  Benign\\0275\\C_0275_1.RIGHT_MLO.png\n","1  /content/drive/MyDrive/Thesis/pos/x/1.jpg  ...   Cancer\\3063\\B_3063_1.RIGHT_CC.png\n","2  /content/drive/MyDrive/Thesis/pos/x/2.jpg  ...  Normal\\0572\\A_0572_1.RIGHT_MLO.png\n","3  /content/drive/MyDrive/Thesis/pos/x/3.jpg  ...   Normal\\0603\\A_0603_1.RIGHT_CC.png\n","4  /content/drive/MyDrive/Thesis/pos/x/4.jpg  ...  Normal\\1990\\A_1990_1.RIGHT_MLO.png\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"h5qCeQ1d8KVi"},"source":["# for i in range(0, len(data)):\n","#     save_i = '/content/drive/MyDrive/Thesis/pos/x/' + str(i) \\\n","#         + '.jpg'\n","#     save_m = '/content/drive/MyDrive/Thesis/pos/y/' + str(i) \\\n","#         + '.jpg'\n","#     List = [save_i, save_m, data['Status'][i], data['fullPath'][i]]\n","#     df_.loc[i] = List\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"7iNM1XlpHEXA","executionInfo":{"status":"ok","timestamp":1627634205540,"user_tz":-60,"elapsed":70,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"e4888bae-b060-4c58-b2ff-68dae1690a14"},"source":["dfc_.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/0.jpg</td>\n","      <td>Benign</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/1.jpg</td>\n","      <td>Cancer</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/2.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/3.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/4.jpg</td>\n","      <td>Normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        image   label\n","0  /content/drive/MyDrive/Thesis/pos/x_/0.jpg  Benign\n","1  /content/drive/MyDrive/Thesis/pos/x_/1.jpg  Cancer\n","2  /content/drive/MyDrive/Thesis/pos/x_/2.jpg  Normal\n","3  /content/drive/MyDrive/Thesis/pos/x_/3.jpg  Normal\n","4  /content/drive/MyDrive/Thesis/pos/x_/4.jpg  Normal"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"tRRw64Ai_gzI"},"source":["# df_.to_csv('/content/drive/MyDrive/Thesis/pos/data_p.csv', index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6tkplKSbKjs"},"source":["# columns = ['image', 'label']\n","# dfc_ = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DhFDmhLZIYN","cellView":"form"},"source":["#@title PSNR\n","\n","from math import log10, sqrt\n","import cv2\n","import numpy as np\n","  \n","def PSNR(original, compressed):\n","    mse = np.mean((original - compressed) ** 2)\n","    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n","                  # Therefore PSNR have no importance.\n","        return 100\n","    max_pixel = 255.0\n","    psnr = 20 * log10(max_pixel / sqrt(mse))\n","    return psnr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fzgi2iw0U6U3"},"source":["# %cd /content/drive/MyDrive/Thesis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDuFRP9xT9EM"},"source":["# Clone the git repo.\n","# !git clone https://github.com/cjlin1/libsvm.git\n","# Build the library.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZyJkRAlWEru"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5wdPNw8UgAIa"},"source":["# Action pre processing"]},{"cell_type":"code","metadata":{"cellView":"form","id":"GFbxA-gdpKvd"},"source":["#@title Dataset mean and std\n","def dataset_mean(filepath):\n","    # filepath = r\"C:/Users/xxx/images/\"  # Dataset directory\n","    pathDir = os.listdir(filepath)  # Images in dataset directory\n","    num = len(pathDir)  # Here (512512) is the size of each image\n","\n","    print(\"Computing mean...\")\n","    data_mean = 0.\n","    data_std = 0.\n","    for idx in range(len(pathDir)):\n","        filename = pathDir[idx]\n","        img = Image.open(os.path.join(filepath, filename)).convert('L')\n","        img = np.array(img) / 255.0\n","        data_mean += np.mean(img)\n","        data_std += np.std(img)  # Take all the data of the first dimension in the three-dimensional matrix\n","\t\t# As the use of gray images, so calculate a channel on it\n","    data_mean = data_mean / num\n","    data_std = data_std / num\n","\n","    # print(\"Computing var...\")\n","    # data_std = 0.\n","    # for idx in range(len(pathDir)):\n","    #     filename = pathDir[idx]\n","    #     img = Image.open(os.path.join(filepath, filename)).convert('L').resize((512, 512))\n","    #     img = np.array(img) / 255.0\n","    #     data_std += np.std(img)\n","\n","    # data_std = data_std / num\n","    print(\"mean:{}\".format(data_mean))\n","    print(\"std:{}\".format(data_std))\n","    return data_mean, data_std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mW_cdx-mpfWI","executionInfo":{"status":"ok","timestamp":1627639128384,"user_tz":-60,"elapsed":16812,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"72a5ce29-e69e-4b1d-928d-565b1eb61674"},"source":["dfc_mean = dataset_mean(\"/content/drive/MyDrive/Thesis/pos/x_\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Computing mean...\n","mean:0.36841838445639874\n","std:0.07403414585441105\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cubYlkKto2T","executionInfo":{"status":"ok","timestamp":1627639441375,"user_tz":-60,"elapsed":313016,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"108bd223-29d4-45b2-f786-4f0c9e17bd0e"},"source":["df_mean = dataset_mean(\"/content/drive/MyDrive/Thesis/pos/x\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Computing mean...\n","mean:0.22149166536827739\n","std:0.24947701339647832\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBzc5FWDzz7Q"},"source":["df_mean = dataset_mean(\"/content/drive/MyDrive/Thesis/pos/x\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3qECTXMebqQ"},"source":["columns = ['image']\n","bu = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6NEv5qSxxHZ"},"source":["i=1\n","\n","# # img_mask = i_mask.save(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", 'jpeg')\n","# img_mask = cv2.imread(\"/content/drive/MyDrive/Thesis/pos/y/0.jpg\", cv2.IMREAD_COLOR)\n","# plt.imshow(img_mask,)\n","  # for cnt in contours:      \n","  #   (x,y,w,h) = cv2.boundingRect(cnt)\n","  #   cv2.rectangle(np.squeeze(Main_mask),(x,y),(x+w,y+h),255,-1)\n","# plt.imshow(np.squeeze(Main_mask), 'gray' )\n","# max(np.unique(Main_mask))\n","# for c in contours:\n","#     temp = np.zeros_like(grayImg)\n","#     cv2.drawContours(temp, [c], 0, (255,255,255), -1)\n","#     if np.mean(grayImg[temp==255]) > intensityPer*255:\n","#         pass # here your code"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kXhjEM7uxPJ"},"source":["\"/content/drive/MyDrive/Thesis/pos/y/\" + str(i) + \".jpg\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"yJZvPDDldSUI","executionInfo":{"status":"ok","timestamp":1627529936773,"user_tz":-60,"elapsed":652,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"f2604f8b-d020-4043-c9b8-80125652fe9d"},"source":["i=1\n","path = root + data[\"fullPath\"][i]#2499 2 205\n","path = path.replace('\\\\', '/')\n","path = path.replace('.png', '.jpg')\n","img = cv2.imread(path, 0)\n","ini_img = img.copy()\n","grid_l = int(img.shape[0] * img.shape[0] / img.shape[1] / 600)\n","grid_w = int(img.shape[1] * img.shape[1] / img.shape[0] / 200)\n","if grid_l < 2:\n","  grid_l = 2\n","if grid_w < 2:\n","  grid_w = 2\n","# img = breast_snip(path, True)\n","# img = morphological_enhancement(img)\n","#   img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),mode='constant',  \n","#                                 preserve_range=True)\n","# img = contrast_streching(img)\n","# plt.imshow(img, cmap='gray')\n","\n","\n","# X_train[n] = img  #Fill empty X_train with values from img\n","Main_mask = np.zeros((ini_img.shape[0], ini_img.shape[1], 1), dtype=np.bool)\n","masks = []\n","rect = []\n","if data['Tumour_Contour'][i] != '-':\n","  masks.append(check_path(root + data['Tumour_Contour'][i]))\n","if data['Tumour_Contour2'][i] != '-':\n","  masks.append(check_path(root + data['Tumour_Contour2'][i]))\n","if pd.isnull(data[\"Tumour_Contour3\"][i]) == False:\n","  masks.append(check_path(root + data['Tumour_Contour3'][i]))\n","if pd.isnull(data[\"Tumour_Contour4\"][i]) == False:\n","  masks.append(check_path(root + data['Tumour_Contour4'][i]))\n","if pd.isnull(data[\"Tumour_Contour5\"][i]) == False:\n","  masks.append(check_path(root + data['Tumour_Contour5'][i]))\n","if pd.isnull(data[\"Tumour_Contour6\"][i]) == False:\n","  masks.append(check_path(root + data['Tumour_Contour6'][i]))\n","for mask in masks:\n","  mask_ = imread(mask)\n","  # mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',   preserve_range=True), axis=-1)\n","\n","  ret,thresh = cv2.threshold(mask_, 0,255, cv2.THRESH_OTSU)\n","  contours, hier = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)                   \n","  if data[\"Status\"][i] != 'Normal':\n","    for cnt in contours:      \n","      (x,y,w,h) = cv2.boundingRect(cnt)\n","      cv2.drawContours(mask_, [cnt], 0,(255, 0, 0),-1)\n","      \n","    # print( np.where(np.nonzero(np.squeeze(Main_mask))))\n","    # ini_img = ini_img * mask_\n","    ini_img[np.where(mask_==0)] = 0\n","    cv2.rectangle(ini_img,(x,y),(x+w,y+h),(255,0,0),2)\n","    xC = (x + x+w) / 2\n","    yC= (y + y+h) / 2\n","    print(w, h)\n","    print(xC, yC)\n","    \n","    plt.imshow(ini_img[int(y*0.99):int(1.01*(y+h)),int(x*0.99):int(1.01*(x+w))], 'gray')\n","    # img_mask[:,:,0][np.nonzero(Main_mask[:,:,2])] = 127\n","    # img_mask[:,:,2][np.nonzero(Main_mask[:,:,2])] = 255\n","  \n","  # Main_mask = np.maximum(Main_mask, mask_) \n","\n"," \n","\n","  # print(len(contours))\n","#image = breast_snip(img)\n","# mammo_med_blurred = cv2.medianBlur(img, 3)\n","# global_threshold = 0  # from Nagi thesis. <<= para to tune!\n","# _, mammo_binary = cv2.threshold(mammo_med_blurred, global_threshold, \n","#                                  maxval=255, type=cv2.THRESH_BINARY)\n","# mammo_breast_mask = select_largest_obj(mammo_binary)  # <<= para to tune!\n","# img = cv2.bitwise_and(image, mammo_breast_mask)\n","\n","\n","# img = cv2.equalizeHist(img)\n","# pect = pect_mask(img)\n","# img = final_mam(img, pect)\n","# fig,axes = subplots(1, 1)\n","# fig.set_size_inches([12, 9])\n","# #res = hstack((mammo_med_blurred, mammo_binary))\n","# axes[0].imshow(image, cmap='gray')\n","# axes[1].imshow(image, cmap='gray')\n","\n","print(ini_img[y:y+h,x:x+w].shape[0], ini_img[y:y+h,x:x+w].shape[1])\n","print(grid_l, grid_w)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285 250\n","1165.5 1313.0\n","250 285\n","6 4\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Zy3lTmI9oS-P"},"source":["len(df_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"H7YMutqGoZUb","executionInfo":{"status":"error","timestamp":1627642371497,"user_tz":-60,"elapsed":1853259,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"f1e148bc-483b-4837-f772-cb66e7c0696a"},"source":["# import imquality.brisque as brisque\n","# import csv\n","# n = len(data)\n","# b = len(df_)+1\n","# n_bri = 0\n","# bri=0\n","# psnr = 0\n","# mse_ = 0\n","# ssim_ = 0\n","\n","data_mean =0.\n","data_std =0.\n","for i in range(0, len(data)):\n","    path = root + data['fullPath'][i]  # 2499\n","    path = path.replace('\\\\', '/')\n","    path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    img = cv2.imread(path, 0)\n","    img = np.array(img) / 255.0\n","    data_mean += np.mean(img)\n","    data_std += np.std(img)\n","data_mean = data_mean / num\n","data_std = data_std / num\n","\n","# print(\"Computing var...\")\n","# data_std = 0.\n","# for idx in range(len(pathDir)):\n","#     filename = pathDir[idx]\n","#     img = Image.open(os.path.join(filepath, filename)).convert('L').resize((512, 512))\n","#     img = np.array(img) / 255.0\n","#     data_std += np.std(img)\n","\n","# data_std = data_std / num\n","print(\"mean:{}\".format(data_mean))\n","print(\"std:{}\".format(data_std))\n","\n","# ini_img = img.copy()\n","# grid_l = int(img.shape[0] * img.shape[0] / img.shape[1] / 600)\n","# grid_w = int(img.shape[1] * img.shape[1] / img.shape[0] / 200)\n","# if grid_l < 2:\n","#     grid_l = 2\n","# if grid_w < 2:\n","#     grid_w = 2\n","# image = breast_snip(img)\n","# n_bri = n_bri + brisque.score(ini_img)\n","# bri = bri + brisque.score(image.copy())\n","# psnr = psnr + PSNR(ini_img, image.copy())\n","# mse_ = mse_ + ssim_mse(ini_img, image.copy())[0]\n","# ssim_ = ssim_ + ssim_mse(ini_img, image.copy())[1]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-d67127d5155c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdata_mean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdata_std\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdata_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mean\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mdata_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_std\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num' is not defined"]}]},{"cell_type":"code","metadata":{"id":"6fxLUws5yjAJ"},"source":["columns = ['image']\n","Udf = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU1aNoumdQIp"},"source":["import cv2\n","import numpy as np\n","for i in range(0, len(data)):\n","    path = root + data['fullPath'][i]  # 2499\n","    path = path.replace('\\\\', '/')\n","    path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    img = cv2.imread(path)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img2 = np.zeros_like(img)\n","    img2[:,:,0] = gray\n","    img2[:,:,1] = gray\n","    img2[:,:,2] = gray\n","    cv2.imwrite('/content/drive/MyDrive/Thesis/pos/3ux/' + str(i) + '.jpg', img2)\n","    # df_.loc[i] = '/content/drive/MyDrive/Thesis/pos/3ux/' + str(i) + '.jpg'   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gXDbNnShyq4S"},"source":["for i in range(0, len(data)):\n","\n","    Udf.loc[i]  = '/content/drive/MyDrive/Thesis/pos/3ux/' + str(i) + '.jpg'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlQi6nx3imIO"},"source":["import cv2\n","import numpy as np\n","for i in range(0, len(dfc_)):\n","    # path = root + data['fullPath'][i]  # 2499\n","    # path = path.replace('\\\\', '/')\n","    # path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    img = cv2.imread(dfc_['image'][i])\n","    img = resize(img, (img.shape[0], IMG_WIDTH, IMG_CHANNELS),mode='constant',   preserve_range=True)\n","    cv2.imwrite('/content/drive/MyDrive/Thesis/pos/3x_/' + str(i) + '.jpg', img2)\n","    # df_.loc[i] = '/content/drive/MyDrive/Thesis/pos/3x_/' + str(i) + '.jpg' "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RH8SXYHpuXuN"},"source":["columns = ['image', 'label']\n","dfc3_ = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3MmhjKTufHT"},"source":["import cv2\n","import numpy as np\n","for i in range(0, len(dfc_)):\n","    # path = root + data['fullPath'][i]  # 2499\n","    # path = path.replace('\\\\', '/')\n","    # path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    dfc3_.loc[i] = ['/content/drive/MyDrive/Thesis/pos/3x_/' + str(i) + '.jpg', dfc_['label']]\n","     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFDd5_VBnXWO"},"source":["columns = ['image', 'mask', 'label']\n","df3_ = pd.DataFrame(columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"tt0n_p_DkSvX","executionInfo":{"status":"error","timestamp":1627671611699,"user_tz":-60,"elapsed":518892,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"05fa3777-6883-429b-ef9c-9033970a97a8"},"source":["import cv2\n","import numpy as np\n","for i in range(0, len(df_)):\n","    # path = root + data['fullPath'][i]  # 2499\n","    # path = path.replace('\\\\', '/')\n","    # path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    # try:\n","    img = cv2.imread(df_['image'][i])\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # except:\n","    #   path = root + data['fullPath'][i]  # 2499\n","    #   path = path.replace('\\\\', '/')\n","    #   path = path.replace('.png', '.jpg')\n","    #   img = cv2.imread(path)\n","    #   img = breast_snip(img)\n","    #   gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img2 = np.zeros_like(img)\n","    img2[:,:,0] = gray\n","    img2[:,:,1] = gray\n","    img2[:,:,2] = gray\n","    cv2.imwrite('/content/drive/MyDrive/Thesis/pos/3x/' + str(i) + '.jpg', img2)\n","    # df_.loc[i] = '/content/drive/MyDrive/Thesis/pos/3x/' + str(i) + '.jpg' "],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-4849a6cd439a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Thesis/pos/3x/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# df_.loc[i] = '/content/drive/MyDrive/Thesis/pos/3x/' + str(i) + '.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"_VFSkSXzydw0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpIpU9oIMeLO","executionInfo":{"status":"ok","timestamp":1627644931109,"user_tz":-60,"elapsed":503,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"b21e6b69-0ce6-4935-9125-bc686eda7faf"},"source":["data_mean = data_mean / len(data)\n","data_std = data_std / len(data)\n","print(\"mean:{}\".format(data_mean))\n","print(\"std:{}\".format(data_std))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean:0.21527170462444334\n","std:0.21957276726846967\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnqfc5xFzJhZ","executionInfo":{"status":"ok","timestamp":1627526338258,"user_tz":-60,"elapsed":307,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"a1ad01b7-3894-437c-84df-946fe79f49dd"},"source":["print(n_bri,bri,psnr, mse_, ssim_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["90.19495708272595 116.5157314455752 29.599896404114148 2950.9106240720957 0.45908368626292406\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hLWDNTfvmvVL","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"ok","timestamp":1627583525697,"user_tz":-60,"elapsed":28343847,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"8885e854-bb88-4bed-8652-432438271505"},"source":["  \n","# Import writer class from csv module\n","#!/usr/bin/python\n","# -*- coding: utf-8 -*-'\n","# j=0\n","for i in range(0, len(data)):\n","\n","    try:\n","        path = root + data['fullPath'][i]  # 2499\n","        path = path.replace('\\\\', '/')\n","        path = path.replace('.png', '.jpg')\n","        img = cv2.imread(path, 0)\n","        ini_img = img.copy()\n","        grid_l = int(img.shape[0] * img.shape[0] / img.shape[1] / 600)\n","        grid_w = int(img.shape[1] * img.shape[1] / img.shape[0] / 200)\n","        if grid_l < 2:\n","            grid_l = 2\n","        if grid_w < 2:\n","            grid_w = 2\n","        image = breast_snip(img)\n","        mask_add(image, data, i)\n","        # n_bri = n_bri + brisque.score(ini_img)\n","        # bri = bri + brisque.score(image.copy())\n","        # psnr = psnr + PSNR(ini_img, image.copy())\n","        # mse_ = mse_ + ssim_mse(ini_img, image.copy())[0]\n","        # ssim_ = ssim_ + ssim_mse(ini_img, image.copy())[1]\n","        save_i = '/content/drive/MyDrive/Thesis/pos/x/' + str(i) \\\n","            + '.jpg'\n","        cv2.imwrite(save_i, image)\n","        save_i = '/content/drive/MyDrive/Thesis/pos/x/' + str(i) + '.jpg'\n","        save_m = '/content/drive/MyDrive/Thesis/pos/y/' + str(i) + '.jpg'\n","        List = [save_i, save_m, data['Status'][i], data['fullPath'][i]]\n","        df_.loc[i] = List\n","\n","    except: \n","        df_.to_csv('/content/drive/MyDrive/Thesis/pos/data_p.csv', index = False)\n","        dfc_.to_csv('/content/drive/MyDrive/Thesis/pos/data_c.csv', index = False)\n","    # print(i)\n","    \n","df_.to_csv('/content/drive/MyDrive/Thesis/pos/data_p.csv', index = False)\n","dfc_.to_csv('/content/drive/MyDrive/Thesis/pos/data_c.csv', index = False)\n","      # List\n","\n","    #     List = [save_i, save_m, data['Status'][i], data['fullPath'][i]]\n","    #     # df_.loc[i] = List\n","    #     writer.writerow(List)\n","    #     print(i, n)\n","    # except:\n","    #   continue\n","\n","\n","\n","\n","  # plt.imshow(image, cmap='gray')\n","  # print(img.shape[0], img.shape[1])\n","  # print(grid_l, grid_w)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CmoxQwl8h8U","executionInfo":{"status":"ok","timestamp":1627634214853,"user_tz":-60,"elapsed":8,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"6dd1ff8b-d8b8-4ed9-e818-3b030bcb4fbf"},"source":["len(df_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5238"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cRfdchGgsfp4","executionInfo":{"status":"ok","timestamp":1627634217572,"user_tz":-60,"elapsed":8,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"6c5af22c-0cf9-4550-f635-3475f1579a90"},"source":["len(df_.loc[df_.label == 'Cancer'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1428"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SvXZL_H3kbHx","executionInfo":{"status":"ok","timestamp":1627634220201,"user_tz":-60,"elapsed":6,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"5afd5906-1be3-430d-c554-bc4c7b277717"},"source":["len(dfc_.loc[dfc_.label == 'Cancer'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1609"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"dL3zsUtX0X5R"},"source":["import imquality.brisque as brisque\n","import csv\n","n = len(data)\n","b = len(df_)+1\n","n_bri = 0\n","bri=0\n","psnr = 0\n","mse_ = 0\n","ssim_ = 0\n","for i in range(0, len(data)):\n","    path = root + data['fullPath'][0]  # 2499\n","    path = path.replace('\\\\', '/')\n","    path = path.replace('.png', '.jpg')\n","    # img.create(11, 2, CV_8UC1)\n","    # src = imread(your-file, CV_8UC1)\n","    img = cv2.imread(path, 0)\n","\n","    ini_img = img.copy()\n","    grid_l = int(img.shape[0] * img.shape[0] / img.shape[1] / 600)\n","    grid_w = int(img.shape[1] * img.shape[1] / img.shape[0] / 200)\n","    if grid_l < 2:\n","        grid_l = 2\n","    if grid_w < 2:\n","        grid_w = 2\n","    image = breast_snip(img)\n","    n_bri = n_bri + brisque.score(ini_img)\n","    bri = bri + brisque.score(image.copy())\n","    psnr = psnr + PSNR(ini_img, image.copy())\n","    mse_ = mse_ + ssim_mse(ini_img, image.copy())[0]\n","    ssim_ = ssim_ + ssim_mse(ini_img, image.copy())[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C92qrb9ucif2"},"source":["for i in range(0, len(data)): \n","  path = root + data[\"fullPath\"][i]#2499\n","  path = path.replace('\\\\', '/')\n","  path = path.replace('.png', '.jpg')\n","  # img = breast_snip(path, True)\n","  # img = morphological_enhancement(img)\n","  #   img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),mode='constant',  \n","  #                                 preserve_range=True)\n","  # img = contrast_streching(img)\n","  img = clahe(img)\n","  # X_train[n] = img  #Fill empty X_train with values from img\n","  img = resize(img, (img.shape[0], img.shape[1], IMG_CHANNELS),mode='constant', preserve_range=True)\n","  Main_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","  masks = []\n","\n","  if data['Tumour_Contour'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour'][i]))\n","  if data['Tumour_Contour2'][i] != '-':\n","    masks.append(check_path(root + data['Tumour_Contour2'][i]))\n","  if pd.isnull(data[\"Tumour_Contour3\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour3'][i]))\n","  if pd.isnull(data[\"Tumour_Contour4\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour4'][i]))\n","  if pd.isnull(data[\"Tumour_Contour5\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour5'][i]))\n","  if pd.isnull(data[\"Tumour_Contour6\"][i]) == False:\n","    masks.append(check_path(root + data['Tumour_Contour6'][i]))\n","  for mask in masks:\n","    mask_ = imread(mask)\n","    mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n","                                  preserve_range=True), axis=-1)\n","    Main_mask = np.maximum(Main_mask, mask_) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2nMbS40gHlM"},"source":["# EfficientUnet"]},{"cell_type":"markdown","metadata":{"id":"nIJUmq6zgXPz"},"source":["## Efficientnet"]},{"cell_type":"code","metadata":{"id":"q8dhNhDdgW58","cellView":"form"},"source":["#@title Efficientnet\n","from keras import models, layers\n","# import sys  \n","# sys.path.insert(0, '/content/drive/MyDrive/Thesis/MPL/EfficientUnet/efficientunet')\n","from tensorflow.keras.utils import get_file\n","# from utils import *\n","\n","__all__ = ['get_model_by_name', 'get_efficientnet_b0_encoder', 'get_efficientnet_b1_encoder',\n","           'get_efficientnet_b2_encoder', 'get_efficientnet_b3_encoder', 'get_efficientnet_b4_encoder',\n","           'get_efficientnet_b5_encoder', 'get_efficientnet_b6_encoder', 'get_efficientnet_b7_encoder']\n","\n","\n","def _efficientnet(input_shape, blocks_args_list, global_params):\n","    batch_norm_momentum = global_params.batch_norm_momentum\n","    batch_norm_epsilon = global_params.batch_norm_epsilon\n","\n","    # Stem part\n","    model_input = layers.Input(shape=input_shape)\n","    x = layers.Conv2D(\n","        filters=round_filters(32, global_params),\n","        kernel_size=[3, 3],\n","        strides=[2, 2],\n","        kernel_initializer=conv_kernel_initializer,\n","        padding='same',\n","        use_bias=False,\n","        name='stem_conv2d'\n","    )(model_input)\n","\n","    x = layers.BatchNormalization(\n","        momentum=batch_norm_momentum,\n","        epsilon=batch_norm_epsilon,\n","        name='stem_batch_norm'\n","    )(x)\n","\n","    x = Swish(name='stem_swish')(x)\n","\n","    # Blocks part\n","    idx = 0\n","    drop_rate = global_params.drop_connect_rate\n","    n_blocks = sum([blocks_args.num_repeat for blocks_args in blocks_args_list])\n","    drop_rate_dx = drop_rate / n_blocks\n","\n","    for blocks_args in blocks_args_list:\n","        assert blocks_args.num_repeat > 0\n","        # Update block input and output filters based on depth multiplier.\n","        blocks_args = blocks_args._replace(\n","            input_filters=round_filters(blocks_args.input_filters, global_params),\n","            output_filters=round_filters(blocks_args.output_filters, global_params),\n","            num_repeat=round_repeats(blocks_args.num_repeat, global_params)\n","        )\n","\n","        # The first block needs to take care of stride and filter size increase.\n","        x = MBConvBlock(blocks_args, global_params, idx, drop_connect_rate=drop_rate_dx * idx)(x)\n","        idx += 1\n","\n","        if blocks_args.num_repeat > 1:\n","            blocks_args = blocks_args._replace(input_filters=blocks_args.output_filters, strides=[1, 1])\n","\n","        for _ in range(blocks_args.num_repeat - 1):\n","            x = MBConvBlock(blocks_args, global_params, idx, drop_connect_rate=drop_rate_dx * idx)(x)\n","            idx += 1\n","\n","    # Head part\n","    x = layers.Conv2D(\n","        filters=round_filters(1280, global_params),\n","        kernel_size=[1, 1],\n","        strides=[1, 1],\n","        kernel_initializer=conv_kernel_initializer,\n","        padding='same',\n","        use_bias=False,\n","        name='head_conv2d'\n","    )(x)\n","\n","    x = layers.BatchNormalization(\n","        momentum=batch_norm_momentum,\n","        epsilon=batch_norm_epsilon,\n","        name='head_batch_norm'\n","    )(x)\n","\n","    x = Swish(name='head_swish')(x)\n","\n","    x = layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)\n","\n","    if global_params.dropout_rate > 0:\n","        x = layers.Dropout(global_params.dropout_rate)(x)\n","\n","    x = layers.Dense(\n","        global_params.num_classes,\n","        kernel_initializer=dense_kernel_initializer,\n","        activation='softmax',\n","        name='head_dense'\n","    )(x)\n","\n","    model = models.Model(model_input, x)\n","\n","    return model\n","\n","\n","def get_model_by_name(model_name, input_shape, classes=3, pretrained=False):\n","    \"\"\"Get an EfficientNet model by its name.\n","    \"\"\"\n","    blocks_args, global_params = get_efficientnet_params(model_name, override_params={'num_classes': classes})\n","    model = _efficientnet(input_shape, blocks_args, global_params)\n","\n","    try:\n","        if pretrained:\n","            weights = IMAGENET_WEIGHTS[model_name]\n","            weights_path = get_file(\n","                weights['name'],\n","                weights['url'],\n","                cache_subdir='models',\n","                md5_hash=weights['md5'],\n","            )\n","            model.load_weights(weights_path)\n","    except KeyError as e:\n","        print(\"NOTE: Currently model {} doesn't have pretrained weights, therefore a model with randomly initialized\"\n","              \" weights is returned.\".format(e))\n","\n","    return model\n","\n","\n","def _get_efficientnet_encoder(model_name, input_shape, pretrained=False):\n","    model = get_model_by_name(model_name, input_shape, pretrained=pretrained)\n","    encoder = models.Model(model.input, model.get_layer('global_average_pooling2d').output)\n","    encoder.layers.pop()  # remove GAP layer\n","    return encoder\n","\n","\n","def get_efficientnet_b0_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b0', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b1_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b1', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b2_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b2', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b3_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b3', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b4_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b4', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b5_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b5', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b6_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b6', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b7_encoder(input_shape, pretrained=False):\n","    return _get_efficientnet_encoder('efficientnet-b7', input_shape, pretrained=pretrained)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iz1mgr0_goYL"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"qje92-TUkfjU"},"source":["#@title number of classes\n","\n","n_classes=3 #@param {type:\"integer\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PR4BA07zgNwD","cellView":"form"},"source":["#@title Utils\n","import re\n","from collections import namedtuple\n","from keras import layers\n","import keras.backend as K\n","import tensorflow as tf\n","import math\n","import numpy as np\n","\n","GlobalParams = namedtuple('GlobalParams', ['batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate', 'num_classes',\n","                                           'width_coefficient', 'depth_coefficient', 'depth_divisor', 'min_depth',\n","                                           'drop_connect_rate'])\n","global_params = None\n","GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n","\n","BlockArgs = namedtuple('BlockArgs', ['kernel_size', 'num_repeat', 'input_filters', 'output_filters', 'expand_ratio',\n","                                     'id_skip', 'strides', 'se_ratio'])\n","BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n","\n","IMAGENET_WEIGHTS = {\n","\n","    'efficientnet-b0': {\n","        'name': 'efficientnet-b0_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000.h5',\n","        'md5': 'bca04d16b1b8a7c607b1152fe9261af7',\n","    },\n","\n","    'efficientnet-b1': {\n","        'name': 'efficientnet-b1_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_imagenet_1000.h5',\n","        'md5': 'bd4a2b82f6f6bada74fc754553c464fc',\n","    },\n","\n","    'efficientnet-b2': {\n","        'name': 'efficientnet-b2_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b2_imagenet_1000.h5',\n","        'md5': '45b28b26f15958bac270ab527a376999',\n","    },\n","\n","    'efficientnet-b3': {\n","        'name': 'efficientnet-b3_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000.h5',\n","        'md5': 'decd2c8a23971734f9d3f6b4053bf424',\n","    },\n","\n","    'efficientnet-b4': {\n","        'name': 'efficientnet-b4_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_imagenet_1000.h5',\n","        'md5': '01df77157a86609530aeb4f1f9527949',\n","    },\n","\n","    'efficientnet-b5': {\n","        'name': 'efficientnet-b5_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_imagenet_1000.h5',\n","        'md5': 'c31311a1a38b5111e14457145fccdf32',\n","    }\n","\n","}\n","\n","\n","def round_filters(filters, global_params):\n","    \"\"\"Round number of filters.\"\"\"\n","    multiplier = global_params.width_coefficient\n","    divisor = global_params.depth_divisor\n","    min_depth = global_params.min_depth\n","    if not multiplier:\n","        return filters\n","\n","    filters *= multiplier\n","    min_depth = min_depth or divisor\n","    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_filters < 0.9 * filters:\n","        new_filters += divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, global_params):\n","    \"\"\"Round number of repeats.\"\"\"\n","    multiplier = global_params.depth_coefficient\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","def get_efficientnet_params(model_name, override_params=None):\n","    \"\"\"Get efficientnet params based on model name.\"\"\"\n","    params_dict = {\n","        # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n","        # Note: the resolution here is just for reference, its values won't be used.\n","        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n","        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n","        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n","        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n","        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n","        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n","        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n","        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n","    }\n","    if model_name not in params_dict.keys():\n","        raise KeyError('There is no model named {}.'.format(model_name))\n","\n","    width_coefficient, depth_coefficient, _, dropout_rate = params_dict[model_name]\n","\n","    blocks_args = [\n","        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n","        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n","        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n","        'r1_k3_s11_e6_i192_o320_se0.25',\n","    ]\n","    global_params = GlobalParams(\n","        batch_norm_momentum=0.99,\n","        batch_norm_epsilon=1e-3,\n","        dropout_rate=dropout_rate,\n","        drop_connect_rate=0.2,\n","        num_classes=n_classes,\n","        width_coefficient=width_coefficient,\n","        depth_coefficient=depth_coefficient,\n","        depth_divisor=8,\n","        min_depth=None)\n","\n","    if override_params:\n","        global_params = global_params._replace(**override_params)\n","\n","    decoder = BlockDecoder()\n","    return decoder.decode(blocks_args), global_params\n","\n","\n","class BlockDecoder(object):\n","    \"\"\"Block Decoder for readability.\"\"\"\n","\n","    @staticmethod\n","    def _decode_block_string(block_string):\n","        \"\"\"Gets a block through a string notation of arguments.\"\"\"\n","        assert isinstance(block_string, str)\n","        ops = block_string.split('_')\n","        options = {}\n","        for op in ops:\n","            splits = re.split(r'(\\d.*)', op)\n","            if len(splits) >= 2:\n","                key, value = splits[:2]\n","                options[key] = value\n","\n","        if 's' not in options or len(options['s']) != 2:\n","            raise ValueError('Strides options should be a pair of integers.')\n","\n","        return BlockArgs(\n","            kernel_size=int(options['k']),\n","            num_repeat=int(options['r']),\n","            input_filters=int(options['i']),\n","            output_filters=int(options['o']),\n","            expand_ratio=int(options['e']),\n","            id_skip=('noskip' not in block_string),\n","            se_ratio=float(options['se']) if 'se' in options else None,\n","            strides=[int(options['s'][0]), int(options['s'][1])]\n","        )\n","\n","    @staticmethod\n","    def _encode_block_string(block):\n","        \"\"\"Encodes a block to a string.\"\"\"\n","        args = [\n","            'r%d' % block.num_repeat,\n","            'k%d' % block.kernel_size,\n","            's%d%d' % (block.strides[0], block.strides[1]),\n","            'e%s' % block.expand_ratio,\n","            'i%d' % block.input_filters,\n","            'o%d' % block.output_filters\n","        ]\n","        if 0 < block.se_ratio <= 1:\n","            args.append('se%s' % block.se_ratio)\n","        if block.id_skip is False:\n","            args.append('noskip')\n","        return '_'.join(args)\n","\n","    def decode(self, string_list):\n","        \"\"\"Decodes a list of string notations to specify blocks inside the network.\n","        Args:\n","          string_list: a list of strings, each string is a notation of block.\n","        Returns:\n","          A list of namedtuples to represent blocks arguments.\n","        \"\"\"\n","        assert isinstance(string_list, list)\n","        blocks_args = []\n","        for block_string in string_list:\n","            blocks_args.append(self._decode_block_string(block_string))\n","        return blocks_args\n","\n","    def encode(self, blocks_args):\n","        \"\"\"Encodes a list of Blocks to a list of strings.\n","        Args:\n","          blocks_args: A list of namedtuples to represent blocks arguments.\n","        Returns:\n","          a list of strings, each string is a notation of block.\n","        \"\"\"\n","        block_strings = []\n","        for block in blocks_args:\n","            block_strings.append(self._encode_block_string(block))\n","        return block_strings\n","\n","\n","class Swish(layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.silu(inputs)#tf.nn.swish I have changed this why I don't know yet\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","\n","\n","def SEBlock(block_args, **kwargs):\n","    num_reduced_filters = max(\n","        1, int(block_args.input_filters * block_args.se_ratio))\n","    filters = block_args.input_filters * block_args.expand_ratio\n","\n","    spatial_dims = [1, 2]\n","\n","    try:\n","        block_name = kwargs['block_name']\n","    except KeyError:\n","        block_name = ''\n","\n","    def block(inputs):\n","        x = inputs\n","        x = layers.Lambda(lambda a: K.mean(a, axis=spatial_dims, keepdims=True))(x)\n","        x = layers.Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'se_reduce_conv2d',\n","            use_bias=True\n","        )(x)\n","\n","        x = Swish(name=block_name + 'se_swish')(x)\n","\n","        x = layers.Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'se_expand_conv2d',\n","            use_bias=True\n","        )(x)\n","\n","        x = layers.Activation('sigmoid')(x)\n","        out = layers.Multiply()([x, inputs])\n","        return out\n","\n","    return block\n","\n","\n","class DropConnect(layers.Layer):\n","\n","    def __init__(self, drop_connect_rate, **kwargs):\n","        super().__init__(**kwargs)\n","        self.drop_connect_rate = drop_connect_rate\n","\n","    def call(self, inputs, **kwargs):\n","        def drop_connect():\n","            keep_prob = 1.0 - self.drop_connect_rate\n","\n","            # Compute drop_connect tensor\n","            batch_size = tf.shape(inputs)[0]\n","            random_tensor = keep_prob\n","            random_tensor += tf.random.uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n","            binary_tensor = tf.floor(random_tensor)\n","            output = tf.math.divide(inputs, keep_prob) * binary_tensor\n","            return output\n","\n","        return K.in_train_phase(drop_connect(), inputs, training=None)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['drop_connect_rate'] = self.drop_connect_rate\n","        return config\n","\n","\n","def conv_kernel_initializer(shape, dtype=K.floatx()):\n","    \"\"\"Initialization for convolutional kernels.\n","    The main difference with tf.variance_scaling_initializer is that\n","    tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n","    standard deviation, whereas here we use a normal distribution. Similarly,\n","    tf.contrib.layers.variance_scaling_initializer uses a truncated normal with\n","    a corrected standard deviation.\n","    Args:\n","        shape: shape of variable\n","        dtype: dtype of variable\n","    Returns:\n","        an initialization for the variable\n","    \"\"\"\n","    kernel_height, kernel_width, _, out_filters = shape\n","    fan_out = int(kernel_height * kernel_width * out_filters)\n","    return tf.random.normal(\n","        shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype)\n","\n","\n","def dense_kernel_initializer(shape, dtype=K.floatx()):\n","    init_range = 1.0 / np.sqrt(shape[1])\n","    return tf.random.uniform(shape, -init_range, init_range, dtype=dtype)\n","\n","\n","def MBConvBlock(block_args, global_params, idx, drop_connect_rate=None):\n","    filters = block_args.input_filters * block_args.expand_ratio\n","    batch_norm_momentum = global_params.batch_norm_momentum\n","    batch_norm_epsilon = global_params.batch_norm_epsilon\n","    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n","\n","    block_name = 'blocks_' + str(idx) + '_'\n","\n","    def block(inputs):\n","        x = inputs\n","\n","        # Expansion phase\n","        if block_args.expand_ratio != 1:\n","            expand_conv = layers.Conv2D(filters,\n","                                        kernel_size=[1, 1],\n","                                        strides=[1, 1],\n","                                        kernel_initializer=conv_kernel_initializer,\n","                                        padding='same',\n","                                        use_bias=False,\n","                                        name=block_name + 'expansion_conv2d'\n","                                        )(x)\n","            bn0 = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                            epsilon=batch_norm_epsilon,\n","                                            name=block_name + 'expansion_batch_norm')(expand_conv)\n","\n","            x = Swish(name=block_name + 'expansion_swish')(bn0)\n","\n","        # Depth-wise convolution phase\n","        kernel_size = block_args.kernel_size\n","        depthwise_conv = layers.DepthwiseConv2D(\n","            [kernel_size, kernel_size],\n","            strides=block_args.strides,\n","            depthwise_initializer=conv_kernel_initializer,\n","            padding='same',\n","            use_bias=False,\n","            name=block_name + 'depthwise_conv2d'\n","        )(x)\n","        bn1 = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                        epsilon=batch_norm_epsilon,\n","                                        name=block_name + 'depthwise_batch_norm'\n","                                        )(depthwise_conv)\n","        x = Swish(name=block_name + 'depthwise_swish')(bn1)\n","\n","        if has_se:\n","            x = SEBlock(block_args, block_name=block_name)(x)\n","\n","        # Output phase\n","        project_conv = layers.Conv2D(\n","            block_args.output_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'output_conv2d',\n","            use_bias=False)(x)\n","        x = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                      epsilon=batch_norm_epsilon,\n","                                      name=block_name + 'output_batch_norm'\n","                                      )(project_conv)\n","        if block_args.id_skip:\n","            if all(\n","                    s == 1 for s in block_args.strides\n","            ) and block_args.input_filters == block_args.output_filters:\n","                # only apply drop_connect if skip presents.\n","                if drop_connect_rate:\n","                    x = DropConnect(drop_connect_rate)(x)\n","                x = layers.add([x, inputs])\n","\n","        return x\n","\n","    return block\n","\n","\n","def freeze_efficientunet_first_n_blocks(model, n):\n","    mbblock_nr = 0\n","    while True:\n","        try:\n","            model.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr))\n","            mbblock_nr += 1\n","        except ValueError:\n","            break\n","\n","    all_block_names = ['blocks_{}_output_batch_norm'.format(i) for i in range(mbblock_nr)]\n","    all_block_index = []\n","    for idx, layer in enumerate(model.layers):\n","        if layer.name == all_block_names[0]:\n","            all_block_index.append(idx)\n","            all_block_names.pop(0)\n","            if len(all_block_names) == 0:\n","                break\n","    n_blocks = len(all_block_index)\n","\n","    if n <= 0:\n","        print('n is less than or equal to 0, therefore no layer will be frozen.')\n","        return\n","    if n > n_blocks:\n","        raise ValueError(\"There are {} blocks in total, n cannot be greater than {}.\".format(n_blocks, n_blocks))\n","\n","    idx_of_last_block_to_be_frozen = all_block_index[n - 1]\n","    for layer in model.layers[:idx_of_last_block_to_be_frozen + 1]:\n","        layer.trainable = False\n","\n","\n","def unfreeze_efficientunet(model):\n","    for layer in model.layers:\n","        layer.trainable = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZ29zXFqh5sm"},"source":["## *Efficientunet*"]},{"cell_type":"code","metadata":{"id":"TGg2DkR-g-2L","cellView":"form"},"source":["#@markdown Efficientnet-unet\n","import sys  \n","# sys.path.insert(0, '/content/drive/MyDrive/Thesis/MPL/EfficientUnet/efficientunet')\n","from keras.layers import *\n","from keras import models\n","# from efficientnet import *\n","# from utils import conv_kernel_initializer\n","\n","\n","__all__ = ['get_efficient_unet_b0', 'get_efficient_unet_b1', 'get_efficient_unet_b2', 'get_efficient_unet_b3',\n","           'get_efficient_unet_b4', 'get_efficient_unet_b5', 'get_efficient_unet_b6', 'get_efficient_unet_b7',\n","           'get_blocknr_of_skip_candidates']\n","\n","\n","def get_blocknr_of_skip_candidates(encoder, verbose=False):\n","    \"\"\"\n","    Get block numbers of the blocks which will be used for concatenation in the Unet.\n","    :param encoder: the encoder\n","    :param verbose: if set to True, the shape information of all blocks will be printed in the console\n","    :return: a list of block numbers\n","    \"\"\"\n","    shapes = []\n","    candidates = []\n","    mbblock_nr = 0\n","    while True:\n","        try:\n","            mbblock = encoder.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr)).output\n","            shape = int(mbblock.shape[1]), int(mbblock.shape[2])\n","            if shape not in shapes:\n","                shapes.append(shape)\n","                candidates.append(mbblock_nr)\n","            if verbose:\n","                print('blocks_{}_output_shape: {}'.format(mbblock_nr, shape))\n","            mbblock_nr += 1\n","        except ValueError:\n","            break\n","    return candidates\n","\n","\n","def DoubleConv(filters, kernel_size, initializer='glorot_uniform'):\n","\n","    def layer(x):\n","\n","        x = Conv2D(filters, kernel_size, padding='same', use_bias=False, kernel_initializer=initializer)(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Conv2D(filters, kernel_size, padding='same', use_bias=False, kernel_initializer=initializer)(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","\n","        return x\n","\n","    return layer\n","\n","\n","def UpSampling2D_block(filters, kernel_size=(3, 3), upsample_rate=(2, 2), interpolation='bilinear',\n","                       initializer='glorot_uniform', skip=None):\n","    def layer(input_tensor):\n","\n","        x = UpSampling2D(size=upsample_rate, interpolation=interpolation)(input_tensor)\n","\n","        if skip is not None:\n","            x = Concatenate()([x, skip])\n","\n","        x = DoubleConv(filters, kernel_size, initializer=initializer)(x)\n","\n","        return x\n","    return layer\n","\n","\n","def Conv2DTranspose_block(filters, kernel_size=(3, 3), transpose_kernel_size=(2, 2), upsample_rate=(2, 2),\n","                          initializer='glorot_uniform', skip=None):\n","    def layer(input_tensor):\n","\n","        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate, padding='same')(input_tensor)\n","\n","        if skip is not None:\n","            x = Concatenate()([x, skip])\n","\n","        x = DoubleConv(filters, kernel_size, initializer=initializer)(x)\n","\n","        return x\n","\n","    return layer\n","\n","\n","# noinspection PyTypeChecker\n","def _get_efficient_unet(encoder, out_channels=2, block_type='upsampling', concat_input=True):\n","    MBConvBlocks = []\n","\n","    skip_candidates = get_blocknr_of_skip_candidates(encoder)\n","\n","    for mbblock_nr in skip_candidates:\n","        mbblock = encoder.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr)).output\n","        MBConvBlocks.append(mbblock)\n","\n","    # delete the last block since it won't be used in the process of concatenation\n","    MBConvBlocks.pop()\n","\n","    input_ = encoder.input\n","    head = encoder.get_layer('head_swish').output\n","    blocks = [input_] + MBConvBlocks + [head]\n","\n","    if block_type == 'upsampling':\n","        UpBlock = UpSampling2D_block\n","    else:\n","        UpBlock = Conv2DTranspose_block\n","\n","    o = blocks.pop()\n","    o = UpBlock(512, initializer=conv_kernel_initializer, skip=blocks.pop())(o)\n","    o = UpBlock(256, initializer=conv_kernel_initializer, skip=blocks.pop())(o)\n","    o = UpBlock(128, initializer=conv_kernel_initializer, skip=blocks.pop())(o)\n","    o = UpBlock(64, initializer=conv_kernel_initializer, skip=blocks.pop())(o)\n","    if concat_input:\n","        o = UpBlock(32, initializer=conv_kernel_initializer, skip=blocks.pop())(o)\n","    else:\n","        o = UpBlock(32, initializer=conv_kernel_initializer, skip=None)(o)\n","    o = Conv2D(out_channels, (1, 1), padding='same', kernel_initializer=conv_kernel_initializer)(o)\n","\n","    model = models.Model(encoder.input, o)\n","\n","    return model\n","\n","\n","def get_efficient_unet_b0(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b0_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b1(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B1 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B1 model\n","    \"\"\"\n","    encoder = get_efficientnet_b1_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b2(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B2 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B2 model\n","    \"\"\"\n","    encoder = get_efficientnet_b2_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b3(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B3 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B3 model\n","    \"\"\"\n","    encoder = get_efficientnet_b3_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b4(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B4 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B4 model\n","    \"\"\"\n","    encoder = get_efficientnet_b4_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b5(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B5 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B5 model\n","    \"\"\"\n","    encoder = get_efficientnet_b5_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b6(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B6 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B6 model\n","    \"\"\"\n","    encoder = get_efficientnet_b6_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","\n","\n","def get_efficient_unet_b7(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B7 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B7 model\n","    \"\"\"\n","    encoder = get_efficientnet_b7_encoder(input_shape, pretrained=pretrained)\n","    model = _get_efficient_unet(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gg6Xw9x-iHkA"},"source":["## Create model"]},{"cell_type":"code","metadata":{"cellView":"form","id":"mdJWcg-biObH"},"source":["Channels = 1 #@param {type:\"integer\"}\n","Img_size =224 #@param {type:\"integer\"}\n","input_shape = (Img_size, Img_size, Channels) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPWwAz8SkX7P"},"source":["tf.keras.backend.clear_session()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rml63YcFiLxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627719878839,"user_tz":-60,"elapsed":6436,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"ae72c2b8-d0bb-453f-c7e1-b004f3b58c07"},"source":["#@markdown Model Efficient unet\n","\n","classifier =  get_efficientnet_b0_encoder((224, 224, 3), pretrained=False)\n","modelS = models.Sequential()\n","modelS.add(classifier)\n","modelS.add(layers.Dense(3))\n","modelS.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model_1 (Functional)         (None, 1280)              4049564   \n","_________________________________________________________________\n","dense (Dense)                (None, 3)                 3843      \n","=================================================================\n","Total params: 4,053,407\n","Trainable params: 4,011,391\n","Non-trainable params: 42,016\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wkXW82PKibDl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627719881607,"user_tz":-60,"elapsed":2775,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"3f302632-0bea-498b-f422-a797d72e3b31"},"source":["classifier_t =  get_efficientnet_b0_encoder((224,224, 3), pretrained=False)\n","modelT = models.Sequential()\n","modelT.add(classifier_t)\n","modelT.add(layers.Dense(3))\n","modelT.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model_3 (Functional)         (None, 1280)              4049564   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 3843      \n","=================================================================\n","Total params: 4,053,407\n","Trainable params: 4,011,391\n","Non-trainable params: 42,016\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-j9x5-Py5RcX"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"pNmm_kkr5RcZ"},"source":["from tensorflow.python.client import device_lib\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","get_available_gpus()    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1iJF97nG5Rcb"},"source":["%cd /content/drive/MyDrive/Thesis/MPL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvcW5Pc2_Cur","cellView":"form"},"source":["#@title MPL config\n","import tensorflow as tf\n","\n","\n","\n","\n","# about dataset\n","IMG_SIZE = 224\n","BATCH_SIZE = 8\n","# LABEL_FILE_PATH = '/content/cifar/label4000.csv' # google\n","# UNLABEL_FILE_PATH = '/content/cifar/train.csv'\n","\n","_MAX_LEVEL = 10\n","CUTOUT_CONST = 40.\n","TRANSLATE_CONST = 100.\n","REPLACE_COLOR = [128, 128, 128]\n","\n","\n","# LABEL_FILE_PATH = '../input/cifar10/cifar/label4000.csv'  # kaggle\n","# UNLABEL_FILE_PATH = '../input/cifar10/cifar/train.csv'\n","\n","\n","AUGMENT_MAGNITUDE = 8\n","SHUFFLE_SIZE = BATCH_SIZE * 16\n","DATA_LEN = 400  # 数据集的总长度\n","\n","# about model\n","NUM_XLA_SHARDS = -1\n","BATCH_NORM_EPSILON = 1e-3\n","BATCH_NORM_DECAY = 0.999\n","DROPOUT_RATE = 0.\n","DROPOUT = 0.2\n","NUM_CLASSES = 3\n","NUM_CLASS = 3\n","\n","# about training\n","LOG_EVERY = 20\n","SAVE_EVERY = 5\n","TEA_SAVE_PATH = '/content/drive/MyDrive/Thesis/weights/CT'\n","STD_SAVE_PATH = '/content/drive/MyDrive/Thesis/weights/CS'\n","\n","MAX_EPOCHS = 1920\n","MAX_STEPS = MAX_EPOCHS * (int(DATA_LEN / BATCH_SIZE)-1)\n","UDA_WEIGHT = 8  # uda的权重\n","UDA_STEPS = 2000\n","TEST_EVERY = 2\n","GRAD_BOUND = 1e9\n","EMA = 0.995\n","\n","\n","# continue train\n","TEA_CONTINUE = False\n","STD_CONTINUE = False\n","TEA_LOAD_PATH = '/content/drive/MyDrive/Thesis/CTweights'\n","STD_LOAD_PATH = '/content/drive/MyDrive/Thesis/CTweights'\n","CONTINUE_EPOCH = 885\n","\n","\n","# about testing\n","# TEST_FILE_PATH = '/content/cifar/test.csv'\n","# TEST_FILE_PATH = '../input/cifar10/cifar/test.csv'\n","TEST_MODEL_PATH = '/content/drive/MyDrive/Thesis/weights/CS'\n","\n","# about UdaCrossEntroy\n","UDA_DATA = 1\n","LABEL_SMOOTHING = 0.15\n","UDA_TEMP = 0.7\n","UDA_THRESHOLD = 0.6\n","\n","# about learning rate\n","STUDENT_LR = 0.0005  # student\n","STUDENT_LR_WARMUP_STEPS = 4000\n","STUDENT_LR_WAIT_STEPS = 2000\n","TEACHER_LR = 0.0005  # teacher\n","TEACHER_LR_WARMUP_STEPS = 1000\n","TEACHER_NUM_WAIT_STEPS = 0\n","\n","LR_DECAY_TYPE = 'cosine'  # constant, exponential, cosine\n","NUM_DECAY_STEPS = 300\n","LR_DECAY_RATE = 0.97\n","\n","# about optimizer\n","OPTIM_TYPE = 'sgd'  # sgd, momentum, rmsprop\n","WEIGHT_DECAY = 5e-4\n","\n","\n","# dtype\n","DTYPE = tf.float32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"JzUpbjZDSWDh"},"source":["#@title Self_aug_func\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import math\n","import tensorflow_addons.image as image_ops\n","\n","# import \n","\n","\n","def autocontrast(image):\n","    lo = tf.cast(tf.reduce_min(image, axis=[0, 1]), tf.float32)\n","    hi = tf.cast(tf.reduce_max(image, axis=[0, 1]), tf.float32)\n","    scale = tf.math.divide(255.0, (hi - lo))\n","    offset = tf.math.multiply(-lo, scale)\n","    image = tf.math.add(\n","        tf.math.multiply(tf.cast(image, tf.float32), scale),\n","        offset\n","    )\n","    image = tf.clip_by_value(image, 0.0, 255.0)\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","\n","def equalize(image):\n","    # image = tf.cast(image, tf.int32)\n","    # channel = tf.shape(image)[-1]\n","    # for i in range(channel):\n","    #     im = tf.cast(image[:, :, i], tf.int32)\n","    #     histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n","    #     nonzero = tf.where(tf.not_equal(histo, 0))\n","    #     nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n","    #     step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n","    #     print(step)\n","    #     if step == 0:\n","    #         pass\n","    #     else:\n","    #         lut = (tf.cumsum(histo) + (step // 2)) // step\n","    #         lut = tf.concat([[0], lut[:-1]], 0)\n","    #         lut = tf.clip_by_value(lut, 0, 255)\n","    #         # print(lut)\n","    #         image[:, :, i] = tf.gather(lut, image[:, :, i])\n","    #         # image[:, :, i] = im\n","    #     # image[:, :, i] = im\n","\n","    def scale_channel(im, c=0):\n","        \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n","        im = tf.cast(im[:, :, 0], tf.int32)\n","        # Compute the histogram of the image channel.\n","        histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n","\n","        # For the purposes of computing the step, filter out the nonzeros.\n","        nonzero = tf.where(tf.not_equal(histo, 0))\n","        nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n","        step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n","\n","        def build_lut(histo, step):\n","            # Compute the cumulative sum, shifting by step // 2\n","            # and then normalization by step.\n","            lut = (tf.cumsum(histo) + (step // 2)) // step\n","            # Shift lut, prepending with 0.\n","            lut = tf.concat([[0], lut[:-1]], 0)\n","            # Clip the counts to be in range.  This is done\n","            # in the C code for image.point.\n","            return tf.clip_by_value(lut, 0, 255)\n","\n","        # If step is zero, return the original image.  Otherwise, build\n","        # lut from the full histogram and step and then index from it.\n","        result = tf.cond(tf.equal(step, 0),\n","                         lambda: im,\n","                         lambda: tf.gather(build_lut(histo, step), im))\n","        return tf.cast(result, tf.uint8)\n","\n","    s1 = scale_channel(image, 0)\n","    s2 = scale_channel(image, 1)\n","    s3 = scale_channel(image, 2)\n","    image = tf.stack([s1, s2, s3], 2)\n","\n","    return image\n","\n","\n","def invert(image):\n","    image = 255 - image\n","    return image\n","\n","\n","def rotate(image):\n","    level = tf.convert_to_tensor((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 30, tf.float32)\n","    should_filp = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool\n","    )\n","    degree = tf.cond(should_filp, lambda: level, lambda: -level)\n","    degree_to_radians = tf.convert_to_tensor(math.pi / 180., tf.float32)\n","    radians = tf.math.multiply(degree, degree_to_radians)\n","    new_imgsize = tf.cast(tf.math.abs(tf.divide(IMG_SIZE, radians)), tf.int32)\n","    image = tf.image.resize(image, (new_imgsize, new_imgsize))\n","    image = image_ops.rotate(image, radians, fill_mode='constant')\n","    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE, IMG_SIZE)\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","\n","def posterize(image):\n","    bit = tf.cast(tf.cast(AUGMENT_MAGNITUDE, tf.float32) / _MAX_LEVEL * 4, tf.float32)\n","    shift = tf.cast(8 - bit, image.dtype)\n","    image = tf.bitwise.right_shift(image, shift)\n","    image = tf.bitwise.left_shift(image, shift)\n","    return image\n","\n","\n","def solarize_arg(image):\n","    threahold = tf.cast(tf.cast(AUGMENT_MAGNITUDE, tf.float32) / _MAX_LEVEL * 22, tf.float32)\n","    threahold = tf.cast(threahold, image.dtype)\n","    image = tf.where(image < threahold, image, 255 - image)\n","    return image\n","\n","\n","def solarize_add(image, threahold=128):\n","    addition = tf.cast(tf.cast(AUGMENT_MAGNITUDE, tf.float32) / _MAX_LEVEL * 2, tf.int32)\n","    threahold = tf.cast(threahold, image.dtype)\n","    image = tf.add(tf.cast(image, tf.int32), addition)\n","    image = tf.cast(tf.clip_by_value(image, 0, 255), tf.uint8)\n","    image = tf.where(image < threahold, image, 255 - image)\n","    return image\n","\n","\n","def color(image, degenetate=None):\n","    if degenetate is None:\n","        degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n","\n","    factor = tf.cast((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 1.8 + 0.1, tf.float32)\n","\n","    def _blend():\n","        degen = tf.image.convert_image_dtype(degenerate, tf.float32)\n","        img = tf.image.convert_image_dtype(image, tf.float32)\n","        output = degen + factor * (img - degen)\n","        output = tf.where(\n","            tf.logical_and(tf.less(0., factor), tf.less(factor, 1.)),\n","            x=output,\n","            y=tf.clip_by_value(output, 0., 255.)\n","        )\n","        return tf.image.convert_image_dtype(output, tf.uint8)\n","\n","    pred_fn_pairs = [\n","        (tf.equal(factor, 0.), lambda: degenerate),\n","        (tf.equal(factor, 1.), lambda: image),\n","    ]\n","    image = tf.case(\n","        pred_fn_pairs=pred_fn_pairs,\n","        default=_blend,\n","        exclusive=True,\n","        strict=True,\n","    )\n","    return image\n","\n","\n","def contrast(image):\n","    degenerate = tf.image.rgb_to_grayscale(image)\n","    degenerate = tf.cast(degenerate, tf.int32)\n","\n","    hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n","    mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.\n","    degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n","    degenerate = tf.clip_by_value(degenerate, 0., 255.)\n","    degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n","\n","    factor = tf.cast((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 0.6 + 0.1, tf.float32)\n","\n","    def _blend():\n","        degen = tf.image.convert_image_dtype(degenerate, tf.float32)\n","        img = tf.image.convert_image_dtype(image, tf.float32)\n","        output = degen + factor * (img - degen)\n","        output = tf.where(\n","            tf.logical_and(tf.less(0., factor), tf.less(factor, 1.)),\n","            x=output,\n","            y=tf.clip_by_value(output, 0., 255.)\n","        )\n","        return tf.image.convert_image_dtype(output, tf.uint8)\n","\n","    pred_fn_pairs = [\n","        (tf.equal(factor, 0.), lambda: degenerate),\n","        (tf.equal(factor, 1.), lambda: image),\n","    ]\n","    image = tf.case(\n","        pred_fn_pairs=pred_fn_pairs,\n","        default=_blend,\n","        exclusive=True,\n","        strict=True,\n","    )\n","    return image\n","\n","\n","def brightness(image):\n","    image = tf.image.adjust_brightness(image, 0.25)\n","    return image\n","\n","\n","def sharpness(image):\n","    factor = tf.cast((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 1.6 + 0.1, tf.float32)\n","    image = tf.cast(image, tf.float32)\n","    image = image_ops.sharpness(image, factor)\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","\n","def shear_x(image):\n","    level = tf.convert_to_tensor((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 0.2, tf.float32)\n","    should_filp = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool\n","    )\n","    level = tf.cond(should_filp, lambda: level, lambda: -level)\n","\n","    new_size = tf.cast(IMG_SIZE * 1.2, dtype=tf.int32)\n","    image = tf.image.resize(image, (new_size, new_size))\n","    image = image_ops.shear_x(\n","        image,\n","        level,\n","        replace=tf.convert_to_tensor(REPLACE_COLOR, image.dtype)\n","    )\n","    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE, IMG_SIZE)\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","\n","def shear_y(image):\n","    level = tf.convert_to_tensor((AUGMENT_MAGNITUDE / _MAX_LEVEL) * 0.2, tf.float32)\n","    should_filp = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool\n","    )\n","    level = tf.cond(should_filp, lambda: level, lambda: -level)\n","\n","    new_size = tf.cast(IMG_SIZE * 1.1, dtype=tf.int32)\n","    image = tf.image.resize(image, (new_size, new_size))\n","    image = image_ops.shear_y(\n","        image,\n","        level,\n","        replace=tf.convert_to_tensor(REPLACE_COLOR, image.dtype)\n","    )\n","    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE, IMG_SIZE)\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","\n","def translate_x(image):\n","    level = tf.convert_to_tensor(\n","        (AUGMENT_MAGNITUDE / _MAX_LEVEL) * float(TRANSLATE_CONST), tf.float32)\n","    should_flip = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool)  # 得到的结果为True和False\n","    pixels = tf.cond(should_flip, lambda: level, lambda: -level)\n","    image = image_ops.translate(image, [-pixels, 0])\n","    return image\n","\n","\n","def translate_y(image):\n","    level = tf.convert_to_tensor(\n","        (AUGMENT_MAGNITUDE / _MAX_LEVEL) * float(TRANSLATE_CONST), tf.float32)\n","    should_flip = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool)  # 得到的结果为True和False\n","    pixels = tf.cond(should_flip, lambda: level, lambda: -level)\n","    image = image_ops.translate(image, [0, -pixels])\n","    return image\n","\n","\n","def cutout(image):\n","    pad_size = tf.cast(\n","        tf.cast(AUGMENT_MAGNITUDE, tf.float32) / _MAX_LEVEL * CUTOUT_CONST,\n","        tf.int32\n","    )\n","    image_height = tf.shape(image)[0]\n","    image_width = tf.shape(image)[1]\n","\n","    # Samples the center location in the image where the zero mask is applied.\n","    cutout_center_height = tf.random.uniform(\n","        shape=[], minval=0, maxval=image_height,\n","        dtype=tf.int32)\n","\n","    cutout_center_width = tf.random.uniform(\n","        shape=[], minval=0, maxval=image_width,\n","        dtype=tf.int32)\n","\n","    lower_pad = tf.maximum(0, cutout_center_height - pad_size)\n","    upper_pad = tf.maximum(0, image_height - cutout_center_height - pad_size)\n","    left_pad = tf.maximum(0, cutout_center_width - pad_size)\n","    right_pad = tf.maximum(0, image_width - cutout_center_width - pad_size)\n","\n","    cutout_shape = [image_height - (lower_pad + upper_pad),\n","                    image_width - (left_pad + right_pad)]\n","    padding_dims = [[lower_pad, upper_pad], [left_pad, right_pad]]\n","    mask = tf.pad(\n","        tf.zeros(cutout_shape, dtype=image.dtype),\n","        padding_dims, constant_values=1)\n","    mask = tf.expand_dims(mask, -1)\n","    mask = tf.tile(mask, [1, 1, 3])\n","    image = tf.where(\n","        tf.equal(mask, 0),\n","        tf.ones_like(image, dtype=image.dtype) * REPLACE_COLOR,\n","        image)\n","    return image\n","\n","\n","def identity(image):\n","    return tf.identity(image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"8e7vEGndSLme","executionInfo":{"status":"ok","timestamp":1627719902312,"user_tz":-60,"elapsed":270,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"2e690c5f-e120-4981-bdbb-f918d2a18633"},"source":["#@title Self_aug_util\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import tensorflow as tf\n","\n","# from self_aug_func import *\n","\n","_MAX_LEVEL = 10\n","\n","\n","\n","def _enhance_level_to_arg(level):\n","    return (tf.cast((level / _MAX_LEVEL) * 1.8 + 0.1, tf.float32),)\n","\n","\n","def _translate_level_to_arg(level, translate_const):\n","    level = tf.convert_to_tensor((level / _MAX_LEVEL) * float(translate_const), tf.float32)\n","    should_flip = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool)  # 得到的结果为True和False\n","    final_tensor = tf.cond(should_flip, lambda: level, lambda: -level)\n","    return final_tensor\n","\n","\n","def _rotate_level_to_arg(level):\n","    level = tf.convert_to_tensor((level / _MAX_LEVEL) * 30, tf.float32)\n","    should_filp = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool\n","    )\n","    final_tensor = tf.cond(should_filp, lambda: level, lambda: -level)\n","    return final_tensor\n","\n","\n","def _shear_level_to_arg(level):\n","    level = tf.convert_to_tensor((level / _MAX_LEVEL) * 0.3, tf.float32)\n","    should_filp = tf.cast(\n","        tf.floor(tf.random.uniform([]) + 0.5),\n","        tf.bool\n","    )\n","    final_tensor = tf.cond(should_filp, lambda: level, lambda: -level)\n","    return final_tensor\n","\n","\n","def level_to_arg(cutout_const, translate_const):\n","    '''\n","    将对image做变化的函数所用到的参数整理成字典形式\n","    :param cutout_const:\n","    :param translate_const:\n","    :return: type:dict\n","    '''\n","    no_arg = lambda level: ()\n","    posterize_arg = lambda level: tf.cast(\n","        tf.cast(level, tf.float32) / _MAX_LEVEL * 4,\n","        tf.float32\n","    )\n","    solarize_arg = lambda level: tf.cast(\n","        tf.cast(level, tf.float32) / _MAX_LEVEL * 256,\n","        tf.float32\n","    )\n","    solarize_add_arg = lambda level: tf.cast(\n","        tf.cast(level, tf.float32) / _MAX_LEVEL * 110,\n","        tf.float32\n","    )\n","    cutout_arg = lambda level: tf.cast(\n","        tf.cast(level, tf.float32) / _MAX_LEVEL * cutout_const,\n","        tf.float32\n","    )\n","    translate_arg = lambda level: _translate_level_to_arg(level, translate_const)\n","\n","    args = {\n","        'Identity': no_arg,\n","        'AutoContrast': no_arg,\n","        'Equalize': no_arg,\n","        'Invert': no_arg,\n","        'Rotate': _rotate_level_to_arg,\n","        'Posterize': posterize_arg,\n","        'Solarize': solarize_arg,\n","        'SplarizeAdd': solarize_add_arg,\n","        'Color': _enhance_level_to_arg,\n","        'Contrast': _enhance_level_to_arg,\n","        'Brightness': _enhance_level_to_arg,\n","        'Sharpness': _enhance_level_to_arg,\n","        'ShearX': _shear_level_to_arg,\n","        'ShearY': _shear_level_to_arg,\n","        'Cutout': cutout_arg,\n","        'TranslateX': translate_arg,\n","        'TranslateY': translate_arg,\n","    }\n","    return args\n","\n","\n","if __name__ == '__main__':\n","    NAME_TO_FUNC = {\n","        'AutoContrast': autocontrast,\n","        'Equalize': equalize,\n","        'Invert': invert,\n","        'Rotate': rotate,\n","        'Posterize': posterize,\n","        'Solarize': solarize_arg,\n","        'SolarizeAdd': solarize_add,\n","        'Color': color,\n","        'Contrast': contrast,\n","        'Brightness': brightness,\n","        'Sharpness': sharpness,\n","        'ShearX': shear_x,\n","        'ShearY': shear_y,\n","        'TranslateX': translate_x,\n","        'TranslateY': translate_y,\n","        'Cutout': cutout,\n","        'Identity': identity,\n","    }\n","\n","    available_ops = [\n","        'AutoContrast', 'Equalize', 'Invert', 'Rotate', 'Posterize',\n","        'Solarize', 'Color', 'Contrast', 'Brightness', 'Sharpness',\n","        'ShearX', 'ShearY', 'TranslateX', 'TranslateY', 'Cutout',\n","    ]\n","\n","    for (i, op_name) in enumerate(available_ops):\n","        func = NAME_TO_FUNC[op_name]\n","        args = level_to_arg(4, 4)[op_name](16)\n","        print(args)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["()\n","()\n","()\n","tf.Tensor(-48.0, shape=(), dtype=float32)\n","tf.Tensor(6.4, shape=(), dtype=float32)\n","tf.Tensor(409.6, shape=(), dtype=float32)\n","(<tf.Tensor: shape=(), dtype=float32, numpy=2.98>,)\n","(<tf.Tensor: shape=(), dtype=float32, numpy=2.98>,)\n","(<tf.Tensor: shape=(), dtype=float32, numpy=2.98>,)\n","(<tf.Tensor: shape=(), dtype=float32, numpy=2.98>,)\n","tf.Tensor(0.48, shape=(), dtype=float32)\n","tf.Tensor(-0.48, shape=(), dtype=float32)\n","tf.Tensor(-6.4, shape=(), dtype=float32)\n","tf.Tensor(6.4, shape=(), dtype=float32)\n","tf.Tensor(6.4, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"cellView":"form","id":"8lCvf2VERloi"},"source":["#@title Self_augment\n","'''\n","reference:\n","https://github.com/google-research/google-research/tree/1f1741a985a0f2e6264adae985bde664a7993bd2/flax_models/cifar/datasets\n","'''\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","\n","'''\n","可能augment.py中的内容有问题 涉及文件augment.py的line 53，54\n","引用的库不一样，因为tensorflow.contrib已经停用，\n","使用的第三方：pip install tensorflow-addons\n","'''\n","import os\n","\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","import pandas as pd\n","\n","# from self_aug_func import *\n","\n","# 将对图片做augment的函数变成一个字典\n","NAME_TO_FUNC = {\n","    'AutoContrast': autocontrast,\n","    'Equalize': equalize,\n","    'Invert': invert,\n","    'Rotate': rotate,\n","    'Posterize': posterize,\n","    'Solarize': solarize_arg,\n","    'SolarizeAdd': solarize_add,\n","    'Color': color,\n","    'Contrast': contrast,\n","    'Brightness': brightness,\n","    'Sharpness': sharpness,\n","    'ShearX': shear_x,\n","    'ShearY': shear_y,\n","    'TranslateX': translate_x,\n","    'TranslateY': translate_y,\n","    'Cutout': cutout,\n","    'Identity': identity,\n","}\n","# 在某些函数中有一些需要一个替换的值，比如旋转中有一些位置的像素值需要补充\n","REPLACE_FUNCS = frozenset({\n","    'Rotate',\n","    'TranslateX',\n","    'ShearX',\n","    'SHearY',\n","    'TranslateY',\n","    'Cutout',\n","})\n","\n","\n","class RandAugment(object):\n","    def __init__(self, num_layers=2, magnitude=None, cutout_const=40, translate_const=100., available_ops=None):\n","        '''\n","        reference: https://arxiv.org/abs/1909.13719\n","        :param num_layers:\n","        :param magnitude:\n","        :param cutout_const:\n","        :param translate_const:\n","        :param avalilable_ops:\n","        '''\n","        super(RandAugment, self).__init__()\n","        self.num_layers = num_layers\n","        self.cutout_const = float(cutout_const)\n","        self.translate_const = float(translate_const)\n","        if available_ops is None:\n","            available_ops = [\n","                'AutoContrast', 'Equalize', 'Invert', 'Rotate', 'Posterize',\n","                'ShearX', 'ShearY', 'TranslateX', 'TranslateY', 'Cutout',\n","                'Solarize', 'Color', 'Contrast', 'Brightness', 'Sharpness',\n","            ]\n","        self.available_ops = available_ops\n","        self.magnitude = magnitude\n","\n","    def distort(self, image):\n","        '''\n","\n","        :param image:  shape:[HWC] C=3\n","        :return: 返回一个经过变化后的图片\n","        '''\n","        input_image_type = image.dtype\n","        image = tf.clip_by_value(image, tf.cast(0, input_image_type), tf.cast(255, input_image_type))\n","        image = tf.cast(image, tf.uint8)\n","\n","        prob = tf.random.uniform([], 0.2, 0.8, tf.float32)\n","\n","        for _ in range(self.num_layers):\n","            op_to_select = tf.random.uniform([], minval=0, maxval=len(self.available_ops), dtype=tf.int32)\n","            for (i, op_name) in enumerate(self.available_ops):\n","                func = NAME_TO_FUNC[op_name]  # 得到函数名称\n","                if i == op_to_select:\n","                    flag = tf.random.uniform([], 0., 1., prob.dtype)\n","                    if tf.math.greater_equal(prob, flag):\n","                        image = func(image)\n","\n","        image = tf.cast(image, dtype=input_image_type)\n","        return image\n","\n","\n","def unlabel_image(img_file, label):\n","    img = tf.io.read_file(img_file)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n","    ori_image = img  # 此图片作为原始图片\n","\n","    aug = RandAugment(\n","        cutout_const=IMG_SIZE // 8,\n","        translate_const=IMG_SIZE // 8,\n","        magnitude=AUGMENT_MAGNITUDE,\n","    )\n","\n","    aug_image, some_info = aug.distort(img)\n","    # aug_image = augment.cutout(aug_image, pad_size=IMG_SIZE // 8, replace=128)\n","    aug_image = tf.image.random_flip_left_right(aug_image)\n","\n","    aug_image = tf.cast(aug_image, tf.float32) / 255.0\n","    ori_image = tf.cast(ori_image, tf.float32) / 255.0\n","\n","    return {'ori_images': ori_image, 'aug_images': aug_image}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSpsmsJEDxj1","cellView":"form"},"source":["#@title UDa\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import numpy as np\n","\n","# import config\n","# from Model import Wrn28k\n","\n","\n","def UdaCrossEntroy(all_logits, l_labels, global_step):\n","    batch_size = BATCH_SIZE\n","    uda_data = UDA_DATA\n","    logits = {}\n","    labels = {}\n","    cross_entroy = {}\n","    masks = {}\n","    # 将网络的输出结果区分成 label ori aug 三个部分\n","    logits['l'], logits['ori'], logits['aug'] = tf.split(\n","        all_logits,\n","        [batch_size, batch_size * uda_data, batch_size * uda_data],\n","        axis=0,\n","    )\n","    # 对标签进行处理\n","    labels['l'] = l_labels\n","\n","    # ------------loss的计算---------\n","    # part1：有监督部分\n","    cross_entroy['l'] = tf.losses.CategoricalCrossentropy(\n","        from_logits=True,\n","        label_smoothing=LABEL_SMOOTHING,\n","        reduction=keras.losses.Reduction.NONE,)(labels['l'], logits['l'])\n","    '''\n","    probs = tf.nn.softmax(logits['l'], axis=-1)  # 将每张图片对应10个类别的输出转化为概率的形式\n","    correct_probs = tf.reduce_sum(labels['l'] * probs, axis=-1)  # 根据图片对应的label和概率计算出 预测正确类别的概率\n","    # 计算一个阈值l_threshold\n","    r = tf.cast(global_step, tf.float32) / tf.convert_to_tensor(MAX_STEPS, dtype=tf.float32)\n","    num_classes = tf.convert_to_tensor(NUM_CLASSES, tf.float32)\n","    l_threshold = r * (1. - 1. / num_classes) + 1. / num_classes\n","    masks['l'] = tf.math.less_equal(correct_probs, l_threshold)\n","    masks['l'] = tf.cast(masks['l'], tf.float32)\n","    masks['l'] = tf.stop_gradient(masks['l'])  # 如果对某图片预测的概率小于l_threahold,输出1，否则是0\n","    '''\n","    cross_entroy['l'] = tf.reduce_sum(cross_entroy['l']) / float(batch_size)\n","\n","    # part2: 无监督部分\n","    labels['ori'] = tf.nn.softmax(logits['ori'] / tf.convert_to_tensor(UDA_TEMP), axis=-1)\n","    labels['ori'] = tf.stop_gradient(labels['ori'])\n","    # tf.nn.log_softmax: 设一张图片对应3个类别的输出为o1，o2，o3 ==>\n","    # b = log(sum(exp(o1) + exp(o2) + exp(o3)))  new_o1=o1-b, new_o2=o2-b ... 恒负，大小关系不变\n","    cross_entroy['u'] = (\n","            labels['ori'] * tf.nn.log_softmax(logits['aug'], axis=-1)\n","    )\n","\n","    largest_probs = tf.reduce_max(labels['ori'], axis=-1, keepdims=True)\n","\n","    masks['u'] = tf.math.greater_equal(largest_probs, tf.constant(UDA_THRESHOLD))  # 判断最大概率是否大于阈值\n","    masks['u'] = tf.cast(masks['u'], DTYPE)\n","    masks['u'] = tf.stop_gradient(masks['u'])\n","    # 极端情况，当ori的预测完全准确，即class i = 1, 其他类别为0时，\n","    # aug的class i最大，即最大的负数，两者相乘再取负，就是一个非常接近于0的数字\n","    cross_entroy['u'] = tf.reduce_sum(-cross_entroy['u'] * masks['u']) / \\\n","                        tf.convert_to_tensor((batch_size * uda_data), dtype=DTYPE)\n","\n","    return logits, labels, masks, cross_entroy\n","\n","\n","# if __name__ == '__main__':\n","#     # 制作数据\n","#     l_images = np.random.random((1, 32, 32, 3))\n","#     l_images = tf.convert_to_tensor(l_images, dtype=DTYPE)\n","#     ori_images = np.random.random((1 * UDA_DATA, 32, 32, 3))\n","#     ori_images = tf.convert_to_tensor(ori_images, dtype=DTYPE)\n","#     aug_images = np.random.random((1 * UDA_DATA, 32, 32, 3))\n","#     aug_images = tf.convert_to_tensor(aug_images, dtype=DTYPE)\n","#     all_images = tf.concat([l_images, ori_images, aug_images], axis=0)  # shape [3, 32, 32, 3]\n","\n","#     l_labels = np.array([2])\n","#     l_labels = tf.convert_to_tensor(l_labels, dtype=tf.int32)\n","#     l_labels = tf.raw_ops.OneHot(indices=l_labels, depth=NUM_CLASSES, on_value=1.0, off_value=0)\n","#     l_labels = tf.cast(l_labels, DTYPE)\n","\n","#     # 构建teacher模型，产生输出\n","#     teacher = Wrn28k(num_inp_filters=3, k=2)\n","#     output = teacher(x=all_images)  # shape=[15, 10]\n","\n","#     logits, labels, masks, cross_entroy = UdaCrossEntroy(output, l_labels, 1)\n","#     print('logits: ', logits.keys())\n","#     print('labels: ', labels.keys())\n","#     print('masks: ', masks.keys())\n","#     # print('cross entroy: ', cross_entroy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEFmWImkDNid"},"source":["#@title Test\n","import os\n","\n","# from WideResnet import WideResnet\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","import pandas as pd\n","\n","# import config\n","\n","\n","def test(student, file_paths, labels):\n","    student.training = False\n","    # 准备数据\n","    # df_label = pd.read_csv(TEST_FILE_PATH)\n","    # file_paths = df_label['file_name'].values\n","    # labels = df_label['label'].values\n","\n","    # testing\n","    total_num = int(len(labels)/2)\n","    corrent_num = 0\n","    for i in range(total_num):\n","        img_file = file_paths[i]\n","        label = int(labels[i])\n","\n","        # 对图片的处理\n","        img = tf.io.read_file(img_file)\n","        img = tf.image.decode_jpeg(img, channels=3)\n","        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n","        img = tf.cast(img, dtype=DTYPE) / 255.0\n","        img = tf.expand_dims(img, axis=0)\n","        mean = tf.expand_dims(tf.convert_to_tensor([0.3684, 0.3684, 0.3684], dtype=DTYPE), axis=0)\n","        std = tf.expand_dims(tf.convert_to_tensor([0.0737, 0.0737, 0.0737], dtype=DTYPE), axis=0)\n","        img = (img - mean) / std\n","\n","        # 网络\n","        output = student(img)\n","        output = tf.nn.softmax(output)\n","        class_index = tf.squeeze(tf.math.argmax(output, axis=1))\n","\n","        if class_index == label:\n","            corrent_num += 1\n","    accuracy = float(corrent_num) / float(total_num) * 100.\n","    student.training = True\n","    return accuracy\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xd5evraDERY","cellView":"form","executionInfo":{"status":"ok","timestamp":1627719958418,"user_tz":-60,"elapsed":237,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"0644b069-a65c-40f3-b3f4-e53bd04e3f9a"},"source":["#@title learning rate\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","# import config\n","\n","\n","class LearningRate(object):\n","    def __init__(self, initial_lr, num_warmup_steps, num_wait_steps=None):\n","        if initial_lr is None:\n","            raise ValueError(f'initial_lr is error in learningRate file')\n","        if num_warmup_steps is None:\n","            raise ValueError(f'num_warmup_steps is error in learningRate file')\n","        if num_wait_steps is None:\n","            raise ValueError(f'num_wait_steps is error in learningRate file')\n","\n","        # initial_lr = initial_lr * BATCH_SIZE / 256\n","        self.initial_lr = initial_lr\n","        self.num_warmup_steps = num_warmup_steps\n","        self.num_wait_steps = num_wait_steps\n","\n","        if LR_DECAY_TYPE == 'constant':\n","            self.lr = tf.constant(self.initial_lr, dtype=tf.float32)\n","\n","        elif LR_DECAY_TYPE == 'exponential':\n","            self.lr = keras.optimizers.schedules.ExponentialDecay(\n","                initial_learning_rate=self.initial_lr,\n","                decay_steps=NUM_DECAY_STEPS,\n","                decay_rate=LR_DECAY_RATE,\n","            )\n","\n","        elif LR_DECAY_TYPE == 'cosine':\n","            self.lr = keras.experimental.CosineDecay(\n","                initial_learning_rate=self.initial_lr,\n","                decay_steps=MAX_STEPS - self.num_wait_steps - self.num_warmup_steps,\n","                alpha=0.0\n","            )\n","        else:\n","            raise ValueError(f'unknown lr_decay_type in py')\n","\n","    def __call__(self, global_step):\n","        global_step = global_step - self.num_wait_steps\n","        if LR_DECAY_TYPE == 'constant':\n","            learn_rate = self.lr\n","        else:\n","            learn_rate = self.lr.__call__(global_step)\n","\n","        r = tf.constant((global_step + 1), tf.float32) / tf.constant(self.num_warmup_steps, tf.float32)\n","        warmup_lr = self.initial_lr * r\n","        lr = tf.cond(\n","            tf.cast(global_step, tf.int32) < tf.cast(self.num_warmup_steps, tf.int32),\n","            lambda: warmup_lr,\n","            lambda: learn_rate,\n","        )\n","        lr = tf.cond(global_step < 0, lambda: tf.constant(0., tf.float32), lambda: lr)\n","        return lr\n","\n","\n","'''\n","def LearningRate(initial_lr, num_warmup_steps, num_wait_steps):\n","    if initial_lr is None:\n","        raise ValueError(f'initial_lr is error in learningRate file')\n","    if num_warmup_steps is None:\n","        raise ValueError(f'num_warmup_steps is error in learningRate file')\n","    if num_wait_steps is None:\n","        raise ValueError(f'num_wait_steps is error in learningRate file')\n","    initial_lr = initial_lr * BATCH_SIZE / 256\n","    if LR_DECAY_TYPE == 'constant':\n","        lr = tf.constant(initial_lr, dtype=tf.float32)\n","    elif LR_DECAY_TYPE == 'exponential':\n","        lr = keras.optimizers.schedules.ExponentialDecay(\n","            initial_learning_rate=initial_lr,\n","            decay_steps=NUM_DECAY_STEPS,\n","            decay_rate=LR_DECAY_RATE,\n","        )\n","    elif LR_DECAY_TYPE == 'cosine':\n","        lr = keras.experimental.CosineDecay(\n","            initial_learning_rate=initial_lr,\n","            decay_steps=MAX_STEPS - num_wait_steps - num_warmup_steps,\n","            alpha=0.0\n","        )\n","    else:\n","        raise ValueError(f'unknown lr_decay_type in py')\n","    return lr\n","'''\n","\n","import math\n","def lr_lambda(current_step):\n","    if current_step < 0:\n","        return float(current_step) / float(max(1, 0))\n","\n","    progress = float(current_step - 0) / \\\n","               float(max(1, 10 - 0))\n","    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(0.5) * 2.0 * progress)))\n","\n","\n","if __name__ == '__main__':\n","    for i in range(10):\n","        print(lr_lambda(i))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n","0.9755282581475768\n","0.9045084971874737\n","0.7938926261462366\n","0.6545084971874737\n","0.5\n","0.34549150281252633\n","0.2061073738537635\n","0.09549150281252633\n","0.024471741852423234\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9gnHT8aeA7sb","cellView":"form"},"source":["#@title C Dataset MLP\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# import config\n","import sys  \n","sys.path.insert(0, '/content/drive/MyDrive/Thesis/MPL')\n","\n","# from Self_augment import RandAugment\n","\n","\n","def normalize_image(img, label):\n","    '''\n","    图片的归一化\n","    :param img:\n","    :param label:\n","    :return:\n","    '''\n","    return tf.cast(img, tf.float32) / 255.0, label\n","\n","\n","# 制作有标签的数据集\n","def label_image(img_file, label):\n","    '''\n","    获取图片，对图片做水平翻转 随机剪裁等， label变为onehot\n","    :param img_file:\n","    :param label:\n","    :return:\n","    '''\n","    # 对图片的处理\n","    img = tf.io.read_file(img_file)\n","    # img = tf.image.grayscale_to_rgb(img, name=None)\n","    # img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE, 3] )\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.random_flip_left_right(img)\n","    img = tf.image.resize(img, (IMG_SIZE + 5, IMG_SIZE + 5))\n","    img = tf.image.random_crop(img, (IMG_SIZE, IMG_SIZE, 3))\n","    img = tf.cast(img, DTYPE) / 255.0\n","    mean = tf.expand_dims(tf.convert_to_tensor([0.3684, 0.3684, 0.3684], dtype=DTYPE), axis=0)\n","    std = tf.expand_dims(tf.convert_to_tensor([0.0740, 0.0740, 0.0740], dtype=DTYPE), axis=0)\n","    img = (img-mean)/std\n","    # 对标签的处理\n","    label = tf.raw_ops.OneHot(indices=label, depth=NUM_CLASSES, on_value=1.0, off_value=0)\n","    label = tf.cast(label, dtype=DTYPE)\n","    return {'images': img, 'labels': label}\n","\n","\n","# 制作无标签的数据集\n","def unlabel_image(img_file, label):\n","    '''\n","    处理无标签数据\n","    :param img_file:\n","    :param label:\n","    :return: 两张图片，一张经过轻微变换后的图片称为ori_image 一张经过较为剧烈变化后的图片，称为aug_images\n","    '''\n","    img = tf.io.read_file(img_file)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n","    ori_image = img  # 此图片作为原始图片\n","\n","    aug = RandAugment(\n","        cutout_const=IMG_SIZE // 8,\n","        translate_const=IMG_SIZE // 8,\n","        magnitude=AUGMENT_MAGNITUDE,\n","    )\n","    # aug_image = mask_label(img)\n","    aug_image = aug.distort(img)\n","    \n","    # aug_image = augment.cutout(aug_image, pad_size=IMG_SIZE // 8, replace=128)\n","    aug_image = tf.image.random_flip_left_right(aug_image)\n","\n","    aug_image = tf.cast(aug_image, DTYPE) / 255.0\n","    ori_image = tf.cast(ori_image, DTYPE) / 255.0\n","\n","    mean = tf.expand_dims(tf.convert_to_tensor([0.2153,0.2153,0.2153], dtype=DTYPE), axis=0)\n","    std = tf.expand_dims(tf.convert_to_tensor([0.2196, 0.2196, 0.2196], dtype=DTYPE), axis=0)\n","\n","    aug_image = (aug_image-mean)/std\n","    ori_image = (ori_image-mean)/std\n","\n","    return {'ori_images': ori_image, 'aug_images': aug_image}\n","\n","\n","def merge_dataset(label_data, unlabel_data):\n","    return label_data['images'], label_data['labels'], unlabel_data['ori_images'], unlabel_data['aug_images']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"Gw6FBnshe72M","executionInfo":{"status":"ok","timestamp":1627682307281,"user_tz":-60,"elapsed":636,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"0bf48487-44bc-41d8-84c2-e0c0209d416d"},"source":["w = cv2.imread(dfc3_['image'][250])\n","plt.imshow(w)\n","w.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(85, 93, 3)"]},"metadata":{"tags":[]},"execution_count":98},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"OofZw1BWNMnx","executionInfo":{"status":"ok","timestamp":1627683882047,"user_tz":-60,"elapsed":299,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"a81bea81-6865-4d54-ccbc-a086e05e2df0"},"source":["dfc_.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/0.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/1.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/2.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/3.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Thesis/pos/x_/4.jpg</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        image label\n","0  /content/drive/MyDrive/Thesis/pos/x_/0.jpg     1\n","1  /content/drive/MyDrive/Thesis/pos/x_/1.jpg     2\n","2  /content/drive/MyDrive/Thesis/pos/x_/2.jpg     0\n","3  /content/drive/MyDrive/Thesis/pos/x_/3.jpg     0\n","4  /content/drive/MyDrive/Thesis/pos/x_/4.jpg     0"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8nsCaSe87M0f","executionInfo":{"status":"error","timestamp":1627750001675,"user_tz":-60,"elapsed":10265629,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"0b31976a-00dd-49dc-be92-1c23940d4d1d"},"source":["#@title C MLPTrain\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","import tensorflow_addons as tfa\n","# from WideResnet import WideResnet\n","from copy import deepcopy\n","import sklearn\n","from sklearn import preprocessing\n","\n","# import config\n","# from Model import Wrn28k\n","# from UdaCrossEntroy import UdaCrossEntroy\n","# from learningRate import LearningRate\n","# from Dataset import label_image\n","# from Dataset import unlabel_image\n","# from Dataset import merge_dataset\n","# from test import test\n","\n","\n","def my_update(model, model_):\n","    for i in range(len(model_)):\n","        model.weights[i] = model.weights[i].assign(\n","            model.weights[i]*(1-EMA)+model_[i]*EMA)\n","    model_ = deepcopy(model.weights)\n","    return model, model_\n","\n","\n","if __name__ == '__main__':\n","    AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","    # 有标签的数据集 batch_size=BATCH_SIZE\n","    # df_label = pd.read_csv(LABEL_FILE_PATH)\n","    le = preprocessing.LabelEncoder()\n","    dfc_['label'] = le.fit_transform(dfc_.label.values)\n","\n","    u_file_paths = []\n","    u_labels = []\n","    for i in range(0, len(data)): \n","      path = root + data[\"fullPath\"][i]#2499\n","      path = path.replace('\\\\', '/')\n","      path = path.replace('.png', '.jpg')\n","      u_file_paths.append(path)\n","      if data[\"Status\"][i] ==\"Cancer\":\n","        u_labels.append(3)\n","      elif data[\"Status\"][i] == \"Normal\":\n","        u_labels.append(1)\n","      elif data[\"Status\"][i] == \"Benign\" :\n","        u_labels.append(2)\n","  \n","    train_dfc_ = dfc_[:int(len(dfc_)*0.7)] \n","    test_dfc_ = dfc_[-int(len(dfc_)*0.7):]\n","    t_file_paths = test_dfc_['image'].values\n","    t_labels = test_dfc_['label'].values\n","    file_paths = train_dfc_['image'].values\n","    labels = train_dfc_['label'].values\n","    ds_label_train = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n","    ds_label_train = ds_label_train \\\n","        .map(label_image, num_parallel_calls=AUTOTUNE) \\\n","        .shuffle(buffer_size=4000) \\\n","        .batch(BATCH_SIZE, drop_remainder=True) \\\n","        .prefetch(AUTOTUNE)\n","\n","    # 无标签的数据集 batch_size=BATCH_SIZE*UDA_DATA\n","    # df_unlabel = pd.read_csv(UNLABEL_FILE_PATH)\n","    # file_paths = df_unlabel['name'].values\n","    # labels = df_unlabel['label'].values\n","    ds_unlabel_train = tf.data.Dataset.from_tensor_slices((u_file_paths, u_labels))\n","    ds_unlabel_train = ds_unlabel_train \\\n","        .map(unlabel_image, num_parallel_calls=AUTOTUNE) \\\n","        .shuffle(buffer_size=50000) \\\n","        .batch(BATCH_SIZE * UDA_DATA, drop_remainder=True) \\\n","        .prefetch(AUTOTUNE)\n","\n","    # 将有标签数据和无标签数据整合成最终的数据形式\n","    ds_train = tf.data.Dataset.zip((ds_label_train, ds_unlabel_train))\n","    ds_train = ds_train.map(merge_dataset)\n","\n","    # 构建teacher模型\n","    if TEA_CONTINUE:\n","        print('continue teacher training')\n","        teacher = modelT#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","        teacher.load_weights(TEA_LOAD_PATH)\n","        teacher.training = True\n","    else:\n","        # teacher = Wrn28k(num_inp_filters=3, k=2)\n","        teacher =  modelT#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","\n","    # 构建student模型\n","    if STD_CONTINUE:\n","        print('continue student training')\n","        student =  modelS#efficientunet.get_efficient_unet_b0(input_shape,  pretrained=False)\n","        student.load_weights(STD_LOAD_PATH)\n","        student.training = True\n","        student = tf.saved_model.load(STD_LOAD_PATH)\n","    else:\n","        # student = Wrn28k(num_inp_filters=3, k=2)\n","        student =  modelS#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","    student_ = student.weights\n","\n","    # 定义teacher的损失函数，损失函数之一为UdaCrossEntroy\n","    mpl_loss = tf.losses.CategoricalCrossentropy(\n","        reduction=tf.losses.Reduction.NONE,\n","        from_logits=True,\n","    )\n","    # 定义student的损失函数， PS：teacher的损失函数为UdaCrossEntroy\n","    s_unlabel_loss = tf.losses.CategoricalCrossentropy(\n","        label_smoothing=LABEL_SMOOTHING,\n","        from_logits=True,\n","        reduction=tf.keras.losses.Reduction.NONE,\n","    )\n","\n","    s_label_loss = tf.losses.CategoricalCrossentropy(\n","        reduction=tf.keras.losses.Reduction.NONE,\n","        from_logits=True,\n","    )\n","\n","    # 定义teacher的学习率\n","    Tea_lr_fun = LearningRate(\n","        TEACHER_LR,\n","        TEACHER_LR_WARMUP_STEPS,\n","        TEACHER_NUM_WAIT_STEPS\n","    )\n","    # 定义student的学习率\n","    Std_lr_fun = LearningRate(\n","        STUDENT_LR,\n","        STUDENT_LR_WARMUP_STEPS,\n","        STUDENT_LR_WAIT_STEPS\n","    )\n","\n","    global_step = 62*CONTINUE_EPOCH\n","    print(f'start training from global step {global_step}......')\n","    TBacc = 0.78\n","    Tacc = 0\n","    SBacc = 0.31\n","    Sacc = 0\n","    epochs = MAX_EPOCHS - CONTINUE_EPOCH\n","    for epoch in range(epochs):\n","        TLOSS = 0\n","        TLOSS_1 = 0\n","        TLOSS_2 = 0\n","        TLOSS_3 = 0\n","        SLOSS = 0\n","        for batch_idx, (l_images, l_labels, ori_images, aug_images) in enumerate(ds_train):\n","            global_step += 1\n","            all_images = tf.concat([l_images, ori_images, aug_images], axis=0)  # shape [15, 32, 32, 3]\n","            u_aug_and_l_images = tf.concat([aug_images, l_images], axis=0)\n","            # step1：经过teacher，得到输出\n","            with tf.GradientTape() as t_tape:\n","                output = teacher(all_images)  # shape=[15, 10]\n","                logits, labels, masks, cross_entroy = UdaCrossEntroy(output, l_labels, global_step)\n","            # step2：1st call student -----------------------------\n","            with tf.GradientTape() as s_tape:\n","                logits['s_on_aug_and_l'] = student(u_aug_and_l_images)  # shape=[8, 10]\n","                logits['s_on_u'], logits['s_on_l_old'] = tf.split(\n","                    logits['s_on_aug_and_l'],\n","                    [aug_images.shape[0], l_images.shape[0]],\n","                    axis=0\n","                )\n","                cross_entroy['s_on_u'] = s_unlabel_loss(\n","                    y_true=tf.stop_gradient(tf.nn.softmax(logits['aug'], -1)),\n","                    y_pred=logits['s_on_u']\n","                )\n","                # 计算损失函数\n","                cross_entroy['s_on_u'] = tf.reduce_sum(cross_entroy['s_on_u']) / \\\n","                                         tf.convert_to_tensor(BATCH_SIZE * UDA_DATA, dtype=tf.float32)\n","                SLOSS += cross_entroy['s_on_u']\n","                # for taylor\n","                cross_entroy['s_on_l_old'] = s_label_loss(\n","                    y_true=labels['l'],\n","                    y_pred=logits['s_on_l_old']\n","                )\n","\n","                cross_entroy['s_on_l_old'] = tf.reduce_sum(cross_entroy['s_on_l_old']) / \\\n","                                             tf.convert_to_tensor(BATCH_SIZE, dtype=tf.float32)\n","            # 反向传播，更新student的参数-------\n","            StudentLR = Std_lr_fun.__call__(global_step=global_step)\n","            StdOptim = keras.optimizers.SGD(\n","                learning_rate=StudentLR,\n","                momentum=0.9,\n","                nesterov=True,\n","                # weight_decay=5e-4,\n","            )\n","            # StdOptim = keras.optimizers.Adam(learning_rate=StudentLR)\n","            GStud_unlabel = s_tape.gradient(cross_entroy['s_on_u'], student.trainable_variables)\n","            GStud_unlabel, _ = tf.clip_by_global_norm(GStud_unlabel, GRAD_BOUND)\n","            StdOptim.apply_gradients(zip(GStud_unlabel, student.trainable_variables))\n","            # 如何更新参数\n","            student, student_ = my_update(student, student_)\n","\n","            # step3: 2nd call student ------------------------------\n","            logits['s_on_l_new'] = student(l_images)\n","            cross_entroy['s_on_l_new'] = s_label_loss(\n","                y_true=labels['l'],\n","                y_pred=logits['s_on_l_new']\n","            )\n","            cross_entroy['s_on_l_new'] = tf.reduce_sum(cross_entroy['s_on_l_new']) / \\\n","                                         tf.convert_to_tensor(BATCH_SIZE, dtype=DTYPE)\n","            dot_product = cross_entroy['s_on_l_new'] - cross_entroy['s_on_l_old']\n","            limit = 3.0**(0.5)\n","            moving_dot_product = tf.random_uniform_initializer(minval=-limit, maxval=limit)(shape=dot_product.shape)\n","            moving_dot_product = tf.Variable(initial_value=moving_dot_product, trainable=False, dtype=DTYPE)\n","            moving_dot_product_update = moving_dot_product.assign_sub(0.01 * (moving_dot_product - dot_product))\n","            dot_product = dot_product - moving_dot_product\n","            dot_product = tf.stop_gradient(dot_product)\n","            # step4: 求teacher的损失函数\n","            with t_tape:\n","                # label = tf.math.argmax(tf.nn.softmax(logits['aug'], axis=-1), axis=-1)\n","                # label = tf.raw_ops.OneHot(indices=label, depth=NUM_CLASSES, on_value=1.0, off_value=0)\n","                cross_entroy['mpl'] = mpl_loss(\n","                    # y_true=tf.stop_gradient(label),\n","                    y_true=tf.stop_gradient(tf.nn.softmax(logits['aug'], axis=-1)),\n","                    y_pred=logits['aug']\n","                )  # 恒正\n","                cross_entroy['mpl'] = tf.reduce_sum(cross_entroy['mpl']) / \\\n","                                      tf.convert_to_tensor(BATCH_SIZE * UDA_DATA, dtype=DTYPE)\n","                uda_weight = UDA_WEIGHT * tf.math.minimum(\n","                    1., tf.cast(global_step, DTYPE) / float(UDA_STEPS)\n","                )\n","                # if StudentLR == 0:\n","                #     dot_product = 0\n","                teacher_loss = cross_entroy['u'] * uda_weight + \\\n","                               cross_entroy['l'] + \\\n","                               cross_entroy['mpl'] * dot_product\n","\n","                TLOSS += teacher_loss\n","                TLOSS_1 += (cross_entroy['u'] * uda_weight)\n","                TLOSS_2 += cross_entroy['l']\n","                TLOSS_3 += cross_entroy['mpl'] * dot_product\n","            # 反向传播，更新teacher的参数-------\n","            TeacherLR = Tea_lr_fun.__call__(global_step=global_step)\n","            TeaOptim = keras.optimizers.SGD(\n","                learning_rate=TeacherLR,\n","                momentum=0.9,\n","                nesterov=True,\n","                # weight_decay=5e-4,\n","            )\n","            # TeaOptim = keras.optimizers.Adam(learning_rate=TeacherLR)\n","            GTea = t_tape.gradient(teacher_loss, teacher.trainable_variables)\n","            GTea, _ = tf.clip_by_global_norm(GTea, GRAD_BOUND)\n","            TeaOptim.apply_gradients(zip(GTea, teacher.trainable_variables))\n","\n","            if (batch_idx + 1) % LOG_EVERY == 0:\n","                TLOSS = TLOSS / LOG_EVERY\n","                TLOSS_1 = TLOSS_1 / LOG_EVERY\n","                TLOSS_2 = TLOSS_2 / LOG_EVERY\n","                TLOSS_3 = TLOSS_3 / LOG_EVERY\n","                SLOSS = SLOSS / LOG_EVERY\n","                print(f'global: %4d' % global_step + ',[epoch:%4d/' % (epoch+CONTINUE_EPOCH) + 'EPOCH: %4d] \\t' % epochs\n","                      + '[U:%.4f' % (TLOSS_1) + ', L:%.4f' % (TLOSS_2) + ', M:%.4f' % (\n","                          TLOSS_3) + ']' + '[TLoss: %.4f]' % TLOSS + '/[SLoss: %.4f]' % SLOSS\n","                      + '\\t[TLR: %.6f' % TeacherLR + ']/[SLR: %.6f]' % StudentLR)\n","                TLOSS = 0\n","                TLOSS_1 = 0\n","                TLOSS_2 = 0\n","                TLOSS_3 = 0\n","                SLOSS = 0\n","        # 测试teacher在test上的acc\n","        if epoch % 5 == 0:\n","            Tacc = test(teacher, t_file_paths, t_labels)\n","            print(f'testing teacher model ... acc: {Tacc}')\n","        # 测试student在test上的acc，当student开始训练的时候\n","        if (StudentLR > 0) and (epoch % 5 == 0):\n","            Sacc = test(student, t_file_paths, t_labels)\n","            print(f'testing ... acc: {Sacc}')\n","        # 保存weights\n","        if Tacc > TBacc:\n","            Tsave_path = TEA_SAVE_PATH  # + str(epoch + 1) + '_' + str(batch_idx + 1)\n","            teacher.save_weights(Tsave_path)\n","            # tf.saved_model.save(teacher, Tsave_path)\n","            TBacc = Tacc\n","            print(f'saving for TBacc {TBacc}, Tpath:{Tsave_path}')\n","        if Sacc > SBacc:\n","            Ssave_path = STD_SAVE_PATH  # + str(epoch + 1) + '_' + str(batch_idx + 1)\n","            student.save_weights(Ssave_path)\n","            SBacc = Sacc\n","            print(f'saving for SBacc {SBacc}, Spath:{Ssave_path}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["global: 59920,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0900, M:-0.1077][TLoss: 0.9822]/[SLoss: 1.0986]\t[TLR: 0.000141]/[SLR: 0.000131]\n","global: 59940,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0870, M:-0.0331][TLoss: 1.0539]/[SLoss: 1.0986]\t[TLR: 0.000141]/[SLR: 0.000131]\n","global: 59960,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0899, M:0.0577][TLoss: 1.1476]/[SLoss: 1.0986]\t[TLR: 0.000141]/[SLR: 0.000131]\n","global: 59980,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0946, M:0.2970][TLoss: 1.3916]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000131]\n","global: 60000,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0865, M:-0.0024][TLoss: 1.0841]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000131]\n","global: 60020,[epoch: 895/EPOCH: 1035] \t[U:0.0000, L:1.0890, M:0.0218][TLoss: 1.1108]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000130]\n","testing teacher model ... acc: 41.15138592750533\n","testing ... acc: 41.15138592750533\n","global: 60049,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0846, M:-0.0907][TLoss: 0.9939]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000130]\n","global: 60069,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0941, M:0.0994][TLoss: 1.1935]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000130]\n","global: 60089,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0875, M:-0.0341][TLoss: 1.0534]/[SLoss: 1.0986]\t[TLR: 0.000140]/[SLR: 0.000130]\n","global: 60109,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0828, M:-0.2736][TLoss: 0.8092]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000130]\n","global: 60129,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0780, M:0.2046][TLoss: 1.2826]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000130]\n","global: 60149,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0924, M:0.3547][TLoss: 1.4471]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000129]\n","global: 60169,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0968, M:0.1599][TLoss: 1.2567]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000129]\n","global: 60189,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0946, M:-0.1374][TLoss: 0.9572]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000129]\n","global: 60209,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0811, M:0.1679][TLoss: 1.2490]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000129]\n","global: 60229,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0901, M:-0.2642][TLoss: 0.8259]/[SLoss: 1.0986]\t[TLR: 0.000139]/[SLR: 0.000129]\n","global: 60249,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0870, M:0.1531][TLoss: 1.2401]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000129]\n","global: 60269,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0974, M:0.1616][TLoss: 1.2591]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60289,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0817, M:0.0928][TLoss: 1.1745]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60309,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0910, M:-0.0770][TLoss: 1.0140]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60329,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0977, M:-0.1459][TLoss: 0.9518]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60349,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0843, M:0.2560][TLoss: 1.3403]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60369,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.1018, M:-0.2218][TLoss: 0.8799]/[SLoss: 1.0986]\t[TLR: 0.000138]/[SLR: 0.000128]\n","global: 60389,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0851, M:0.3576][TLoss: 1.4426]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000128]\n","global: 60409,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0900, M:-0.1450][TLoss: 0.9450]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000127]\n","global: 60429,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0766, M:-0.0189][TLoss: 1.0577]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000127]\n","global: 60449,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0905, M:-0.1248][TLoss: 0.9657]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000127]\n","global: 60469,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0869, M:0.1197][TLoss: 1.2066]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000127]\n","global: 60489,[epoch: 896/EPOCH: 1035] \t[U:0.0000, L:1.0905, M:-0.1972][TLoss: 0.8933]/[SLoss: 1.0986]\t[TLR: 0.000137]/[SLR: 0.000127]\n","global: 60518,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0997, M:0.4140][TLoss: 1.5137]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000127]\n","global: 60538,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0864, M:-0.4869][TLoss: 0.5995]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000126]\n","global: 60558,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0963, M:-0.2323][TLoss: 0.8640]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000126]\n","global: 60578,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0885, M:0.2289][TLoss: 1.3174]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000126]\n","global: 60598,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0878, M:-0.2948][TLoss: 0.7930]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000126]\n","global: 60618,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0919, M:0.1984][TLoss: 1.2903]/[SLoss: 1.0986]\t[TLR: 0.000136]/[SLR: 0.000126]\n","global: 60638,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0914, M:0.0924][TLoss: 1.1838]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000126]\n","global: 60658,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0733, M:-0.0116][TLoss: 1.0617]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60678,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0824, M:-0.2515][TLoss: 0.8308]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60698,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0890, M:0.3143][TLoss: 1.4033]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60718,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0986, M:0.4052][TLoss: 1.5038]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60738,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0870, M:-0.0287][TLoss: 1.0583]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60758,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0860, M:0.0929][TLoss: 1.1788]/[SLoss: 1.0986]\t[TLR: 0.000135]/[SLR: 0.000125]\n","global: 60778,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0772, M:0.1793][TLoss: 1.2565]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000125]\n","global: 60798,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0832, M:0.2163][TLoss: 1.2995]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60818,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0837, M:-0.0182][TLoss: 1.0654]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60838,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0967, M:-0.0297][TLoss: 1.0670]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60858,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0826, M:-0.5311][TLoss: 0.5515]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60878,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0846, M:-0.1179][TLoss: 0.9667]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60898,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0901, M:-0.2021][TLoss: 0.8880]/[SLoss: 1.0986]\t[TLR: 0.000134]/[SLR: 0.000124]\n","global: 60918,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0924, M:-0.1721][TLoss: 0.9202]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 60938,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.1037, M:-0.0073][TLoss: 1.0964]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 60958,[epoch: 897/EPOCH: 1035] \t[U:0.0000, L:1.0906, M:0.8179][TLoss: 1.9085]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 60987,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0815, M:-0.0194][TLoss: 1.0621]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 61007,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0876, M:0.0904][TLoss: 1.1780]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 61027,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0937, M:0.0675][TLoss: 1.1612]/[SLoss: 1.0986]\t[TLR: 0.000133]/[SLR: 0.000123]\n","global: 61047,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0825, M:-0.4879][TLoss: 0.5946]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61067,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0937, M:-0.4197][TLoss: 0.6739]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61087,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0789, M:-0.3931][TLoss: 0.6858]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61107,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0855, M:-0.1297][TLoss: 0.9558]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61127,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0985, M:-0.5408][TLoss: 0.5576]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61147,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0972, M:0.2001][TLoss: 1.2973]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61167,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0914, M:-0.0711][TLoss: 1.0203]/[SLoss: 1.0986]\t[TLR: 0.000132]/[SLR: 0.000122]\n","global: 61187,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0944, M:-0.1216][TLoss: 0.9728]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61207,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0937, M:-0.0035][TLoss: 1.0902]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61227,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0822, M:-0.0967][TLoss: 0.9854]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61247,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0921, M:-0.4074][TLoss: 0.6847]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61267,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0952, M:0.3573][TLoss: 1.4525]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61287,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0849, M:-0.2319][TLoss: 0.8530]/[SLoss: 1.0986]\t[TLR: 0.000131]/[SLR: 0.000121]\n","global: 61307,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0882, M:-0.5104][TLoss: 0.5779]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61327,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0860, M:-0.2573][TLoss: 0.8286]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61347,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0741, M:0.0916][TLoss: 1.1657]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61367,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0839, M:-0.0249][TLoss: 1.0590]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61387,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0921, M:0.1500][TLoss: 1.2421]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61407,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0955, M:0.0523][TLoss: 1.1478]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61427,[epoch: 898/EPOCH: 1035] \t[U:0.0000, L:1.0927, M:0.2112][TLoss: 1.3038]/[SLoss: 1.0986]\t[TLR: 0.000130]/[SLR: 0.000120]\n","global: 61456,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0789, M:-0.1547][TLoss: 0.9241]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61476,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0809, M:-0.1270][TLoss: 0.9539]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61496,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0816, M:-0.0656][TLoss: 1.0161]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61516,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.1002, M:-0.1781][TLoss: 0.9221]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61536,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.1005, M:-0.1848][TLoss: 0.9157]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61556,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0911, M:-0.2301][TLoss: 0.8609]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000119]\n","global: 61576,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.1009, M:-0.1596][TLoss: 0.9414]/[SLoss: 1.0986]\t[TLR: 0.000129]/[SLR: 0.000118]\n","global: 61596,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.1069, M:0.2988][TLoss: 1.4058]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61616,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0851, M:-0.1928][TLoss: 0.8923]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61636,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0809, M:-0.3751][TLoss: 0.7058]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61656,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0856, M:-0.0733][TLoss: 1.0123]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61676,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0892, M:0.1427][TLoss: 1.2319]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61696,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0782, M:-0.1424][TLoss: 0.9357]/[SLoss: 1.0986]\t[TLR: 0.000128]/[SLR: 0.000118]\n","global: 61716,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0894, M:-0.5235][TLoss: 0.5659]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61736,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0900, M:0.1304][TLoss: 1.2204]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61756,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0892, M:-0.5115][TLoss: 0.5778]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61776,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0821, M:0.3935][TLoss: 1.4756]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61796,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0977, M:-0.2086][TLoss: 0.8891]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61816,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0902, M:-0.2088][TLoss: 0.8815]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000117]\n","global: 61836,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0783, M:-0.0111][TLoss: 1.0672]/[SLoss: 1.0986]\t[TLR: 0.000127]/[SLR: 0.000116]\n","global: 61856,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0863, M:-0.0029][TLoss: 1.0834]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61876,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0910, M:-0.1361][TLoss: 0.9549]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61896,[epoch: 899/EPOCH: 1035] \t[U:0.0000, L:1.0921, M:-0.0758][TLoss: 1.0163]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61925,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0892, M:-0.1390][TLoss: 0.9501]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61945,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0971, M:0.4458][TLoss: 1.5429]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61965,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0865, M:-0.0795][TLoss: 1.0071]/[SLoss: 1.0986]\t[TLR: 0.000126]/[SLR: 0.000116]\n","global: 61985,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0963, M:0.2164][TLoss: 1.3127]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62005,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0820, M:0.0267][TLoss: 1.1087]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62025,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0865, M:-0.1780][TLoss: 0.9085]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62045,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0900, M:0.0368][TLoss: 1.1267]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62065,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0827, M:0.2458][TLoss: 1.3285]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62085,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0975, M:0.0413][TLoss: 1.1388]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000115]\n","global: 62105,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0924, M:0.1406][TLoss: 1.2330]/[SLoss: 1.0986]\t[TLR: 0.000125]/[SLR: 0.000114]\n","global: 62125,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0857, M:0.0768][TLoss: 1.1625]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62145,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0819, M:-0.0943][TLoss: 0.9875]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62165,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0802, M:0.2437][TLoss: 1.3239]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62185,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0986, M:0.1810][TLoss: 1.2796]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62205,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0934, M:-0.1860][TLoss: 0.9074]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62225,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0745, M:-0.0357][TLoss: 1.0388]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000114]\n","global: 62245,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0956, M:0.1557][TLoss: 1.2514]/[SLoss: 1.0986]\t[TLR: 0.000124]/[SLR: 0.000113]\n","global: 62265,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0824, M:-0.1169][TLoss: 0.9655]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","global: 62285,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0877, M:-0.6102][TLoss: 0.4775]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","global: 62305,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0872, M:0.2952][TLoss: 1.3825]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","global: 62325,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0926, M:-0.2260][TLoss: 0.8666]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","global: 62345,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0847, M:0.2584][TLoss: 1.3431]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","global: 62365,[epoch: 900/EPOCH: 1035] \t[U:0.0000, L:1.0918, M:0.2923][TLoss: 1.3841]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000113]\n","testing teacher model ... acc: 41.15138592750533\n","testing ... acc: 41.15138592750533\n","global: 62394,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0932, M:0.3010][TLoss: 1.3942]/[SLoss: 1.0986]\t[TLR: 0.000123]/[SLR: 0.000112]\n","global: 62414,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0751, M:0.3557][TLoss: 1.4308]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000112]\n","global: 62434,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0937, M:0.0707][TLoss: 1.1644]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000112]\n","global: 62454,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0965, M:-0.1930][TLoss: 0.9035]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000112]\n","global: 62474,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0916, M:-0.1820][TLoss: 0.9095]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000112]\n","global: 62494,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0789, M:-0.4146][TLoss: 0.6643]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000112]\n","global: 62514,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0937, M:0.0374][TLoss: 1.1311]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000111]\n","global: 62534,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0885, M:0.3841][TLoss: 1.4726]/[SLoss: 1.0986]\t[TLR: 0.000122]/[SLR: 0.000111]\n","global: 62554,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0784, M:0.0287][TLoss: 1.1071]/[SLoss: 1.0986]\t[TLR: 0.000121]/[SLR: 0.000111]\n","global: 62574,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0935, M:-0.2804][TLoss: 0.8131]/[SLoss: 1.0986]\t[TLR: 0.000121]/[SLR: 0.000111]\n","global: 62594,[epoch: 901/EPOCH: 1035] \t[U:0.0000, L:1.0976, M:0.2956][TLoss: 1.3931]/[SLoss: 1.0986]\t[TLR: 0.000121]/[SLR: 0.000111]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2527736fd0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mStdOptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGStud_unlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;31m# 如何更新参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# step3: 2nd call student ------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-2527736fd0d6>\u001b[0m in \u001b[0;36mmy_update\u001b[0;34m(model, model_)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         model.weights[i] = model.weights[i].assign(\n\u001b[0;32m---> 28\u001b[0;31m             model.weights[i]*(1-EMA)+model_[i]*EMA)\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \"\"\"\n\u001b[0;32m-> 2421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2427\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m       \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2430\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2183\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m     \"\"\"\n\u001b[0;32m-> 2185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \"\"\"\n\u001b[0;32m-> 2421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2427\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m       \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2430\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2183\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m     \"\"\"\n\u001b[0;32m-> 2185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1300\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mnon_trainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       children_weights = self._gather_children_attribute(\n\u001b[0;32m-> 1286\u001b[0;31m           'non_trainable_variables')\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0mnon_trainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchildren_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_gather_children_attribute\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m   2789\u001b[0m     }\n\u001b[1;32m   2790\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_self_tracked_trackables'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2791\u001b[0;31m       \u001b[0mnested_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2792\u001b[0m       return list(\n\u001b[1;32m   2793\u001b[0m           itertools.chain.from_iterable(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHjQ7pgDisr6","executionInfo":{"status":"ok","timestamp":1627684350254,"user_tz":-60,"elapsed":229,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"d585dadb-32a0-49f9-8a0b-b78aeba88ad0"},"source":["dfc_['image'].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5362,)"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldLOgn9XjEVI","executionInfo":{"status":"ok","timestamp":1627684383145,"user_tz":-60,"elapsed":253,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"0bc5808d-45ec-45e5-d72d-f0591938dbdd"},"source":["dfc_['label'].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5362,)"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"QdTkLiX3Z6XZ","executionInfo":{"status":"error","timestamp":1627682078796,"user_tz":-60,"elapsed":241,"user":{"displayName":"Antonio Franco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpZWpPk6ug7_9xt90pVX8z1iULSGekWi2cTqST=s64","userId":"09756366898940169615"}},"outputId":"0127ea07-4050-4359-e9c6-4c6d5b9d6702"},"source":["test_dfc_['label'][0]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 0 is not in range","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-b69893ce5433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dfc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"]}]},{"cell_type":"markdown","metadata":{"id":"ZYRx1ELs5Rcb"},"source":["# MPL"]},{"cell_type":"markdown","metadata":{"id":"GYqQ7sb-WI0l"},"source":["## *Config*"]},{"cell_type":"code","metadata":{"cellView":"form","id":"qoCHqKI8WIiJ"},"source":["import tensorflow as tf\n","#@markdown config\n","\n","\n","\n","\n","# about dataset\n","IMG_SIZE = 224 #@param {type:\"integer\"}\n","BATCH_SIZE = 8 #@param {type:\"integer\"}\n","# LABEL_FILE_PATH = '/content/cifar/label4000.csv' # google\n","# UNLABEL_FILE_PATH = '/content/cifar/train.csv'\n","\n","_MAX_LEVEL = 10\n","CUTOUT_CONST = 40.\n","TRANSLATE_CONST = 100.\n","REPLACE_COLOR = [128, 128, 128]\n","\n","\n","LABEL_FILE_PATH = '../input/cifar10/cifar/label4000.csv'  # kaggle\n","UNLABEL_FILE_PATH = '../input/cifar10/cifar/train.csv'\n","\n","\n","AUGMENT_MAGNITUDE = 8\n","SHUFFLE_SIZE = BATCH_SIZE * 16\n","DATA_LEN = 400  # 数据集的总长度\n","\n","# about model\n","NUM_XLA_SHARDS = -1\n","BATCH_NORM_EPSILON = 1e-3\n","BATCH_NORM_DECAY = 0.999\n","DROPOUT_RATE = 0.\n","DROPOUT = 0.2\n","NUM_CLASSES = 3\n","NUM_CLASS = 3\n","\n","# about training\n","LOG_EVERY = 20\n","SAVE_EVERY = 5\n","TEA_SAVE_PATH = '/content/drive/MyDrive/Thesis/weights/T'\n","STD_SAVE_PATH = '/content/drive/MyDrive/Thesis/weights/S'\n","\n","MAX_EPOCHS = 1920\n","MAX_STEPS = MAX_EPOCHS * (int(DATA_LEN / BATCH_SIZE)-1)\n","UDA_WEIGHT = 8  # uda的权重\n","UDA_STEPS = 2000\n","TEST_EVERY = 2\n","GRAD_BOUND = 1e9\n","EMA = 0.995\n","\n","\n","# continue train\n","TEA_CONTINUE = False\n","STD_CONTINUE = False\n","TEA_LOAD_PATH = '../input/weights/weights/T'\n","STD_LOAD_PATH = '../input/weights/weights/S'\n","CONTINUE_EPOCH = 885\n","\n","\n","# about testing\n","# TEST_FILE_PATH = '/content/cifar/test.csv'\n","TEST_FILE_PATH = '../input/cifar10/cifar/test.csv'\n","TEST_MODEL_PATH = './weights/S'\n","\n","# about UdaCrossEntroy\n","UDA_DATA = 1\n","LABEL_SMOOTHING = 0.15\n","UDA_TEMP = 0.7\n","UDA_THRESHOLD = 0.6\n","\n","# about learning rate\n","STUDENT_LR = 0.0005  # student\n","STUDENT_LR_WARMUP_STEPS = 4000\n","STUDENT_LR_WAIT_STEPS = 2000\n","TEACHER_LR = 0.0005  # teacher\n","TEACHER_LR_WARMUP_STEPS = 1000\n","TEACHER_NUM_WAIT_STEPS = 0\n","\n","LR_DECAY_TYPE = 'cosine'  # constant, exponential, cosine\n","NUM_DECAY_STEPS = 300\n","LR_DECAY_RATE = 0.97\n","\n","# about optimizer\n","OPTIM_TYPE = 'sgd'  # sgd, momentum, rmsprop\n","WEIGHT_DECAY = 5e-4\n","\n","\n","# dtype\n","DTYPE = tf.float32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C2-h_cq1lOtO"},"source":["## *UdaCrossEntropy*"]},{"cell_type":"code","metadata":{"id":"cbAmJWm_lWW3","cellView":"form"},"source":["#@markdown Unsupervised domain adaptive cross entropy\n","# import os\n","\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import numpy as np\n","\n","# import config\n","# from Model import Wrn28k\n","\n","\n","def UdaCrossEntroy(all_logits, l_labels, global_step):\n","    batch_size = BATCH_SIZE\n","    uda_data = UDA_DATA\n","    logits = {}\n","    labels = {}\n","    cross_entroy = {}\n","    masks = {}\n","    # 将网络的输出结果区分成 label ori aug 三个部分\n","    logits['l'], logits['ori'], logits['aug'] = tf.split(\n","        all_logits,\n","        [batch_size, batch_size * uda_data, batch_size * uda_data],\n","        axis=0,\n","    )\n","    # 对标签进行处理\n","    labels['l'] = l_labels\n","\n","    # ------------loss的计算---------\n","    # part1：有监督部分\n","    cross_entroy['l'] = keras.losses.sparse_categorical_crossentropy(\n","        from_logits=True,\n","        label_smoothing=LABEL_SMOOTHING,\n","        reduction=keras.losses.Reduction.NONE,\n","    )(labels['l'], logits['l'])\n","    '''\n","    probs = tf.nn.softmax(logits['l'], axis=-1)  # 将每张图片对应10个类别的输出转化为概率的形式\n","    correct_probs = tf.reduce_sum(labels['l'] * probs, axis=-1)  # 根据图片对应的label和概率计算出 预测正确类别的概率\n","\n","    # 计算一个阈值l_threshold\n","    r = tf.cast(global_step, tf.float32) / tf.convert_to_tensor(MAX_STEPS, dtype=tf.float32)\n","    num_classes = tf.convert_to_tensor(NUM_CLASSES, tf.float32)\n","    l_threshold = r * (1. - 1. / num_classes) + 1. / num_classes\n","\n","    masks['l'] = tf.math.less_equal(correct_probs, l_threshold)\n","    masks['l'] = tf.cast(masks['l'], tf.float32)\n","    masks['l'] = tf.stop_gradient(masks['l'])  # 如果对某图片预测的概率小于l_threahold,输出1，否则是0\n","    '''\n","    cross_entroy['l'] = tf.reduce_sum(cross_entroy['l']) / float(batch_size)\n","\n","    # part2: 无监督部分\n","    labels['ori'] = tf.nn.softmax(logits['ori'] / tf.convert_to_tensor(UDA_TEMP), axis=-1)\n","    labels['ori'] = tf.stop_gradient(labels['ori'])\n","    # tf.nn.log_softmax: 设一张图片对应3个类别的输出为o1，o2，o3 ==>\n","    # b = log(sum(exp(o1) + exp(o2) + exp(o3)))  new_o1=o1-b, new_o2=o2-b ... 恒负，大小关系不变\n","    cross_entroy['u'] = (\n","            labels['ori'] * tf.nn.log_softmax(logits['aug'], axis=-1)\n","    )\n","\n","    largest_probs = tf.reduce_max(labels['ori'], axis=-1, keepdims=True)\n","\n","    masks['u'] = tf.math.greater_equal(largest_probs, tf.constant(UDA_THRESHOLD))  # Determine whether the maximum probability is greater than the threshold    masks['u'] = tf.cast(masks['u'], DTYPE)\n","    masks['u'] = tf.stop_gradient(masks['u'])\n","    # In extreme cases, when ori’s prediction is completely accurate, that is, class i = 1, other categories are 0,\n","    # aug's class i is the largest, that is, the largest negative number, multiplying the two and then taking the negative, is a number very close to 0\n","    # 极端情况，当ori的预测完全准确，即class i = 1, 其他类别为0时，\n","    # aug的class i最大，即最大的负数，两者相乘再取负，就是一个非常接近于0的数字\n","    cross_entroy['u'] = tf.reduce_sum(-cross_entroy['u'] * masks['u']) / \\\n","                        tf.convert_to_tensor((batch_size * uda_data), dtype=DTYPE)\n","\n","    return logits, labels, masks, cross_entroy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLB_L2Nl5Rcc"},"source":["import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","# import sys  \n","# sys.path.insert(0, '/content/drive/MyDrive/Thesis/MPL/EfficientUnet/efficientunet')\n","import tensorflow as tf\n","from tensorflow import keras\n","# import pandas as pd\n","import tensorflow_addons as tfa\n","# from WideResnet import WideResnet\n","\n","\n","\n","# import efficientunet\n","# import efficientnet\n","from copy import deepcopy\n","\n","\n","sys.path.insert(0, '/content/drive/MyDrive/Thesis/MPL')\n","import config\n","# from Model import Wrn28k\n","# from UdaCrossEntroy import UdaCrossEntroy\n","# from learningRate import LearningRate\n","# from Dataset import label_image\n","# from Dataset import unlabel_image\n","# from Dataset import merge_dataset\n","# from test import test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgMA1fUn6Jjs"},"source":["input_shape = (224, 224, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdo-aoxsRU19"},"source":["\n","model2 = efficientunet.get_efficient_unet_b0(input_shape, out_channels=3, pretrained=False, block_type='transpose', concat_input=True)\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65GCE6niTZHp"},"source":["img_data_array=[]\n","class_name=[]\n","for i in range(0, len(data)): \n","  path = root + data[\"fullPath\"][i]#2499\n","  path = path.replace('\\\\', '/')\n","  path = path.replace('.png', '.jpg')\n","  try:\n","    image = Image.open(path)\n","    #image= cv2.imread( path,0)\n","    # print(image.size)\n","    image=cv2.resize(image, (224, 224),interpolation = cv2.INTER_AREA)\n","    # print(image.size)\n","    # image=cv2.resize(image, (224, 224),interpolation = cv2.INTER_AREA)\n","    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","    image=np.array(image)\n","    image = image.astype('float32')\n","    image /= 255 \n","    img_data_array.append(image)\n","    class_name.append(data[\"Status\"][i])\n","  except:\n","    continue\n","  # return img_data_array, class_name\n","# extract the image array and class name\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olh66u_obqrI"},"source":["def image_generator(files, batch_size = 32, sz = (224, 224)):\n","  \n","  while True: \n","    \n","    #extract a random batch \n","    batch = np.random.choice(files, size = batch_size)    \n","    \n","    #variables for collecting batches of inputs and outputs \n","    batch_x = []\n","    batch_y = []\n","    \n","    \n","    for f in batch:\n","        path_ = root + f[\"fullPath\"]\n","        path_ = path_.replace('\\\\', '/')\n","        path_ = path_.replace('.png', '.jpg')\n","        #get the masks. Note that masks are png files \n","        mask = Image.open(path)\n","        mask = np.array(mask.resize(sz))\n","\n","\n","        #preprocess the mask \n","        mask[mask >= 2] = 0 \n","        mask[mask != 0 ] = 1\n","        \n","        batch_y.append(mask)\n","\n","        #preprocess the raw images \n","        path = root + f[\"fullPath\"]\n","        path = path.replace('\\\\', '/')\n","        path = path.replace('.png', '.jpg')\n","        raw = Image.open(path)\n","        raw = raw.resize(sz)\n","        raw = np.array(raw)\n","\n","        #check the number of channels because some of the images are RGBA or GRAY\n","        if len(raw.shape) == 2:\n","          raw = np.stack((raw,)*3, axis=-1)\n","\n","        else:\n","          raw = raw[:,:,0:3]\n","\n","        batch_x.append(raw)\n","\n","    #preprocess a batch of images and masks \n","    batch_x = np.array(batch_x)/255.\n","    batch_y = np.array(batch_y)\n","    batch_y = np.expand_dims(batch_y,3)\n","\n","    yield (batch_x, batch_y) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sU6SPuVY8Mdc"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"sZJqhrsFoQhC"},"source":["train_generator = image_generator(data, batch_size = 32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pf9By7UkpcJ9"},"source":["train_generator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5U1W633KpAI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"raXLOfBk1pLV"},"source":["# IoU metric\n","\n","The intersection over union (IoU) metric is a simple metric used to evaluate the performance of a segmentation algorithm. Given two masks $y_{true}, y_{pred}$ we evaluate \n","\n","$$IoU = \\frac{y_{true} \\cap y_{pred}}{y_{true} \\cup y_{pred}}$$"]},{"cell_type":"code","metadata":{"id":"xJLriYXX1oZU"},"source":["from keras import backend as K\n","def mean_iou(y_true, y_pred):\n","    yt0 = y_true[:,:,:,0]\n","    yp0 = K.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n","    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n","    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n","    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n","    return iou"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iolXIH71ehNb"},"source":["from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","def build_callbacks():\n","        checkpointer = ModelCheckpoint(filepath='unet.h5', verbose=0, save_best_only=True, save_weights_only=True)\n","        callbacks = [checkpointer, PlotLearning()]\n","        return callbacks\n","\n","# inheritance for training process plot \n","class PlotLearning(keras.callbacks.Callback):\n","\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.losses = []\n","        self.val_losses = []\n","        self.acc = []\n","        self.val_acc = []\n","        #self.fig = plt.figure()\n","        self.logs = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.acc.append(logs.get('mean_iou'))\n","        self.val_acc.append(logs.get('val_mean_iou'))\n","        self.i += 1\n","        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n","        \n","        #choose a random test image and preprocess\n","        path = np.random.choice(test_files)\n","        raw = Image.open(f'images/{path}')\n","        raw = np.array(raw.resize((256, 256)))/255.\n","        raw = raw[:,:,0:3]\n","        \n","        #predict the mask \n","        pred = model.predict(np.expand_dims(raw, 0))\n","        \n","        #mask post-processing \n","        msk  = pred.squeeze()\n","        msk = np.stack((msk,)*3, axis=-1)\n","        msk[msk >= 0.5] = 1 \n","        msk[msk < 0.5] = 0 \n","        \n","        #show the mask and the segmented image \n","        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n","        plt.axis('off')\n","        plt.imshow(combined)\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvrG3Q_JKq-N"},"source":["# New section"]},{"cell_type":"code","metadata":{"id":"c7zzbX2ZKyLd"},"source":[" model2.compile(optimizer = tf.keras.optimizers.RMSprop(lr=1e-5), loss = 'binary_crossentropy', metrics = [mean_iou])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MXGinNg9Wjj"},"source":["train_steps = len(data) //32\n","# rmodel2.fit(\n","#     x= X_train, y= Y_train,\n","#     batch_size=None,\n","#     epochs=1,\n","#     verbose=\"auto\",\n","#     callbacks=None,\n","#     validation_split=0.0,\n","#     validation_data=None,\n","#     shuffle=True,\n","#     class_weight=None,\n","#     sample_weight=None,\n","#     initial_epoch=0,\n","#     steps_per_epoch=None,\n","#     validation_steps=None,\n","#     validation_batch_size=None,\n","#     validation_freq=1,\n","#     max_queue_size=10,\n","#     workers=1,\n","#     use_multiprocessing=False\n","# )\n","callbacks = [ModelCheckpoint(filepath='/content/drive/MyDrive/Thesis/effunet.h5', verbose=0, save_best_only=True, save_weights_only=True),\n","        tf.keras.callbacks.EarlyStopping(patience=40, monitor='val_loss'),\n","        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n","\n","results = model2.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30, callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm1e9QtHXleE"},"source":["ds_label_train = tf.data.Dataset.from_tensor_slices((X, Y))\n","ds_label_train = ds_label_train.shuffle(100).batch(64)\n","train_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XbxyOVZ51kA2"},"source":["from tensorflow.keras.applications import EfficientNetB0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gAETwb3rEWW"},"source":["# x = img_augmentation(inputs)\n","model = EfficientNetB0( input_shape=input_shape,include_top=True, weights=None, classes=3,classifier_activation=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MLmXe5c__Wh"},"source":["df_['']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDBsc62E5Rcd"},"source":["def my_update(model, model_):\n","    for i in range(len(model_)):\n","        #print(model_[i])\n","        # if model.weights[i].dtype != np.float32 :\n","        #   model.weights[i] = tf.cast(model.weights[i], dtype=float32)\n","        #   model_[i] = tf.cast(model_[i], dtype=float32)\n","          # continue\n","        model.weights[i] = model.weights[i].assign(\n","            model.weights[i]*(1-config.EMA)+model_[i]*config.EMA)\n","    model_ = deepcopy(model.weights)\n","    return model, model_\n","\n","\n","if __name__ == '__main__':\n","    AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","    # 有标签的数据集 batch_size=config.BATCH_SIZE\n","    # df_label = pd.read_csv(config.LABEL_FILE_PATH)\n","    # file_paths = []\n","    # labels = []\n","    # for i in range(0, len(data)): \n","    #   path = root + data[\"fullPath\"][i]#2499\n","    #   path = path.replace('\\\\', '/')\n","    #   path = path.replace('.png', '.jpg')\n","    #   file_paths.append(path)\n","    #   if data[\"Status\"][i] ==\"Cancer\":\n","    #     labels.append(3)\n","    #   elif data[\"Status\"][i] == \"Normal\":\n","    #     labels.append(1)\n","    #   elif data[\"Status\"][i] == \"Benign\" :\n","    #     labels.append(2)\n","\n","    # labels = data['Status'].values\n","    # for i in range(0, len(data)): \n","    ds_label_train = tf.data.Dataset.from_tensor_slices((df_['image'], df_['label']))\n","    # ds_label_train = ds_label_train.shuffle(100).batch(64)\n","    ds_label_train = ds_label_train \\\n","        .map(label_image, num_parallel_calls=AUTOTUNE) \\\n","        .shuffle(buffer_size=1000) \\\n","        .batch(config.BATCH_SIZE, drop_remainder=True) \\\n","        .prefetch(AUTOTUNE)\n","\n","    # 无标签的数据集 batch_size=config.BATCH_SIZE*config.UDA_DATA\n","    # df_unlabel = pd.read_csv(config.UNLABEL_FILE_PATH)\n","    # file_paths = df_unlabel['name'].values\n","    # labels = df_unlabel['label'].values\n","    ds_unlabel_train = tf.data.Dataset.from_tensor_slices((df_['image'], df_['label']))\n","    # ds_label_train = ds_label_train.shuffle(100).batch(64)\n","    # ds_unlabel_train = ds_unlabel_train.shuffle(100).batch(64)\n","    ds_unlabel_train = ds_unlabel_train \\\n","        .map(unlabel_image, num_parallel_calls=AUTOTUNE) \\\n","        .shuffle(buffer_size=1000) \\\n","        .batch(config.BATCH_SIZE * config.UDA_DATA, drop_remainder=True) \\\n","        .prefetch(AUTOTUNE)\n","\n","    # 将有标签数据和无标签数据整合成最终的数据形式\n","    ds_train = tf.data.Dataset.zip((ds_label_train, ds_unlabel_train))\n","    ds_train = ds_train.map(merge_dataset)\n","\n","    # 构建teacher模型\n","    if config.TEA_CONTINUE:\n","        print('continue teacher training')\n","        teacher = model2#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","        teacher.load_weights(config.TEA_LOAD_PATH)\n","        teacher.training = True\n","    else:\n","        # teacher = Wrn28k(num_inp_filters=3, k=2)\n","        teacher =  model2#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","\n","    # 构建student模型\n","    if config.STD_CONTINUE:\n","        print('continue student training')\n","        student =  model2#efficientunet.get_efficient_unet_b0(input_shape,  pretrained=False)\n","        student.load_weights(config.STD_LOAD_PATH)\n","        student.training = True\n","        student = tf.saved_model.load(config.STD_LOAD_PATH)\n","    else:\n","        # student = Wrn28k(num_inp_filters=3, k=2)\n","        student =  model2#efficientunet.get_efficient_unet_b0(input_shape, pretrained=False)\n","    student_ = student.weights\n","\n","    for i in range(len(student_)):\n","      #print(model_[i])\n","      if student.weights[i].dtype != np.float32 :\n","        student.weights[i] = tf.cast(student.weights[i], dtype=float32)\n","        student_[i] = tf.cast(student_[i], dtype=float32)\n","    # 定义teacher的损失函数，损失函数之一为UdaCrossEntroy\n","    mpl_loss = tf.losses.SparseCategoricalCrossentropy(\n","        reduction=tf.losses.Reduction.NONE,\n","        from_logits=True,\n","    )\n","    # 定义student的损失函数， PS：teacher的损失函数为UdaCrossEntroy\n","    s_unlabel_loss = tf.losses.SparseCategoricalCrossentropy(\n","        label_smoothing=config.LABEL_SMOOTHING,\n","        from_logits=True,\n","        reduction=tf.keras.losses.Reduction.NONE,\n","    )\n","\n","    s_label_loss = tf.losses.SparseCategoricalCrossentropy(\n","        reduction=tf.keras.losses.Reduction.NONE,\n","        from_logits=True,\n","    )\n","\n","    # 定义teacher的学习率\n","    Tea_lr_fun = LearningRate(\n","        config.TEACHER_LR,\n","        config.TEACHER_LR_WARMUP_STEPS,\n","        config.TEACHER_NUM_WAIT_STEPS\n","    )\n","    # 定义student的学习率\n","    Std_lr_fun = LearningRate(\n","        config.STUDENT_LR,\n","        config.STUDENT_LR_WARMUP_STEPS,\n","        config.STUDENT_LR_WAIT_STEPS\n","    )\n","\n","    global_step = 62*config.CONTINUE_EPOCH\n","    print(f'start training from global step {global_step}......')\n","    TBacc = 0.78\n","    Tacc = 0\n","    SBacc = 0.31\n","    Sacc = 0\n","    epochs = config.MAX_EPOCHS - config.CONTINUE_EPOCH\n","    for epoch in range(epochs):\n","        TLOSS = 0\n","        TLOSS_1 = 0\n","        TLOSS_2 = 0\n","        TLOSS_3 = 0\n","        SLOSS = 0\n","        for batch_idx, (l_images, l_labels, ori_images, aug_images) in enumerate(ds_train):\n","            global_step += 1\n","            all_images = tf.concat([l_images, ori_images, aug_images], axis=0)  # shape [15, 32, 32, 3]\n","            u_aug_and_l_images = tf.concat([aug_images, l_images], axis=0)\n","            # step1：经过teacher，得到输出\n","            with tf.GradientTape() as t_tape:\n","                output = teacher(all_images)  # shape=[15, 10]\n","                logits, labels, masks, cross_entroy = UdaCrossEntroy(output, l_labels, global_step)\n","            # step2：1st call student -----------------------------\n","            with tf.GradientTape() as s_tape:\n","                logits['s_on_aug_and_l'] = student(u_aug_and_l_images)  # shape=[8, 10]\n","                logits['s_on_u'], logits['s_on_l_old'] = tf.split(\n","                    logits['s_on_aug_and_l'],\n","                    [aug_images.shape[0], l_images.shape[0]],\n","                    axis=0\n","                )\n","                cross_entroy['s_on_u'] = s_unlabel_loss(\n","                    y_true=tf.stop_gradient(tf.nn.softmax(logits['aug'], -1)),\n","                    y_pred=logits['s_on_u']\n","                )\n","                # 计算损失函数\n","                cross_entroy['s_on_u'] = tf.reduce_sum(cross_entroy['s_on_u']) / \\\n","                                         tf.convert_to_tensor(config.BATCH_SIZE * config.UDA_DATA, dtype=tf.float32)\n","                SLOSS += cross_entroy['s_on_u']\n","                # for taylor\n","                cross_entroy['s_on_l_old'] = s_label_loss(\n","                    y_true=labels['l'],\n","                    y_pred=logits['s_on_l_old']\n","                )\n","\n","                cross_entroy['s_on_l_old'] = tf.reduce_sum(cross_entroy['s_on_l_old']) / \\\n","                                             tf.convert_to_tensor(config.BATCH_SIZE, dtype=tf.float32)\n","            # 反向传播，更新student的参数-------\n","            StudentLR = Std_lr_fun.__call__(global_step=global_step)\n","            StdOptim = keras.optimizers.SGD(\n","                learning_rate=StudentLR,\n","                momentum=0.9,\n","                nesterov=True,\n","                # weight_decay=5e-4,\n","            )\n","            # StdOptim = keras.optimizers.Adam(learning_rate=StudentLR)\n","            GStud_unlabel = s_tape.gradient(cross_entroy['s_on_u'], student.trainable_variables)\n","            GStud_unlabel, _ = tf.clip_by_global_norm(GStud_unlabel, config.GRAD_BOUND)\n","            StdOptim.apply_gradients(zip(GStud_unlabel, student.trainable_variables))\n","            # 如何更新参数\n","            student, student_ = my_update(student, student_)\n","\n","            # step3: 2nd call student ------------------------------\n","            logits['s_on_l_new'] = student(l_images)\n","            cross_entroy['s_on_l_new'] = s_label_loss(\n","                y_true=labels['l'],\n","                y_pred=logits['s_on_l_new']\n","            )\n","            cross_entroy['s_on_l_new'] = tf.reduce_sum(cross_entroy['s_on_l_new']) / \\\n","                                         tf.convert_to_tensor(config.BATCH_SIZE, dtype=config.DTYPE)\n","            dot_product = cross_entroy['s_on_l_new'] - cross_entroy['s_on_l_old']\n","            limit = 3.0**(0.5)\n","            moving_dot_product = tf.random_uniform_initializer(minval=-limit, maxval=limit)(shape=dot_product.shape)\n","            moving_dot_product = tf.Variable(initial_value=moving_dot_product, trainable=False, dtype=config.DTYPE)\n","            moving_dot_product_update = moving_dot_product.assign_sub(0.01 * (moving_dot_product - dot_product))\n","            dot_product = dot_product - moving_dot_product\n","            dot_product = tf.stop_gradient(dot_product)\n","            # step4: 求teacher的损失函数\n","            with t_tape:\n","                # label = tf.math.argmax(tf.nn.softmax(logits['aug'], axis=-1), axis=-1)\n","                # label = tf.raw_ops.OneHot(indices=label, depth=config.NUM_CLASSES, on_value=1.0, off_value=0)\n","                cross_entroy['mpl'] = mpl_loss(\n","                    # y_true=tf.stop_gradient(label),\n","                    y_true=tf.stop_gradient(tf.nn.softmax(logits['aug'], axis=-1)),\n","                    y_pred=logits['aug']\n","                )  # 恒正\n","                cross_entroy['mpl'] = tf.reduce_sum(cross_entroy['mpl']) / \\\n","                                      tf.convert_to_tensor(config.BATCH_SIZE * config.UDA_DATA, dtype=config.DTYPE)\n","                uda_weight = config.UDA_WEIGHT * tf.math.minimum(\n","                    1., tf.cast(global_step, config.DTYPE) / float(config.UDA_STEPS)\n","                )\n","                # if StudentLR == 0:\n","                #     dot_product = 0\n","                teacher_loss = cross_entroy['u'] * uda_weight + \\\n","                               cross_entroy['l'] + \\\n","                               cross_entroy['mpl'] * dot_product\n","\n","                TLOSS += teacher_loss\n","                TLOSS_1 += (cross_entroy['u'] * uda_weight)\n","                TLOSS_2 += cross_entroy['l']\n","                TLOSS_3 += cross_entroy['mpl'] * dot_product\n","            # 反向传播，更新teacher的参数-------\n","            TeacherLR = Tea_lr_fun.__call__(global_step=global_step)\n","            TeaOptim = keras.optimizers.SGD(\n","                learning_rate=TeacherLR,\n","                momentum=0.9,\n","                nesterov=True,\n","                # weight_decay=5e-4,\n","            )\n","            # TeaOptim = keras.optimizers.Adam(learning_rate=TeacherLR)\n","            GTea = t_tape.gradient(teacher_loss, teacher.trainable_variables)\n","            GTea, _ = tf.clip_by_global_norm(GTea, config.GRAD_BOUND)\n","            TeaOptim.apply_gradients(zip(GTea, teacher.trainable_variables))\n","\n","            if (batch_idx + 1) % config.LOG_EVERY == 0:\n","                TLOSS = TLOSS / config.LOG_EVERY\n","                TLOSS_1 = TLOSS_1 / config.LOG_EVERY\n","                TLOSS_2 = TLOSS_2 / config.LOG_EVERY\n","                TLOSS_3 = TLOSS_3 / config.LOG_EVERY\n","                SLOSS = SLOSS / config.LOG_EVERY\n","                print(f'global: %4d' % global_step + ',[epoch:%4d/' % (epoch+config.CONTINUE_EPOCH) + 'EPOCH: %4d] \\t' % epochs\n","                      + '[U:%.4f' % (TLOSS_1) + ', L:%.4f' % (TLOSS_2) + ', M:%.4f' % (\n","                          TLOSS_3) + ']' + '[TLoss: %.4f]' % TLOSS + '/[SLoss: %.4f]' % SLOSS\n","                      + '\\t[TLR: %.6f' % TeacherLR + ']/[SLR: %.6f]' % StudentLR)\n","                TLOSS = 0\n","                TLOSS_1 = 0\n","                TLOSS_2 = 0\n","                TLOSS_3 = 0\n","                SLOSS = 0\n","        # 测试teacher在test上的acc\n","        if epoch % 5 == 0:\n","            Tacc = test(teacher, file_paths, labels)\n","            print(f'testing teacher model ... acc: {Tacc}')\n","        # 测试student在test上的acc，当student开始训练的时候\n","        if (StudentLR > 0) and (epoch % 5 == 0):\n","            Sacc = test(student, file_paths, labels)\n","            print(f'testing ... acc: {Sacc}')\n","        # 保存weights\n","        if Tacc > TBacc:\n","            Tsave_path = config.TEA_SAVE_PATH  # + str(epoch + 1) + '_' + str(batch_idx + 1)\n","            teacher.save_weights(Tsave_path)\n","            # tf.saved_model.save(teacher, Tsave_path)\n","            TBacc = Tacc\n","            print(f'saving for TBacc {TBacc}, Tpath:{Tsave_path}')\n","        if Sacc > SBacc:\n","            Ssave_path = config.STD_SAVE_PATH  # + str(epoch + 1) + '_' + str(batch_idx + 1)\n","            student.save_weights(Ssave_path)\n","            SBacc = Sacc\n","            print(f'saving for SBacc {SBacc}, Spath:{Ssave_path}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5rKsM968Tzb"},"source":["student.weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fj5U6AJT5jW"},"source":["teacher.weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQJXdt_Y5Rch"},"source":["## Others"]},{"cell_type":"code","metadata":{"id":"cHMphWE25Rci"},"source":["mod = keras.Sequential()\n","mod.add(model)\n","mod.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZBMqH5S5Rcj"},"source":["%cd /content/drive/MyDrive/Thesis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D951x6G75Rcj"},"source":["import sys  \n","sys.path.insert(0, '/content/drive/MyDrive/Thesis/EfficientUnet/efficientunet')\n","\n","\n","import efficientunet\n","import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB6\n","\n","import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4ERusyJ5Rck"},"source":["input_shape = (224, 224, 3)\n","model2 = efficientunet.get_efficient_unet_b7(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True)\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vlGg_Kyh5Rcl"},"source":["import itertools\n","import os\n","\n","import matplotlib.pylab as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print('TF version:', tf.__version__)\n","print('Hub version:', hub.__version__)\n","print('Phsical devices:', tf.config.list_physical_devices())\n","\n","def get_hub_url_and_isize(model_name, ckpt_type, hub_type):\n","  if ckpt_type == '-1k':\n","    ckpt_type = ''  # json doesn't support empty string\n","  \n","  hub_url_map = {\n","    'efficientnetv2-b0': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/{hub_type}',\n","    'efficientnetv2-b1': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1/{hub_type}',\n","    'efficientnetv2-b2': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2/{hub_type}',\n","    'efficientnetv2-b3': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3/{hub_type}',\n","    'efficientnetv2-s':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s/{hub_type}',\n","    'efficientnetv2-m':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m/{hub_type}',\n","    'efficientnetv2-l':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l/{hub_type}',\n","    'efficientnetv2-s-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k/{hub_type}',\n","    'efficientnetv2-m-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k/{hub_type}',\n","    'efficientnetv2-l-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k/{hub_type}',\n","    'efficientnetv2-s-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k-ft1k/{hub_type}',\n","    'efficientnetv2-m-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k-ft1k/{hub_type}',\n","    'efficientnetv2-l-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k-ft1k/{hub_type}',\n","      \n","    # efficientnetv1\n","    'efficientnet_b0': f'https://tfhub.dev/tensorflow/efficientnet/b0/{hub_type}/1',\n","    'efficientnet_b1': f'https://tfhub.dev/tensorflow/efficientnet/b1/{hub_type}/1',\n","    'efficientnet_b2': f'https://tfhub.dev/tensorflow/efficientnet/b2/{hub_type}/1',\n","    'efficientnet_b3': f'https://tfhub.dev/tensorflow/efficientnet/b3/{hub_type}/1',\n","    'efficientnet_b4': f'https://tfhub.dev/tensorflow/efficientnet/b4/{hub_type}/1',\n","    'efficientnet_b5': f'https://tfhub.dev/tensorflow/efficientnet/b5/{hub_type}/1',\n","    'efficientnet_b6': f'https://tfhub.dev/tensorflow/efficientnet/b6/{hub_type}/1',\n","    'efficientnet_b7': f'https://tfhub.dev/tensorflow/efficientnet/b7/{hub_type}/1',\n","  }\n","  \n","  image_size_map = {\n","    'efficientnetv2-b0': 224,\n","    'efficientnetv2-b1': 240,\n","    'efficientnetv2-b2': 260,\n","    'efficientnetv2-b3': 300,\n","    'efficientnetv2-s':  384,\n","    'efficientnetv2-m':  480,\n","    'efficientnetv2-l':  480,\n","  \n","    'efficientnet_b0': 224,\n","    'efficientnet_b1': 240,\n","    'efficientnet_b2': 260,\n","    'efficientnet_b3': 300,\n","    'efficientnet_b4': 380,\n","    'efficientnet_b5': 456,\n","    'efficientnet_b6': 528,\n","    'efficientnet_b7': 600,\n","  }\n","  \n","  hub_url = hub_url_map.get(model_name + ckpt_type)\n","  image_size = image_size_map.get(model_name, 224)\n","  return hub_url, image_size\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Czkmh-k05Rcm"},"source":["# Build model\n","import tensorflow_hub as hub\n","model_name = 'efficientnetv2-b0' #@param {type:'string'}\n","ckpt_type = '-1k'   # @param ['-21k', '-21k-ft1k', '-1k']\n","hub_type = 'classification' # @param ['classification', 'feature-vector']\n","hub_url, image_size = get_hub_url_and_isize(model_name, ckpt_type, hub_type)\n","tf.keras.backend.clear_session()\n","m = hub.KerasLayer(hub_url, trainable=False)\n","  # Batch input shape."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYgy0rF5Z9pP"},"source":["l = tf.keras.layers.Layer(hub_url)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"umZNPU9CbtF8"},"source":["l.trainable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVXwC1s4bg5J"},"source":["encoder = tf.keras.Sequential([\n","    # Explicitly define the input shape so the model can be properly\n","    # loaded by the TFLiteConverter\n","    tf.keras.layers.InputLayer(input_shape=[image_size, image_size, 3]),\n","    l,\n","    #tf.keras.layers.Dropout(rate=0.2)\n","    # tf.keras.layers.Dense(train_generator.num_classes,\n","                          # kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n","])\n","#encoder.build((image_size, image_size, 3))\n","encoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7rUfun25Rcn"},"source":["from keras import models\n","from keras import Sequential\n","# whether to finetune the whole model or just the top layer.\n","do_fine_tuning = False #@param {type:\"boolean\"}\n","num_epochs = 2 #@param {type:\"integer\"}\n","\n","tf.keras.backend.clear_session()\n","#model = models.Model.build(m, [None, 224, 224, 3])\n","encoder = tf.keras.Sequential([\n","    # Explicitly define the input shape so the model can be properly\n","    # loaded by the TFLiteConverter\n","    tf.keras.layers.InputLayer(input_shape=[image_size, image_size, 3]),\n","    hub.KerasLayer(hub_url, trainable=do_fine_tuning),\n","    #tf.keras.layers.Dropout(rate=0.2)\n","    # tf.keras.layers.Dense(train_generator.num_classes,\n","                          # kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n","])\n","#encoder.build((image_size, image_size, 3))\n","encoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5fXosbW5Rcn"},"source":["input_shape = (224, 224, 3)\n","model2 = efficientnet.get_efficientnet_b6_encoder(input_shape, pretrained=False)\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbYqpYqe5Rco"},"source":["shapes = []\n","candidates = []\n","mbblock_nr = 0\n","while True:\n","    try:\n","        mbblock = encoder.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr)).output\n","        shape = int(mbblock.shape[1]), int(mbblock.shape[2])\n","        if shape not in shapes:\n","            shapes.append(shape)\n","            candidates.append(mbblock_nr)\n","        if verbose:\n","            print('blocks_{}_output_shape: {}'.format(mbblock_nr, shape))\n","        mbblock_nr += 1\n","    except ValueError:\n","        break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htti8opi5Rcp"},"source":[".output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vf9DNQxK5Rcq"},"source":["# input_shape = (224, 224, 3)\n","# encoder = encoder\n","model = efficientunet._get_efficient_unet(encoder, out_channels=2, block_type='upsampling', concat_input=True)\n","#model2 = efficientnet.get_efficientnet_b6_encoder(input_shape, pretrained=False)\n","#model3 = EfficientNetB6(include_top=False, weights='imagenet')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TZjgVhb5Rcq"},"source":["learning_rate = 0.003\n","meta_step_size = 0.25\n","\n","inner_batch_size = 25\n","eval_batch_size = 25\n","\n","meta_iters = 2000\n","eval_iters = 5\n","inner_iters = 4\n","\n","eval_interval = 1\n","train_shots = 20\n","shots = 5\n","classes = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8MJRJhXC5Rcr"},"source":["# import sys  \n","# sys.path.insert(0, '/content/google-research')\n","\n","# from meta_pseudo_labels import modeling\n","# from meta_pseudo_labels import flag_utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZKG607D5Rcr"},"source":["# teacher = models.get_teacher_model\n","# student = models.get_student_model\n","# fine_tune = models.get_finetune_model\n","# train = train."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKloKBho5Rcs"},"source":["\n","# eff_net = modeling.Wrn28k\n","\n","# l2 = eff_net"],"execution_count":null,"outputs":[]}]}